# Emerging Technologies
This repository supplements the Emerging Technologies course. By the end of the course, the learner is expected to demonstrate Artificial Intelligence-driven solutions to solve engineering problems.

## Dependencies
Create a new virtual environment and install the necessary libraries using the [requirements.txt](requirements.txt) file.
```bash
pip install -r requirements.txt
```

## Course Outline

 | Activity | Learning Objective | Main Resource |
| -------- | -------- | -------- |
| Python Basics and Exercises | To enhance practical skills in basic Python syntax |  [activities/Lastname_Python_Basics_and_Exercises.ipynb](activities/Lastname_Python_Basics_and_Exercises.ipynb) |
| Advanced Python and Exercises | To learn NumPy and Pandas libraries | [activities/Lastname_Advanced_Python_and_Exercises.ipynb](activities/Lastname_Advanced_Python_and_Exercises.ipynb) |
| Coin Counting | To master OpenCV's image processing available APIs. Read the [coin_counting/README.md](activities/opencv_samples/coin_counting/README.md) for the details on the sample images. | [activities/opencv_samples/coin_counting/coin_counting.py](activities/opencv_samples/coin_counting/coin_counting.py) |
| Color Tracking | To master OpenCV's color tracking capability. Read the [color_tracking/README.md](activities/opencv_samples/color_tracking/README.md). | [activities/opencv_samples/color_tracking/color_tracking.py](activities/opencv_samples/color_tracking/color_tracking.py) |
| Face Tracking | To implement face detection and tracking using Haar cascades. Read the [face_tracking/README.md](activities/opencv_samples/face_tracking/README.md) | [activities/opencv_samples/face_tracking/facetracking.py](activities/opencv_samples/face_tracking/facetracking.py) |
| Eye Tracking | To implement eye detection and tracking using Haar cascades. Read the [eye_tracking/README.md](activities/opencv_samples/eye_tracking/README.md) | [activities/opencv_samples/eye_tracking/eyetracking.py](activities/opencv_samples/eye_tracking/eyetracking.py) | 
| Hand Detection | To demonstrate Mediapipe's detection model to determine the left and right hands, with their other useful information. | [activities/opencv_samples/hand_detection/hand.py](activities/opencv_samples/hand_detection/hand.py) |
| Hand Gesture Detection | To demonstrate  Mediapipe's detection model to detect and classify specific hand gestures.  | [activities/opencv_samples/hand_gesture_detection/gesture.py](activities/opencv_samples/hand_gesture_detection/gesture.py) |
| Facial Emotion Recognition | To demonstrate Mediapipe's detection model to identify facial emotions. Read the [facial_emotion_recognition/README.md](activities/opencv_samples/facial_emotion_recognition/README.md)|[activities/opencv_samples/facial_emotion_recognition/facial_emotion.py](activities/opencv_samples/facial_emotion_recognition/facial_emotion.py)|
| Gender and Age Recognition | To demonstrate deep learning-based models to identify gender and age. Read the [gender_and_age_detection/README.md](activities/opencv_samples/gender_and_age_detection/README.md)| [activities/opencv_samples/gender_and_age_detection/gender_age.py](activities/opencv_samples/gender_and_age_detection/gender_age.py) |
| Pose Estimation | To demonstrate Mediapipe's pose detection model to estimate the joints of the body's pose. Read the [pose_estimation/README.md](activities/opencv_samples/pose_estimation/README.md) | [activities/opencv_samples/pose_estimation/pose.py](activities/opencv_samples/pose_estimation/pose.py)|