{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idvgYpln1lRB"
      },
      "source": [
        "# Machine Learning Workflow: Regression\n",
        "\n",
        "Let us elevate your knowledge on Machine Learning by getting hands-on experience with Regression task. From the past activities, you learn that classification requires discrete values on targets. In regression, the targets are in continuous values, rather than discrete. There is no changes in the workflow, as shown in the figure below. The only difference is that the new target transitions to different data types, from `int` to `float`.\n",
        "\n",
        "\n",
        "By the end of this laboratory notebook, you will be able to **implement solutions in any ML regression tasks.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5e4x9nKRgc_"
      },
      "source": [
        "![workflow2.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvgy1kqc1k2S"
      },
      "source": [
        "## 1. Data Preparation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fsZJ6PpgYjI"
      },
      "source": [
        "You can download the `boston_house.csv` from this [GDrive](https://drive.google.com/file/d/1KEkOfr_ubEL4F-a4zhwGEa9T906hWpim/view?usp=drive_link)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u6lSQ829_Ui2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded boston_house.csv into a DataFrame.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "try: # if csv file is already in Colab, then load\n",
        "  raw_data = pd.read_csv(\"C:/Users/DWIGHT LANCE JUMAOAS/don't open this/emerging_technology/emerging-technologies-main/activities/machine_learning_samples/boston_house.csv\")\n",
        "  print(\"Loaded boston_house.csv into a DataFrame.\")\n",
        "except FileNotFoundError: # otherwise, allow user to upload the CSV file\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "      raw_data = pd.read_csv(filename)\n",
        "      print(f\"Loaded {filename} into a DataFrame.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daac5VqHN9J_"
      },
      "source": [
        "Determine the `features` and `ground-truth classes`. Once again, we represent the array of features as the `X` variable, while the ground-truth classes (or the targets) as the `y` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6XojiBuTN8Ym"
      },
      "outputs": [],
      "source": [
        "X = raw_data.iloc[:, :-1]\n",
        "y = raw_data.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLdg7yMf87jG"
      },
      "source": [
        "Then, you need to perform data splitting: 70% training, 15% validation, and 15% testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l0nsRLUKUWN3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_others, y_train, y_others = train_test_split(\n",
        "    X,  # features\n",
        "    y,  # targets\n",
        "    train_size=0.7,  # 70% training set\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_others,  # features\n",
        "    y_others,  # targets\n",
        "    test_size=0.5,  # 15% = 0.5 of 30%\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5qLFqqQbPku"
      },
      "source": [
        "Alright! So now, you need to remember that:\n",
        "\n",
        "\n",
        "1.   `X_train` and `y_train` correspond to the features and targets in the training set.\n",
        "2.   `X_val` and `y_val` correspond to the features and targets in the validation set.\n",
        "3.   `X_test` and `y_test` correspond to the features and targets in the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBP7qoqubmNa"
      },
      "source": [
        "## 2. Training\n",
        "\n",
        "Declare your own ML regression algorithms. Go to [sklearn page](https://scikit-learn.org/stable/supervised_learning.html) for the various options and their documentations.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1jNJ4f2a7ORX"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "model = MLPRegressor(\n",
        "    hidden_layer_sizes=(100),     \n",
        "    max_iter=1000\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlWNKC4Iq_26"
      },
      "source": [
        "Assign values for `epoch` and `batch size`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eTwJA8jxp1rn"
      },
      "outputs": [],
      "source": [
        "epochs = 6000\n",
        "batch_size = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "disB4cZbrmTG"
      },
      "source": [
        "Since we will employ batch processing, you need to re-use the function below to create create batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y5fhiejWrsZ9"
      },
      "outputs": [],
      "source": [
        "def get_batches(X, y, batch_size):\n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        X_batch = X[i:i + batch_size]\n",
        "        y_batch = y[i:i + batch_size]\n",
        "        yield X_batch, y_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7OhIYZM7m56"
      },
      "source": [
        "Next thing you need to do is to define your own regression loss function. You can optionally call available APIs of different regression loss functions in the sklearn modules. Go to [3.4.1. Scoring parameter](https://scikit-learn.org/stable/modules/model_evaluation.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OWLKgAY9u0Wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq4cUGwYsU__"
      },
      "source": [
        "You can run the code snippet below to begin the training process. The program might not run, unless you have assigned values for `X_train`, `y_train`, `X_val`, `y_val`, `epochs`, `batch_size`, `model`, and `loss`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "roFsBs45saHu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6000: train_loss=1015.4416, val_loss=1033.5037, \n",
            "Epoch 2/6000: train_loss=459.8736, val_loss=478.4598, \n",
            "Epoch 3/6000: train_loss=424.7147, val_loss=421.9628, \n",
            "Epoch 4/6000: train_loss=541.9534, val_loss=523.0354, \n",
            "Epoch 5/6000: train_loss=547.7231, val_loss=530.5310, \n",
            "Epoch 6/6000: train_loss=429.8301, val_loss=424.3044, \n",
            "Epoch 7/6000: train_loss=271.0674, val_loss=277.0368, \n",
            "Epoch 8/6000: train_loss=163.9818, val_loss=172.4039, \n",
            "Epoch 9/6000: train_loss=138.8061, val_loss=139.5226, \n",
            "Epoch 10/6000: train_loss=166.8770, val_loss=155.2545, \n",
            "Epoch 11/6000: train_loss=192.0308, val_loss=170.9438, \n",
            "Epoch 12/6000: train_loss=182.2209, val_loss=159.3311, \n",
            "Epoch 13/6000: train_loss=146.3947, val_loss=129.2792, \n",
            "Epoch 14/6000: train_loss=114.9316, val_loss=107.2988, \n",
            "Epoch 15/6000: train_loss=105.0809, val_loss=107.2722, \n",
            "Epoch 16/6000: train_loss=113.1950, val_loss=122.5183, \n",
            "Epoch 17/6000: train_loss=120.8151, val_loss=133.1730, \n",
            "Epoch 18/6000: train_loss=115.4001, val_loss=126.8325, \n",
            "Epoch 19/6000: train_loss=100.3288, val_loss=106.9919, \n",
            "Epoch 20/6000: train_loss=87.8635, val_loss=87.2246, \n",
            "Epoch 21/6000: train_loss=84.2774, val_loss=76.1431, \n",
            "Epoch 22/6000: train_loss=86.1029, val_loss=71.9292, \n",
            "Epoch 23/6000: train_loss=86.5805, val_loss=69.7968, \n",
            "Epoch 24/6000: train_loss=83.4392, val_loss=67.3730, \n",
            "Epoch 25/6000: train_loss=78.8174, val_loss=65.9446, \n",
            "Epoch 26/6000: train_loss=76.2123, val_loss=67.4530, \n",
            "Epoch 27/6000: train_loss=76.5011, val_loss=71.2524, \n",
            "Epoch 28/6000: train_loss=77.5260, val_loss=74.1482, \n",
            "Epoch 29/6000: train_loss=76.9061, val_loss=73.2501, \n",
            "Epoch 30/6000: train_loss=75.0214, val_loss=69.4896, \n",
            "Epoch 31/6000: train_loss=73.3256, val_loss=64.8688, \n",
            "Epoch 32/6000: train_loss=72.7171, val_loss=61.4980, \n",
            "Epoch 33/6000: train_loss=72.5204, val_loss=59.6328, \n",
            "Epoch 34/6000: train_loss=71.8261, val_loss=58.8639, \n",
            "Epoch 35/6000: train_loss=70.7231, val_loss=58.8004, \n",
            "Epoch 36/6000: train_loss=69.7421, val_loss=59.5651, \n",
            "Epoch 37/6000: train_loss=69.1543, val_loss=60.1891, \n",
            "Epoch 38/6000: train_loss=68.7459, val_loss=60.7484, \n",
            "Epoch 39/6000: train_loss=68.2412, val_loss=60.3836, \n",
            "Epoch 40/6000: train_loss=67.7225, val_loss=59.8196, \n",
            "Epoch 41/6000: train_loss=67.0996, val_loss=58.3652, \n",
            "Epoch 42/6000: train_loss=66.6151, val_loss=56.6869, \n",
            "Epoch 43/6000: train_loss=66.2588, val_loss=55.5173, \n",
            "Epoch 44/6000: train_loss=65.7261, val_loss=55.3337, \n",
            "Epoch 45/6000: train_loss=65.1993, val_loss=55.4407, \n",
            "Epoch 46/6000: train_loss=64.7509, val_loss=55.6040, \n",
            "Epoch 47/6000: train_loss=64.3395, val_loss=55.5416, \n",
            "Epoch 48/6000: train_loss=63.8752, val_loss=54.6279, \n",
            "Epoch 49/6000: train_loss=63.4466, val_loss=53.5452, \n",
            "Epoch 50/6000: train_loss=63.0243, val_loss=53.5326, \n",
            "Epoch 51/6000: train_loss=62.6131, val_loss=52.9785, \n",
            "Epoch 52/6000: train_loss=62.2180, val_loss=52.5610, \n",
            "Epoch 53/6000: train_loss=61.8313, val_loss=52.2147, \n",
            "Epoch 54/6000: train_loss=61.4514, val_loss=51.4956, \n",
            "Epoch 55/6000: train_loss=61.0790, val_loss=51.0187, \n",
            "Epoch 56/6000: train_loss=60.7105, val_loss=50.7496, \n",
            "Epoch 57/6000: train_loss=60.3572, val_loss=50.7932, \n",
            "Epoch 58/6000: train_loss=60.0004, val_loss=50.3804, \n",
            "Epoch 59/6000: train_loss=59.6443, val_loss=49.8187, \n",
            "Epoch 60/6000: train_loss=59.3044, val_loss=49.3291, \n",
            "Epoch 61/6000: train_loss=58.9725, val_loss=48.8970, \n",
            "Epoch 62/6000: train_loss=58.6425, val_loss=48.5719, \n",
            "Epoch 63/6000: train_loss=58.3209, val_loss=48.6016, \n",
            "Epoch 64/6000: train_loss=58.0308, val_loss=48.8030, \n",
            "Epoch 65/6000: train_loss=57.7010, val_loss=48.3539, \n",
            "Epoch 66/6000: train_loss=57.3680, val_loss=47.5292, \n",
            "Epoch 67/6000: train_loss=57.0622, val_loss=47.2602, \n",
            "Epoch 68/6000: train_loss=56.7620, val_loss=46.9732, \n",
            "Epoch 69/6000: train_loss=56.4702, val_loss=46.5125, \n",
            "Epoch 70/6000: train_loss=56.1793, val_loss=46.3348, \n",
            "Epoch 71/6000: train_loss=55.8991, val_loss=45.8830, \n",
            "Epoch 72/6000: train_loss=55.6148, val_loss=45.8304, \n",
            "Epoch 73/6000: train_loss=55.3474, val_loss=45.8242, \n",
            "Epoch 74/6000: train_loss=55.1109, val_loss=46.0341, \n",
            "Epoch 75/6000: train_loss=54.8481, val_loss=45.7818, \n",
            "Epoch 76/6000: train_loss=54.5614, val_loss=45.0964, \n",
            "Epoch 77/6000: train_loss=54.3065, val_loss=44.4495, \n",
            "Epoch 78/6000: train_loss=54.0609, val_loss=44.1331, \n",
            "Epoch 79/6000: train_loss=53.8910, val_loss=43.2008, \n",
            "Epoch 80/6000: train_loss=53.6045, val_loss=43.3227, \n",
            "Epoch 81/6000: train_loss=53.3390, val_loss=43.8406, \n",
            "Epoch 82/6000: train_loss=53.1062, val_loss=43.4944, \n",
            "Epoch 83/6000: train_loss=52.8833, val_loss=43.6208, \n",
            "Epoch 84/6000: train_loss=52.6845, val_loss=43.8565, \n",
            "Epoch 85/6000: train_loss=52.4427, val_loss=43.5555, \n",
            "Epoch 86/6000: train_loss=52.1847, val_loss=42.7228, \n",
            "Epoch 87/6000: train_loss=51.9818, val_loss=42.0002, \n",
            "Epoch 88/6000: train_loss=51.7544, val_loss=41.8421, \n",
            "Epoch 89/6000: train_loss=51.5215, val_loss=41.8243, \n",
            "Epoch 90/6000: train_loss=51.2998, val_loss=42.2940, \n",
            "Epoch 91/6000: train_loss=51.0908, val_loss=42.2576, \n",
            "Epoch 92/6000: train_loss=50.8729, val_loss=42.0374, \n",
            "Epoch 93/6000: train_loss=50.6468, val_loss=41.5012, \n",
            "Epoch 94/6000: train_loss=50.4354, val_loss=41.1205, \n",
            "Epoch 95/6000: train_loss=50.2193, val_loss=41.0497, \n",
            "Epoch 96/6000: train_loss=50.0045, val_loss=40.9862, \n",
            "Epoch 97/6000: train_loss=49.7914, val_loss=40.8681, \n",
            "Epoch 98/6000: train_loss=49.5828, val_loss=40.4306, \n",
            "Epoch 99/6000: train_loss=49.3746, val_loss=40.3982, \n",
            "Epoch 100/6000: train_loss=49.1764, val_loss=40.5615, \n",
            "Epoch 101/6000: train_loss=48.9688, val_loss=40.3972, \n",
            "Epoch 102/6000: train_loss=48.7661, val_loss=40.3156, \n",
            "Epoch 103/6000: train_loss=48.5519, val_loss=39.9978, \n",
            "Epoch 104/6000: train_loss=48.3455, val_loss=39.3309, \n",
            "Epoch 105/6000: train_loss=48.1384, val_loss=39.3077, \n",
            "Epoch 106/6000: train_loss=47.9434, val_loss=39.0484, \n",
            "Epoch 107/6000: train_loss=47.7528, val_loss=38.8177, \n",
            "Epoch 108/6000: train_loss=47.5554, val_loss=38.7545, \n",
            "Epoch 109/6000: train_loss=47.3733, val_loss=38.4414, \n",
            "Epoch 110/6000: train_loss=47.1782, val_loss=38.4902, \n",
            "Epoch 111/6000: train_loss=47.0054, val_loss=38.9539, \n",
            "Epoch 112/6000: train_loss=46.8727, val_loss=39.3509, \n",
            "Epoch 113/6000: train_loss=46.6757, val_loss=39.0699, \n",
            "Epoch 114/6000: train_loss=46.4545, val_loss=38.2294, \n",
            "Epoch 115/6000: train_loss=46.3004, val_loss=37.6183, \n",
            "Epoch 116/6000: train_loss=46.1637, val_loss=37.2212, \n",
            "Epoch 117/6000: train_loss=45.9408, val_loss=37.5395, \n",
            "Epoch 118/6000: train_loss=45.7848, val_loss=38.2960, \n",
            "Epoch 119/6000: train_loss=45.6788, val_loss=38.7075, \n",
            "Epoch 120/6000: train_loss=45.4708, val_loss=38.3163, \n",
            "Epoch 121/6000: train_loss=45.2403, val_loss=37.4140, \n",
            "Epoch 122/6000: train_loss=45.0929, val_loss=36.6800, \n",
            "Epoch 123/6000: train_loss=44.9484, val_loss=36.3580, \n",
            "Epoch 124/6000: train_loss=44.7383, val_loss=36.6394, \n",
            "Epoch 125/6000: train_loss=44.5969, val_loss=37.3808, \n",
            "Epoch 126/6000: train_loss=44.4431, val_loss=37.3954, \n",
            "Epoch 127/6000: train_loss=44.2405, val_loss=36.8398, \n",
            "Epoch 128/6000: train_loss=44.0667, val_loss=36.5848, \n",
            "Epoch 129/6000: train_loss=43.9077, val_loss=36.0787, \n",
            "Epoch 130/6000: train_loss=43.7456, val_loss=35.9979, \n",
            "Epoch 131/6000: train_loss=43.5793, val_loss=36.2263, \n",
            "Epoch 132/6000: train_loss=43.4311, val_loss=36.4171, \n",
            "Epoch 133/6000: train_loss=43.2666, val_loss=36.0141, \n",
            "Epoch 134/6000: train_loss=43.1163, val_loss=35.7518, \n",
            "Epoch 135/6000: train_loss=42.9660, val_loss=35.9041, \n",
            "Epoch 136/6000: train_loss=42.8207, val_loss=35.9145, \n",
            "Epoch 137/6000: train_loss=42.6705, val_loss=35.6190, \n",
            "Epoch 138/6000: train_loss=42.5343, val_loss=35.1486, \n",
            "Epoch 139/6000: train_loss=42.4277, val_loss=34.6754, \n",
            "Epoch 140/6000: train_loss=42.2583, val_loss=34.8276, \n",
            "Epoch 141/6000: train_loss=42.1102, val_loss=35.0932, \n",
            "Epoch 142/6000: train_loss=41.9959, val_loss=35.4317, \n",
            "Epoch 143/6000: train_loss=41.8530, val_loss=35.1951, \n",
            "Epoch 144/6000: train_loss=41.7116, val_loss=34.8059, \n",
            "Epoch 145/6000: train_loss=41.5921, val_loss=34.3862, \n",
            "Epoch 146/6000: train_loss=41.4920, val_loss=34.0574, \n",
            "Epoch 147/6000: train_loss=41.3385, val_loss=34.2973, \n",
            "Epoch 148/6000: train_loss=41.2141, val_loss=34.7710, \n",
            "Epoch 149/6000: train_loss=41.0942, val_loss=34.7448, \n",
            "Epoch 150/6000: train_loss=40.9691, val_loss=34.6056, \n",
            "Epoch 151/6000: train_loss=40.8398, val_loss=34.1409, \n",
            "Epoch 152/6000: train_loss=40.7500, val_loss=33.6027, \n",
            "Epoch 153/6000: train_loss=40.6014, val_loss=33.8605, \n",
            "Epoch 154/6000: train_loss=40.4825, val_loss=33.7360, \n",
            "Epoch 155/6000: train_loss=40.3603, val_loss=33.7405, \n",
            "Epoch 156/6000: train_loss=40.2448, val_loss=33.8926, \n",
            "Epoch 157/6000: train_loss=40.2097, val_loss=34.6899, \n",
            "Epoch 158/6000: train_loss=40.0311, val_loss=34.1152, \n",
            "Epoch 159/6000: train_loss=39.9016, val_loss=33.3884, \n",
            "Epoch 160/6000: train_loss=39.7895, val_loss=33.2688, \n",
            "Epoch 161/6000: train_loss=39.6778, val_loss=33.2456, \n",
            "Epoch 162/6000: train_loss=39.5685, val_loss=33.5476, \n",
            "Epoch 163/6000: train_loss=39.4916, val_loss=33.9099, \n",
            "Epoch 164/6000: train_loss=39.3572, val_loss=33.2505, \n",
            "Epoch 165/6000: train_loss=39.3031, val_loss=32.5712, \n",
            "Epoch 166/6000: train_loss=39.2147, val_loss=32.4359, \n",
            "Epoch 167/6000: train_loss=39.0553, val_loss=32.9952, \n",
            "Epoch 168/6000: train_loss=38.9976, val_loss=33.6117, \n",
            "Epoch 169/6000: train_loss=38.9293, val_loss=33.7991, \n",
            "Epoch 170/6000: train_loss=38.7911, val_loss=33.4647, \n",
            "Epoch 171/6000: train_loss=38.6986, val_loss=32.2327, \n",
            "Epoch 172/6000: train_loss=38.6699, val_loss=31.8444, \n",
            "Epoch 173/6000: train_loss=38.5427, val_loss=31.9055, \n",
            "Epoch 174/6000: train_loss=38.3711, val_loss=32.5426, \n",
            "Epoch 175/6000: train_loss=38.3366, val_loss=33.3983, \n",
            "Epoch 176/6000: train_loss=38.2047, val_loss=33.0137, \n",
            "Epoch 177/6000: train_loss=38.0897, val_loss=32.5209, \n",
            "Epoch 178/6000: train_loss=38.0484, val_loss=31.7687, \n",
            "Epoch 179/6000: train_loss=37.9131, val_loss=32.0820, \n",
            "Epoch 180/6000: train_loss=37.8114, val_loss=32.4031, \n",
            "Epoch 181/6000: train_loss=37.7303, val_loss=32.5386, \n",
            "Epoch 182/6000: train_loss=37.6301, val_loss=32.0835, \n",
            "Epoch 183/6000: train_loss=37.5425, val_loss=31.8526, \n",
            "Epoch 184/6000: train_loss=37.4696, val_loss=32.4079, \n",
            "Epoch 185/6000: train_loss=37.3747, val_loss=32.2452, \n",
            "Epoch 186/6000: train_loss=37.2732, val_loss=31.9481, \n",
            "Epoch 187/6000: train_loss=37.1834, val_loss=31.8566, \n",
            "Epoch 188/6000: train_loss=37.0982, val_loss=31.6056, \n",
            "Epoch 189/6000: train_loss=37.0133, val_loss=31.8194, \n",
            "Epoch 190/6000: train_loss=36.9309, val_loss=31.8677, \n",
            "Epoch 191/6000: train_loss=36.8717, val_loss=31.0042, \n",
            "Epoch 192/6000: train_loss=36.7833, val_loss=30.9756, \n",
            "Epoch 193/6000: train_loss=36.6773, val_loss=31.4636, \n",
            "Epoch 194/6000: train_loss=36.6118, val_loss=31.7290, \n",
            "Epoch 195/6000: train_loss=36.5525, val_loss=31.8563, \n",
            "Epoch 196/6000: train_loss=36.4409, val_loss=31.3502, \n",
            "Epoch 197/6000: train_loss=36.3938, val_loss=30.7362, \n",
            "Epoch 198/6000: train_loss=36.3835, val_loss=30.3857, \n",
            "Epoch 199/6000: train_loss=36.2274, val_loss=30.8212, \n",
            "Epoch 200/6000: train_loss=36.1921, val_loss=31.8394, \n",
            "Epoch 201/6000: train_loss=36.1595, val_loss=32.0010, \n",
            "Epoch 202/6000: train_loss=36.0160, val_loss=31.4379, \n",
            "Epoch 203/6000: train_loss=35.9393, val_loss=30.5226, \n",
            "Epoch 204/6000: train_loss=35.8802, val_loss=30.3674, \n",
            "Epoch 205/6000: train_loss=35.7828, val_loss=30.8206, \n",
            "Epoch 206/6000: train_loss=35.7970, val_loss=31.6133, \n",
            "Epoch 207/6000: train_loss=35.6858, val_loss=31.2450, \n",
            "Epoch 208/6000: train_loss=35.5798, val_loss=30.5205, \n",
            "Epoch 209/6000: train_loss=35.5220, val_loss=30.3378, \n",
            "Epoch 210/6000: train_loss=35.4577, val_loss=30.3413, \n",
            "Epoch 211/6000: train_loss=35.3882, val_loss=30.7697, \n",
            "Epoch 212/6000: train_loss=35.3188, val_loss=30.4142, \n",
            "Epoch 213/6000: train_loss=35.2612, val_loss=30.6685, \n",
            "Epoch 214/6000: train_loss=35.2009, val_loss=30.6460, \n",
            "Epoch 215/6000: train_loss=35.1392, val_loss=30.5874, \n",
            "Epoch 216/6000: train_loss=35.1015, val_loss=29.7024, \n",
            "Epoch 217/6000: train_loss=35.0769, val_loss=29.4459, \n",
            "Epoch 218/6000: train_loss=34.9419, val_loss=30.0716, \n",
            "Epoch 219/6000: train_loss=34.9239, val_loss=30.6663, \n",
            "Epoch 220/6000: train_loss=34.8222, val_loss=30.1124, \n",
            "Epoch 221/6000: train_loss=34.7663, val_loss=29.7389, \n",
            "Epoch 222/6000: train_loss=34.7097, val_loss=29.6792, \n",
            "Epoch 223/6000: train_loss=34.6788, val_loss=29.4362, \n",
            "Epoch 224/6000: train_loss=34.6032, val_loss=30.2644, \n",
            "Epoch 225/6000: train_loss=34.5706, val_loss=30.4601, \n",
            "Epoch 226/6000: train_loss=34.4732, val_loss=29.7547, \n",
            "Epoch 227/6000: train_loss=34.4646, val_loss=29.2346, \n",
            "Epoch 228/6000: train_loss=34.3600, val_loss=29.7583, \n",
            "Epoch 229/6000: train_loss=34.3052, val_loss=29.7042, \n",
            "Epoch 230/6000: train_loss=34.2608, val_loss=29.9439, \n",
            "Epoch 231/6000: train_loss=34.2076, val_loss=29.9433, \n",
            "Epoch 232/6000: train_loss=34.1736, val_loss=29.0983, \n",
            "Epoch 233/6000: train_loss=34.1052, val_loss=29.1594, \n",
            "Epoch 234/6000: train_loss=34.0336, val_loss=29.5266, \n",
            "Epoch 235/6000: train_loss=33.9816, val_loss=29.3336, \n",
            "Epoch 236/6000: train_loss=33.9315, val_loss=29.2397, \n",
            "Epoch 237/6000: train_loss=33.8916, val_loss=29.7422, \n",
            "Epoch 238/6000: train_loss=33.8464, val_loss=29.8073, \n",
            "Epoch 239/6000: train_loss=33.7803, val_loss=29.4662, \n",
            "Epoch 240/6000: train_loss=33.7364, val_loss=29.0436, \n",
            "Epoch 241/6000: train_loss=33.6918, val_loss=28.9427, \n",
            "Epoch 242/6000: train_loss=33.6576, val_loss=29.5836, \n",
            "Epoch 243/6000: train_loss=33.5912, val_loss=29.3510, \n",
            "Epoch 244/6000: train_loss=33.5702, val_loss=28.6925, \n",
            "Epoch 245/6000: train_loss=33.4854, val_loss=29.1499, \n",
            "Epoch 246/6000: train_loss=33.4436, val_loss=29.4233, \n",
            "Epoch 247/6000: train_loss=33.4051, val_loss=29.5184, \n",
            "Epoch 248/6000: train_loss=33.3581, val_loss=28.8108, \n",
            "Epoch 249/6000: train_loss=33.3650, val_loss=28.4456, \n",
            "Epoch 250/6000: train_loss=33.3173, val_loss=28.4035, \n",
            "Epoch 251/6000: train_loss=33.2177, val_loss=29.0675, \n",
            "Epoch 252/6000: train_loss=33.1982, val_loss=29.3797, \n",
            "Epoch 253/6000: train_loss=33.1487, val_loss=29.3420, \n",
            "Epoch 254/6000: train_loss=33.0857, val_loss=28.9281, \n",
            "Epoch 255/6000: train_loss=33.0491, val_loss=28.8356, \n",
            "Epoch 256/6000: train_loss=33.0178, val_loss=28.7098, \n",
            "Epoch 257/6000: train_loss=32.9746, val_loss=28.8499, \n",
            "Epoch 258/6000: train_loss=32.9597, val_loss=29.4152, \n",
            "Epoch 259/6000: train_loss=32.8966, val_loss=29.0244, \n",
            "Epoch 260/6000: train_loss=32.8671, val_loss=28.5615, \n",
            "Epoch 261/6000: train_loss=32.8586, val_loss=28.3060, \n",
            "Epoch 262/6000: train_loss=32.8067, val_loss=28.3089, \n",
            "Epoch 263/6000: train_loss=32.7510, val_loss=28.4493, \n",
            "Epoch 264/6000: train_loss=32.7215, val_loss=28.8490, \n",
            "Epoch 265/6000: train_loss=32.6818, val_loss=28.7102, \n",
            "Epoch 266/6000: train_loss=32.6432, val_loss=28.3519, \n",
            "Epoch 267/6000: train_loss=32.6106, val_loss=28.3036, \n",
            "Epoch 268/6000: train_loss=32.5724, val_loss=28.3585, \n",
            "Epoch 269/6000: train_loss=32.5368, val_loss=28.4053, \n",
            "Epoch 270/6000: train_loss=32.5111, val_loss=28.8645, \n",
            "Epoch 271/6000: train_loss=32.4907, val_loss=28.9565, \n",
            "Epoch 272/6000: train_loss=32.4352, val_loss=28.6094, \n",
            "Epoch 273/6000: train_loss=32.4050, val_loss=28.2992, \n",
            "Epoch 274/6000: train_loss=32.3849, val_loss=28.1317, \n",
            "Epoch 275/6000: train_loss=32.3388, val_loss=28.2678, \n",
            "Epoch 276/6000: train_loss=32.3358, val_loss=28.9609, \n",
            "Epoch 277/6000: train_loss=32.2767, val_loss=28.6906, \n",
            "Epoch 278/6000: train_loss=32.2661, val_loss=27.9729, \n",
            "Epoch 279/6000: train_loss=32.2380, val_loss=27.9137, \n",
            "Epoch 280/6000: train_loss=32.1718, val_loss=28.3131, \n",
            "Epoch 281/6000: train_loss=32.1987, val_loss=28.9799, \n",
            "Epoch 282/6000: train_loss=32.3021, val_loss=29.5938, \n",
            "Epoch 283/6000: train_loss=32.0834, val_loss=28.2256, \n",
            "Epoch 284/6000: train_loss=32.1879, val_loss=27.5070, \n",
            "Epoch 285/6000: train_loss=32.0865, val_loss=27.6774, \n",
            "Epoch 286/6000: train_loss=32.0136, val_loss=28.6092, \n",
            "Epoch 287/6000: train_loss=31.9758, val_loss=28.4762, \n",
            "Epoch 288/6000: train_loss=31.9342, val_loss=28.0862, \n",
            "Epoch 289/6000: train_loss=31.9432, val_loss=27.6867, \n",
            "Epoch 290/6000: train_loss=31.8925, val_loss=28.4030, \n",
            "Epoch 291/6000: train_loss=31.9428, val_loss=28.9659, \n",
            "Epoch 292/6000: train_loss=31.8189, val_loss=27.9326, \n",
            "Epoch 293/6000: train_loss=31.8580, val_loss=27.6212, \n",
            "Epoch 294/6000: train_loss=31.8156, val_loss=27.7566, \n",
            "Epoch 295/6000: train_loss=31.7306, val_loss=28.2312, \n",
            "Epoch 296/6000: train_loss=31.8720, val_loss=29.4097, \n",
            "Epoch 297/6000: train_loss=31.7300, val_loss=28.8493, \n",
            "Epoch 298/6000: train_loss=31.6485, val_loss=27.9092, \n",
            "Epoch 299/6000: train_loss=31.6606, val_loss=27.5716, \n",
            "Epoch 300/6000: train_loss=31.7339, val_loss=27.1990, \n",
            "Epoch 301/6000: train_loss=31.5739, val_loss=28.2652, \n",
            "Epoch 302/6000: train_loss=31.5563, val_loss=28.3229, \n",
            "Epoch 303/6000: train_loss=31.5192, val_loss=27.7091, \n",
            "Epoch 304/6000: train_loss=31.4900, val_loss=27.7329, \n",
            "Epoch 305/6000: train_loss=31.4606, val_loss=27.7595, \n",
            "Epoch 306/6000: train_loss=31.4318, val_loss=27.8836, \n",
            "Epoch 307/6000: train_loss=31.4319, val_loss=28.4357, \n",
            "Epoch 308/6000: train_loss=31.4293, val_loss=28.5627, \n",
            "Epoch 309/6000: train_loss=31.3684, val_loss=28.2684, \n",
            "Epoch 310/6000: train_loss=31.3337, val_loss=27.8048, \n",
            "Epoch 311/6000: train_loss=31.3812, val_loss=27.3283, \n",
            "Epoch 312/6000: train_loss=31.2897, val_loss=27.6199, \n",
            "Epoch 313/6000: train_loss=31.2635, val_loss=28.2109, \n",
            "Epoch 314/6000: train_loss=31.2922, val_loss=28.5544, \n",
            "Epoch 315/6000: train_loss=31.2344, val_loss=27.3892, \n",
            "Epoch 316/6000: train_loss=31.2823, val_loss=27.0499, \n",
            "Epoch 317/6000: train_loss=31.1515, val_loss=27.6415, \n",
            "Epoch 318/6000: train_loss=31.1509, val_loss=28.1051, \n",
            "Epoch 319/6000: train_loss=31.1451, val_loss=28.2319, \n",
            "Epoch 320/6000: train_loss=31.0761, val_loss=27.7292, \n",
            "Epoch 321/6000: train_loss=31.0524, val_loss=27.7214, \n",
            "Epoch 322/6000: train_loss=31.0309, val_loss=27.5921, \n",
            "Epoch 323/6000: train_loss=31.0078, val_loss=27.5716, \n",
            "Epoch 324/6000: train_loss=30.9870, val_loss=28.0015, \n",
            "Epoch 325/6000: train_loss=30.9722, val_loss=27.4488, \n",
            "Epoch 326/6000: train_loss=31.0258, val_loss=27.0531, \n",
            "Epoch 327/6000: train_loss=30.9382, val_loss=27.2842, \n",
            "Epoch 328/6000: train_loss=30.9482, val_loss=28.2521, \n",
            "Epoch 329/6000: train_loss=30.9117, val_loss=28.1273, \n",
            "Epoch 330/6000: train_loss=30.8640, val_loss=27.2129, \n",
            "Epoch 331/6000: train_loss=30.8885, val_loss=26.9898, \n",
            "Epoch 332/6000: train_loss=30.7912, val_loss=27.5420, \n",
            "Epoch 333/6000: train_loss=30.7774, val_loss=27.8553, \n",
            "Epoch 334/6000: train_loss=30.7673, val_loss=27.9990, \n",
            "Epoch 335/6000: train_loss=30.7892, val_loss=28.3056, \n",
            "Epoch 336/6000: train_loss=30.7012, val_loss=27.5259, \n",
            "Epoch 337/6000: train_loss=30.6909, val_loss=27.1430, \n",
            "Epoch 338/6000: train_loss=30.6567, val_loss=27.3330, \n",
            "Epoch 339/6000: train_loss=30.7051, val_loss=27.9744, \n",
            "Epoch 340/6000: train_loss=30.6247, val_loss=27.5748, \n",
            "Epoch 341/6000: train_loss=30.7208, val_loss=26.6523, \n",
            "Epoch 342/6000: train_loss=30.5721, val_loss=27.2403, \n",
            "Epoch 343/6000: train_loss=30.5875, val_loss=27.9542, \n",
            "Epoch 344/6000: train_loss=30.5864, val_loss=28.0776, \n",
            "Epoch 345/6000: train_loss=30.5031, val_loss=27.5497, \n",
            "Epoch 346/6000: train_loss=30.4737, val_loss=27.2019, \n",
            "Epoch 347/6000: train_loss=30.4487, val_loss=27.1255, \n",
            "Epoch 348/6000: train_loss=30.4150, val_loss=27.1686, \n",
            "Epoch 349/6000: train_loss=30.4410, val_loss=27.8721, \n",
            "Epoch 350/6000: train_loss=30.3464, val_loss=27.5137, \n",
            "Epoch 351/6000: train_loss=30.2659, val_loss=26.4375, \n",
            "Epoch 352/6000: train_loss=30.3291, val_loss=26.4675, \n",
            "Epoch 353/6000: train_loss=30.1975, val_loss=27.5528, \n",
            "Epoch 354/6000: train_loss=30.2355, val_loss=27.9071, \n",
            "Epoch 355/6000: train_loss=30.0972, val_loss=26.6653, \n",
            "Epoch 356/6000: train_loss=30.1066, val_loss=26.5520, \n",
            "Epoch 357/6000: train_loss=30.0018, val_loss=27.0865, \n",
            "Epoch 358/6000: train_loss=29.9678, val_loss=27.2014, \n",
            "Epoch 359/6000: train_loss=29.9864, val_loss=26.3247, \n",
            "Epoch 360/6000: train_loss=29.8802, val_loss=26.5222, \n",
            "Epoch 361/6000: train_loss=29.8434, val_loss=26.9455, \n",
            "Epoch 362/6000: train_loss=29.7985, val_loss=26.8583, \n",
            "Epoch 363/6000: train_loss=29.7597, val_loss=26.2555, \n",
            "Epoch 364/6000: train_loss=29.7089, val_loss=26.3227, \n",
            "Epoch 365/6000: train_loss=29.6463, val_loss=26.8007, \n",
            "Epoch 366/6000: train_loss=29.5943, val_loss=26.7698, \n",
            "Epoch 367/6000: train_loss=29.5452, val_loss=26.4841, \n",
            "Epoch 368/6000: train_loss=29.5307, val_loss=26.8768, \n",
            "Epoch 369/6000: train_loss=29.4482, val_loss=26.6360, \n",
            "Epoch 370/6000: train_loss=29.4610, val_loss=25.9156, \n",
            "Epoch 371/6000: train_loss=29.3650, val_loss=26.0205, \n",
            "Epoch 372/6000: train_loss=29.3508, val_loss=26.8723, \n",
            "Epoch 373/6000: train_loss=29.2517, val_loss=26.5785, \n",
            "Epoch 374/6000: train_loss=29.2108, val_loss=26.0939, \n",
            "Epoch 375/6000: train_loss=29.1339, val_loss=26.4289, \n",
            "Epoch 376/6000: train_loss=29.1102, val_loss=26.5399, \n",
            "Epoch 377/6000: train_loss=29.0459, val_loss=26.4602, \n",
            "Epoch 378/6000: train_loss=29.0159, val_loss=25.6954, \n",
            "Epoch 379/6000: train_loss=28.9940, val_loss=25.4123, \n",
            "Epoch 380/6000: train_loss=28.8808, val_loss=26.1119, \n",
            "Epoch 381/6000: train_loss=28.8522, val_loss=26.3455, \n",
            "Epoch 382/6000: train_loss=28.7492, val_loss=25.8808, \n",
            "Epoch 383/6000: train_loss=28.7129, val_loss=25.9996, \n",
            "Epoch 384/6000: train_loss=28.6503, val_loss=26.0699, \n",
            "Epoch 385/6000: train_loss=28.5718, val_loss=25.9735, \n",
            "Epoch 386/6000: train_loss=28.5383, val_loss=26.0784, \n",
            "Epoch 387/6000: train_loss=28.5238, val_loss=25.1560, \n",
            "Epoch 388/6000: train_loss=28.4238, val_loss=25.2155, \n",
            "Epoch 389/6000: train_loss=28.5879, val_loss=26.6566, \n",
            "Epoch 390/6000: train_loss=28.2864, val_loss=25.3775, \n",
            "Epoch 391/6000: train_loss=28.2528, val_loss=25.2374, \n",
            "Epoch 392/6000: train_loss=28.1853, val_loss=25.7383, \n",
            "Epoch 393/6000: train_loss=28.1222, val_loss=25.3612, \n",
            "Epoch 394/6000: train_loss=28.0640, val_loss=25.5819, \n",
            "Epoch 395/6000: train_loss=28.0528, val_loss=24.9506, \n",
            "Epoch 396/6000: train_loss=28.0156, val_loss=24.8497, \n",
            "Epoch 397/6000: train_loss=27.9355, val_loss=25.6768, \n",
            "Epoch 398/6000: train_loss=28.1367, val_loss=26.4963, \n",
            "Epoch 399/6000: train_loss=27.8659, val_loss=24.6152, \n",
            "Epoch 400/6000: train_loss=27.9761, val_loss=24.2978, \n",
            "Epoch 401/6000: train_loss=27.8581, val_loss=26.1362, \n",
            "Epoch 402/6000: train_loss=27.8139, val_loss=26.1582, \n",
            "Epoch 403/6000: train_loss=27.5691, val_loss=24.8098, \n",
            "Epoch 404/6000: train_loss=27.5987, val_loss=24.4850, \n",
            "Epoch 405/6000: train_loss=27.4613, val_loss=25.2356, \n",
            "Epoch 406/6000: train_loss=27.4521, val_loss=25.4719, \n",
            "Epoch 407/6000: train_loss=27.3633, val_loss=24.5399, \n",
            "Epoch 408/6000: train_loss=27.3708, val_loss=24.2278, \n",
            "Epoch 409/6000: train_loss=27.3201, val_loss=25.4931, \n",
            "Epoch 410/6000: train_loss=27.1993, val_loss=25.1539, \n",
            "Epoch 411/6000: train_loss=27.1799, val_loss=24.2034, \n",
            "Epoch 412/6000: train_loss=27.2664, val_loss=23.9237, \n",
            "Epoch 413/6000: train_loss=27.0236, val_loss=24.9888, \n",
            "Epoch 414/6000: train_loss=26.9534, val_loss=24.5068, \n",
            "Epoch 415/6000: train_loss=26.9202, val_loss=24.1802, \n",
            "Epoch 416/6000: train_loss=26.8606, val_loss=24.6972, \n",
            "Epoch 417/6000: train_loss=26.7789, val_loss=24.3728, \n",
            "Epoch 418/6000: train_loss=26.8325, val_loss=23.6833, \n",
            "Epoch 419/6000: train_loss=26.6685, val_loss=24.1517, \n",
            "Epoch 420/6000: train_loss=26.6940, val_loss=24.9983, \n",
            "Epoch 421/6000: train_loss=26.5785, val_loss=24.0757, \n",
            "Epoch 422/6000: train_loss=26.5691, val_loss=23.8603, \n",
            "Epoch 423/6000: train_loss=26.4747, val_loss=24.6739, \n",
            "Epoch 424/6000: train_loss=26.3800, val_loss=24.0366, \n",
            "Epoch 425/6000: train_loss=26.3783, val_loss=23.7250, \n",
            "Epoch 426/6000: train_loss=26.2783, val_loss=24.1769, \n",
            "Epoch 427/6000: train_loss=26.2378, val_loss=24.2827, \n",
            "Epoch 428/6000: train_loss=26.1564, val_loss=23.7545, \n",
            "Epoch 429/6000: train_loss=26.1142, val_loss=24.0170, \n",
            "Epoch 430/6000: train_loss=26.0929, val_loss=24.2133, \n",
            "Epoch 431/6000: train_loss=26.0076, val_loss=24.1464, \n",
            "Epoch 432/6000: train_loss=25.9811, val_loss=23.4990, \n",
            "Epoch 433/6000: train_loss=25.9481, val_loss=23.5350, \n",
            "Epoch 434/6000: train_loss=26.0789, val_loss=25.0580, \n",
            "Epoch 435/6000: train_loss=25.8016, val_loss=24.1215, \n",
            "Epoch 436/6000: train_loss=26.1434, val_loss=22.7379, \n",
            "Epoch 437/6000: train_loss=25.7201, val_loss=23.2433, \n",
            "Epoch 438/6000: train_loss=26.1275, val_loss=25.3399, \n",
            "Epoch 439/6000: train_loss=25.5929, val_loss=23.9462, \n",
            "Epoch 440/6000: train_loss=25.7029, val_loss=22.8417, \n",
            "Epoch 441/6000: train_loss=25.4848, val_loss=23.2419, \n",
            "Epoch 442/6000: train_loss=25.6895, val_loss=24.6075, \n",
            "Epoch 443/6000: train_loss=25.3957, val_loss=22.8561, \n",
            "Epoch 444/6000: train_loss=25.5387, val_loss=22.5171, \n",
            "Epoch 445/6000: train_loss=25.2469, val_loss=23.3969, \n",
            "Epoch 446/6000: train_loss=25.2607, val_loss=23.9457, \n",
            "Epoch 447/6000: train_loss=25.1268, val_loss=23.2697, \n",
            "Epoch 448/6000: train_loss=25.0934, val_loss=23.0253, \n",
            "Epoch 449/6000: train_loss=25.0349, val_loss=23.2132, \n",
            "Epoch 450/6000: train_loss=25.0511, val_loss=23.7205, \n",
            "Epoch 451/6000: train_loss=24.9253, val_loss=22.9087, \n",
            "Epoch 452/6000: train_loss=24.9114, val_loss=22.6960, \n",
            "Epoch 453/6000: train_loss=24.8256, val_loss=23.0287, \n",
            "Epoch 454/6000: train_loss=24.7664, val_loss=22.7442, \n",
            "Epoch 455/6000: train_loss=24.7409, val_loss=22.5694, \n",
            "Epoch 456/6000: train_loss=24.6917, val_loss=23.1760, \n",
            "Epoch 457/6000: train_loss=24.6355, val_loss=23.1559, \n",
            "Epoch 458/6000: train_loss=24.5882, val_loss=22.5141, \n",
            "Epoch 459/6000: train_loss=24.5252, val_loss=23.1428, \n",
            "Epoch 460/6000: train_loss=24.4674, val_loss=22.9670, \n",
            "Epoch 461/6000: train_loss=24.4456, val_loss=22.3453, \n",
            "Epoch 462/6000: train_loss=24.3811, val_loss=22.4091, \n",
            "Epoch 463/6000: train_loss=24.3254, val_loss=22.9850, \n",
            "Epoch 464/6000: train_loss=24.2481, val_loss=22.7654, \n",
            "Epoch 465/6000: train_loss=24.2447, val_loss=22.3959, \n",
            "Epoch 466/6000: train_loss=24.1663, val_loss=22.6984, \n",
            "Epoch 467/6000: train_loss=24.2628, val_loss=23.5229, \n",
            "Epoch 468/6000: train_loss=24.0448, val_loss=22.6322, \n",
            "Epoch 469/6000: train_loss=24.0788, val_loss=21.8925, \n",
            "Epoch 470/6000: train_loss=23.9597, val_loss=22.3051, \n",
            "Epoch 471/6000: train_loss=23.9218, val_loss=22.5882, \n",
            "Epoch 472/6000: train_loss=23.8393, val_loss=22.1636, \n",
            "Epoch 473/6000: train_loss=23.9098, val_loss=21.8105, \n",
            "Epoch 474/6000: train_loss=23.7390, val_loss=22.4475, \n",
            "Epoch 475/6000: train_loss=24.0094, val_loss=23.6633, \n",
            "Epoch 476/6000: train_loss=23.6765, val_loss=21.9430, \n",
            "Epoch 477/6000: train_loss=23.5990, val_loss=21.9224, \n",
            "Epoch 478/6000: train_loss=23.5869, val_loss=22.4820, \n",
            "Epoch 479/6000: train_loss=23.5772, val_loss=21.4743, \n",
            "Epoch 480/6000: train_loss=23.4407, val_loss=21.8420, \n",
            "Epoch 481/6000: train_loss=23.5998, val_loss=22.9713, \n",
            "Epoch 482/6000: train_loss=23.3892, val_loss=22.3996, \n",
            "Epoch 483/6000: train_loss=23.3829, val_loss=21.4617, \n",
            "Epoch 484/6000: train_loss=23.2599, val_loss=22.1588, \n",
            "Epoch 485/6000: train_loss=23.1917, val_loss=21.9167, \n",
            "Epoch 486/6000: train_loss=23.1513, val_loss=22.0292, \n",
            "Epoch 487/6000: train_loss=23.0920, val_loss=21.8142, \n",
            "Epoch 488/6000: train_loss=23.0840, val_loss=21.4577, \n",
            "Epoch 489/6000: train_loss=22.9962, val_loss=21.8026, \n",
            "Epoch 490/6000: train_loss=22.9722, val_loss=21.9818, \n",
            "Epoch 491/6000: train_loss=22.9151, val_loss=21.4515, \n",
            "Epoch 492/6000: train_loss=22.8829, val_loss=21.2957, \n",
            "Epoch 493/6000: train_loss=22.8427, val_loss=21.8136, \n",
            "Epoch 494/6000: train_loss=22.9243, val_loss=22.3224, \n",
            "Epoch 495/6000: train_loss=22.7325, val_loss=21.3153, \n",
            "Epoch 496/6000: train_loss=22.6843, val_loss=21.4044, \n",
            "Epoch 497/6000: train_loss=22.6323, val_loss=21.7262, \n",
            "Epoch 498/6000: train_loss=22.6011, val_loss=21.2504, \n",
            "Epoch 499/6000: train_loss=22.5318, val_loss=21.2423, \n",
            "Epoch 500/6000: train_loss=22.4864, val_loss=21.3998, \n",
            "Epoch 501/6000: train_loss=22.4384, val_loss=21.2387, \n",
            "Epoch 502/6000: train_loss=22.4539, val_loss=20.7306, \n",
            "Epoch 503/6000: train_loss=22.3493, val_loss=21.1050, \n",
            "Epoch 504/6000: train_loss=22.4059, val_loss=21.8129, \n",
            "Epoch 505/6000: train_loss=22.2778, val_loss=20.9306, \n",
            "Epoch 506/6000: train_loss=22.3482, val_loss=20.6353, \n",
            "Epoch 507/6000: train_loss=22.2009, val_loss=21.4848, \n",
            "Epoch 508/6000: train_loss=22.1432, val_loss=21.3299, \n",
            "Epoch 509/6000: train_loss=22.1263, val_loss=20.5873, \n",
            "Epoch 510/6000: train_loss=22.1074, val_loss=20.4183, \n",
            "Epoch 511/6000: train_loss=22.1424, val_loss=21.6637, \n",
            "Epoch 512/6000: train_loss=21.9794, val_loss=21.2604, \n",
            "Epoch 513/6000: train_loss=22.0001, val_loss=20.3655, \n",
            "Epoch 514/6000: train_loss=21.8721, val_loss=21.1689, \n",
            "Epoch 515/6000: train_loss=21.9408, val_loss=21.6211, \n",
            "Epoch 516/6000: train_loss=21.8848, val_loss=20.3176, \n",
            "Epoch 517/6000: train_loss=21.7175, val_loss=20.7344, \n",
            "Epoch 518/6000: train_loss=21.7039, val_loss=21.1823, \n",
            "Epoch 519/6000: train_loss=21.6711, val_loss=20.3552, \n",
            "Epoch 520/6000: train_loss=21.5912, val_loss=20.4996, \n",
            "Epoch 521/6000: train_loss=21.6203, val_loss=21.3253, \n",
            "Epoch 522/6000: train_loss=21.4877, val_loss=20.8299, \n",
            "Epoch 523/6000: train_loss=21.5713, val_loss=20.2850, \n",
            "Epoch 524/6000: train_loss=21.4069, val_loss=20.8446, \n",
            "Epoch 525/6000: train_loss=21.5708, val_loss=21.6196, \n",
            "Epoch 526/6000: train_loss=21.3918, val_loss=20.1138, \n",
            "Epoch 527/6000: train_loss=21.3195, val_loss=20.1047, \n",
            "Epoch 528/6000: train_loss=21.5282, val_loss=21.5447, \n",
            "Epoch 529/6000: train_loss=21.3019, val_loss=20.9341, \n",
            "Epoch 530/6000: train_loss=21.7952, val_loss=19.4105, \n",
            "Epoch 531/6000: train_loss=21.2667, val_loss=19.7275, \n",
            "Epoch 532/6000: train_loss=22.0619, val_loss=22.9005, \n",
            "Epoch 533/6000: train_loss=21.0251, val_loss=20.3264, \n",
            "Epoch 534/6000: train_loss=22.1481, val_loss=19.3618, \n",
            "Epoch 535/6000: train_loss=20.9717, val_loss=20.6603, \n",
            "Epoch 536/6000: train_loss=21.1869, val_loss=21.4764, \n",
            "Epoch 537/6000: train_loss=20.9061, val_loss=19.8122, \n",
            "Epoch 538/6000: train_loss=20.9870, val_loss=19.4815, \n",
            "Epoch 539/6000: train_loss=20.8003, val_loss=20.2812, \n",
            "Epoch 540/6000: train_loss=20.7814, val_loss=20.4508, \n",
            "Epoch 541/6000: train_loss=20.7124, val_loss=20.1000, \n",
            "Epoch 542/6000: train_loss=20.7469, val_loss=19.7036, \n",
            "Epoch 543/6000: train_loss=20.6427, val_loss=20.3922, \n",
            "Epoch 544/6000: train_loss=20.8366, val_loss=21.2036, \n",
            "Epoch 545/6000: train_loss=20.5621, val_loss=19.8964, \n",
            "Epoch 546/6000: train_loss=20.5834, val_loss=19.5737, \n",
            "Epoch 547/6000: train_loss=20.5367, val_loss=20.4111, \n",
            "Epoch 548/6000: train_loss=20.4583, val_loss=20.1718, \n",
            "Epoch 549/6000: train_loss=20.4850, val_loss=19.4123, \n",
            "Epoch 550/6000: train_loss=20.3591, val_loss=19.8327, \n",
            "Epoch 551/6000: train_loss=20.3340, val_loss=19.9911, \n",
            "Epoch 552/6000: train_loss=20.3798, val_loss=20.4056, \n",
            "Epoch 553/6000: train_loss=20.3094, val_loss=19.5102, \n",
            "Epoch 554/6000: train_loss=20.2322, val_loss=19.7215, \n",
            "Epoch 555/6000: train_loss=20.1892, val_loss=20.0252, \n",
            "Epoch 556/6000: train_loss=20.1520, val_loss=19.9531, \n",
            "Epoch 557/6000: train_loss=20.2052, val_loss=19.3485, \n",
            "Epoch 558/6000: train_loss=20.0730, val_loss=19.8060, \n",
            "Epoch 559/6000: train_loss=20.1029, val_loss=20.1543, \n",
            "Epoch 560/6000: train_loss=20.0918, val_loss=19.1074, \n",
            "Epoch 561/6000: train_loss=20.0312, val_loss=19.1706, \n",
            "Epoch 562/6000: train_loss=20.0377, val_loss=20.1133, \n",
            "Epoch 563/6000: train_loss=19.9044, val_loss=19.4805, \n",
            "Epoch 564/6000: train_loss=19.9115, val_loss=19.3690, \n",
            "Epoch 565/6000: train_loss=19.8711, val_loss=19.4741, \n",
            "Epoch 566/6000: train_loss=19.8985, val_loss=19.2688, \n",
            "Epoch 567/6000: train_loss=20.0560, val_loss=20.7904, \n",
            "Epoch 568/6000: train_loss=19.7631, val_loss=19.8549, \n",
            "Epoch 569/6000: train_loss=19.9156, val_loss=18.7713, \n",
            "Epoch 570/6000: train_loss=19.6784, val_loss=19.5491, \n",
            "Epoch 571/6000: train_loss=19.7219, val_loss=19.9333, \n",
            "Epoch 572/6000: train_loss=19.5828, val_loss=19.2802, \n",
            "Epoch 573/6000: train_loss=19.7196, val_loss=18.9527, \n",
            "Epoch 574/6000: train_loss=19.6426, val_loss=20.2948, \n",
            "Epoch 575/6000: train_loss=19.4924, val_loss=19.7205, \n",
            "Epoch 576/6000: train_loss=19.6601, val_loss=18.7066, \n",
            "Epoch 577/6000: train_loss=19.4055, val_loss=19.4625, \n",
            "Epoch 578/6000: train_loss=19.4647, val_loss=19.9854, \n",
            "Epoch 579/6000: train_loss=19.3217, val_loss=19.3051, \n",
            "Epoch 580/6000: train_loss=19.4823, val_loss=18.8175, \n",
            "Epoch 581/6000: train_loss=19.2890, val_loss=19.6342, \n",
            "Epoch 582/6000: train_loss=19.3820, val_loss=20.0764, \n",
            "Epoch 583/6000: train_loss=19.3607, val_loss=18.5672, \n",
            "Epoch 584/6000: train_loss=19.1888, val_loss=18.9260, \n",
            "Epoch 585/6000: train_loss=19.3690, val_loss=20.1629, \n",
            "Epoch 586/6000: train_loss=19.0987, val_loss=19.2694, \n",
            "Epoch 587/6000: train_loss=19.2814, val_loss=18.6483, \n",
            "Epoch 588/6000: train_loss=19.1082, val_loss=19.8264, \n",
            "Epoch 589/6000: train_loss=19.0793, val_loss=19.7638, \n",
            "Epoch 590/6000: train_loss=19.0320, val_loss=18.8118, \n",
            "Epoch 591/6000: train_loss=18.9623, val_loss=18.9295, \n",
            "Epoch 592/6000: train_loss=18.9199, val_loss=19.3220, \n",
            "Epoch 593/6000: train_loss=19.0384, val_loss=19.9872, \n",
            "Epoch 594/6000: train_loss=19.1452, val_loss=18.3244, \n",
            "Epoch 595/6000: train_loss=18.8926, val_loss=18.5656, \n",
            "Epoch 596/6000: train_loss=18.8847, val_loss=19.5840, \n",
            "Epoch 597/6000: train_loss=18.9005, val_loss=19.7056, \n",
            "Epoch 598/6000: train_loss=18.9324, val_loss=18.3346, \n",
            "Epoch 599/6000: train_loss=18.7169, val_loss=18.7292, \n",
            "Epoch 600/6000: train_loss=18.9770, val_loss=20.2706, \n",
            "Epoch 601/6000: train_loss=18.8691, val_loss=18.5157, \n",
            "Epoch 602/6000: train_loss=18.6382, val_loss=18.9316, \n",
            "Epoch 603/6000: train_loss=18.7158, val_loss=19.8182, \n",
            "Epoch 604/6000: train_loss=18.6213, val_loss=18.4790, \n",
            "Epoch 605/6000: train_loss=18.6303, val_loss=18.3663, \n",
            "Epoch 606/6000: train_loss=18.5703, val_loss=19.4513, \n",
            "Epoch 607/6000: train_loss=18.4697, val_loss=18.7070, \n",
            "Epoch 608/6000: train_loss=18.4955, val_loss=18.6774, \n",
            "Epoch 609/6000: train_loss=18.4100, val_loss=18.8874, \n",
            "Epoch 610/6000: train_loss=18.4278, val_loss=19.3772, \n",
            "Epoch 611/6000: train_loss=18.3501, val_loss=18.7418, \n",
            "Epoch 612/6000: train_loss=18.3664, val_loss=18.4358, \n",
            "Epoch 613/6000: train_loss=18.2867, val_loss=18.7961, \n",
            "Epoch 614/6000: train_loss=18.3803, val_loss=19.5026, \n",
            "Epoch 615/6000: train_loss=18.2594, val_loss=18.5343, \n",
            "Epoch 616/6000: train_loss=18.3927, val_loss=18.1485, \n",
            "Epoch 617/6000: train_loss=18.3567, val_loss=19.4138, \n",
            "Epoch 618/6000: train_loss=18.1911, val_loss=18.8134, \n",
            "Epoch 619/6000: train_loss=18.1671, val_loss=18.3154, \n",
            "Epoch 620/6000: train_loss=18.1186, val_loss=19.0204, \n",
            "Epoch 621/6000: train_loss=18.1154, val_loss=19.1798, \n",
            "Epoch 622/6000: train_loss=18.1479, val_loss=18.3759, \n",
            "Epoch 623/6000: train_loss=18.0736, val_loss=18.4162, \n",
            "Epoch 624/6000: train_loss=18.0897, val_loss=19.2049, \n",
            "Epoch 625/6000: train_loss=18.0507, val_loss=18.0614, \n",
            "Epoch 626/6000: train_loss=18.0025, val_loss=18.7760, \n",
            "Epoch 627/6000: train_loss=17.9405, val_loss=18.2743, \n",
            "Epoch 628/6000: train_loss=17.9070, val_loss=18.5398, \n",
            "Epoch 629/6000: train_loss=17.8760, val_loss=18.6649, \n",
            "Epoch 630/6000: train_loss=17.8723, val_loss=18.8125, \n",
            "Epoch 631/6000: train_loss=17.8901, val_loss=18.4743, \n",
            "Epoch 632/6000: train_loss=17.8175, val_loss=18.7770, \n",
            "Epoch 633/6000: train_loss=17.8859, val_loss=19.0714, \n",
            "Epoch 634/6000: train_loss=17.8592, val_loss=17.9077, \n",
            "Epoch 635/6000: train_loss=17.8707, val_loss=17.8562, \n",
            "Epoch 636/6000: train_loss=17.9145, val_loss=19.4005, \n",
            "Epoch 637/6000: train_loss=17.6954, val_loss=18.3524, \n",
            "Epoch 638/6000: train_loss=17.7788, val_loss=18.1192, \n",
            "Epoch 639/6000: train_loss=17.7218, val_loss=19.0982, \n",
            "Epoch 640/6000: train_loss=17.6383, val_loss=18.7644, \n",
            "Epoch 641/6000: train_loss=17.7161, val_loss=17.8216, \n",
            "Epoch 642/6000: train_loss=17.5674, val_loss=18.3613, \n",
            "Epoch 643/6000: train_loss=17.6613, val_loss=19.0070, \n",
            "Epoch 644/6000: train_loss=17.5214, val_loss=18.3262, \n",
            "Epoch 645/6000: train_loss=17.5650, val_loss=18.0443, \n",
            "Epoch 646/6000: train_loss=17.4931, val_loss=18.7180, \n",
            "Epoch 647/6000: train_loss=17.4550, val_loss=18.3132, \n",
            "Epoch 648/6000: train_loss=17.4312, val_loss=18.3016, \n",
            "Epoch 649/6000: train_loss=17.4556, val_loss=17.9192, \n",
            "Epoch 650/6000: train_loss=17.4270, val_loss=18.6315, \n",
            "Epoch 651/6000: train_loss=17.3586, val_loss=18.2214, \n",
            "Epoch 652/6000: train_loss=17.4914, val_loss=17.9620, \n",
            "Epoch 653/6000: train_loss=17.4277, val_loss=19.1128, \n",
            "Epoch 654/6000: train_loss=17.4606, val_loss=19.1679, \n",
            "Epoch 655/6000: train_loss=17.3814, val_loss=17.7236, \n",
            "Epoch 656/6000: train_loss=17.2691, val_loss=17.9262, \n",
            "Epoch 657/6000: train_loss=17.3610, val_loss=18.6493, \n",
            "Epoch 658/6000: train_loss=17.2373, val_loss=18.0011, \n",
            "Epoch 659/6000: train_loss=17.2299, val_loss=18.0294, \n",
            "Epoch 660/6000: train_loss=17.2563, val_loss=18.9733, \n",
            "Epoch 661/6000: train_loss=17.1604, val_loss=18.2348, \n",
            "Epoch 662/6000: train_loss=17.6967, val_loss=17.4403, \n",
            "Epoch 663/6000: train_loss=17.3786, val_loss=19.2071, \n",
            "Epoch 664/6000: train_loss=17.2506, val_loss=18.8855, \n",
            "Epoch 665/6000: train_loss=17.6682, val_loss=17.2559, \n",
            "Epoch 666/6000: train_loss=17.0551, val_loss=18.0080, \n",
            "Epoch 667/6000: train_loss=17.4185, val_loss=19.4804, \n",
            "Epoch 668/6000: train_loss=17.0286, val_loss=17.9524, \n",
            "Epoch 669/6000: train_loss=17.1701, val_loss=17.6871, \n",
            "Epoch 670/6000: train_loss=16.9744, val_loss=18.1023, \n",
            "Epoch 671/6000: train_loss=17.0058, val_loss=18.4809, \n",
            "Epoch 672/6000: train_loss=16.9595, val_loss=18.2816, \n",
            "Epoch 673/6000: train_loss=17.1446, val_loss=17.3949, \n",
            "Epoch 674/6000: train_loss=16.9069, val_loss=18.2106, \n",
            "Epoch 675/6000: train_loss=16.9254, val_loss=18.4259, \n",
            "Epoch 676/6000: train_loss=16.8828, val_loss=17.8659, \n",
            "Epoch 677/6000: train_loss=16.8480, val_loss=17.9805, \n",
            "Epoch 678/6000: train_loss=16.8286, val_loss=17.9319, \n",
            "Epoch 679/6000: train_loss=16.8057, val_loss=17.9218, \n",
            "Epoch 680/6000: train_loss=16.7863, val_loss=18.1108, \n",
            "Epoch 681/6000: train_loss=16.7823, val_loss=17.7973, \n",
            "Epoch 682/6000: train_loss=16.7491, val_loss=17.9445, \n",
            "Epoch 683/6000: train_loss=16.7391, val_loss=18.1429, \n",
            "Epoch 684/6000: train_loss=16.7780, val_loss=17.6907, \n",
            "Epoch 685/6000: train_loss=16.7823, val_loss=18.5817, \n",
            "Epoch 686/6000: train_loss=16.7046, val_loss=18.2300, \n",
            "Epoch 687/6000: train_loss=16.6726, val_loss=17.6941, \n",
            "Epoch 688/6000: train_loss=16.6470, val_loss=17.7793, \n",
            "Epoch 689/6000: train_loss=16.6302, val_loss=18.0136, \n",
            "Epoch 690/6000: train_loss=16.6200, val_loss=18.1913, \n",
            "Epoch 691/6000: train_loss=16.5921, val_loss=18.0615, \n",
            "Epoch 692/6000: train_loss=16.5990, val_loss=18.3099, \n",
            "Epoch 693/6000: train_loss=16.5595, val_loss=17.8595, \n",
            "Epoch 694/6000: train_loss=16.5439, val_loss=18.0402, \n",
            "Epoch 695/6000: train_loss=16.5402, val_loss=18.1480, \n",
            "Epoch 696/6000: train_loss=16.5904, val_loss=17.3886, \n",
            "Epoch 697/6000: train_loss=16.5030, val_loss=17.6945, \n",
            "Epoch 698/6000: train_loss=16.5789, val_loss=18.3076, \n",
            "Epoch 699/6000: train_loss=16.5433, val_loss=17.3700, \n",
            "Epoch 700/6000: train_loss=16.4469, val_loss=17.7940, \n",
            "Epoch 701/6000: train_loss=16.5338, val_loss=18.5109, \n",
            "Epoch 702/6000: train_loss=16.4493, val_loss=17.4823, \n",
            "Epoch 703/6000: train_loss=16.5037, val_loss=17.2318, \n",
            "Epoch 704/6000: train_loss=16.6683, val_loss=18.6982, \n",
            "Epoch 705/6000: train_loss=16.3952, val_loss=18.0984, \n",
            "Epoch 706/6000: train_loss=16.8212, val_loss=17.1207, \n",
            "Epoch 707/6000: train_loss=16.3468, val_loss=18.0630, \n",
            "Epoch 708/6000: train_loss=16.4512, val_loss=18.4556, \n",
            "Epoch 709/6000: train_loss=16.3530, val_loss=17.3667, \n",
            "Epoch 710/6000: train_loss=16.2967, val_loss=17.5327, \n",
            "Epoch 711/6000: train_loss=16.2681, val_loss=17.7005, \n",
            "Epoch 712/6000: train_loss=16.2520, val_loss=17.7421, \n",
            "Epoch 713/6000: train_loss=16.2553, val_loss=17.9969, \n",
            "Epoch 714/6000: train_loss=16.2222, val_loss=17.7687, \n",
            "Epoch 715/6000: train_loss=16.2634, val_loss=17.3908, \n",
            "Epoch 716/6000: train_loss=16.2174, val_loss=17.8647, \n",
            "Epoch 717/6000: train_loss=16.1952, val_loss=17.6565, \n",
            "Epoch 718/6000: train_loss=16.1671, val_loss=17.3912, \n",
            "Epoch 719/6000: train_loss=16.1912, val_loss=17.3769, \n",
            "Epoch 720/6000: train_loss=16.1486, val_loss=17.8156, \n",
            "Epoch 721/6000: train_loss=16.1578, val_loss=18.0720, \n",
            "Epoch 722/6000: train_loss=16.1124, val_loss=17.4902, \n",
            "Epoch 723/6000: train_loss=16.0928, val_loss=17.5497, \n",
            "Epoch 724/6000: train_loss=16.3493, val_loss=18.6506, \n",
            "Epoch 725/6000: train_loss=16.2061, val_loss=17.1597, \n",
            "Epoch 726/6000: train_loss=16.0529, val_loss=17.7401, \n",
            "Epoch 727/6000: train_loss=16.1276, val_loss=18.1328, \n",
            "Epoch 728/6000: train_loss=16.0943, val_loss=17.2171, \n",
            "Epoch 729/6000: train_loss=16.0374, val_loss=17.2888, \n",
            "Epoch 730/6000: train_loss=16.2388, val_loss=18.5416, \n",
            "Epoch 731/6000: train_loss=15.9989, val_loss=17.3023, \n",
            "Epoch 732/6000: train_loss=16.1423, val_loss=17.1174, \n",
            "Epoch 733/6000: train_loss=16.0606, val_loss=18.2870, \n",
            "Epoch 734/6000: train_loss=15.9806, val_loss=17.9677, \n",
            "Epoch 735/6000: train_loss=16.1689, val_loss=16.9196, \n",
            "Epoch 736/6000: train_loss=15.9237, val_loss=17.3410, \n",
            "Epoch 737/6000: train_loss=16.0876, val_loss=18.2943, \n",
            "Epoch 738/6000: train_loss=15.8873, val_loss=17.2726, \n",
            "Epoch 739/6000: train_loss=15.8965, val_loss=17.0823, \n",
            "Epoch 740/6000: train_loss=15.8678, val_loss=17.6682, \n",
            "Epoch 741/6000: train_loss=15.8453, val_loss=17.6791, \n",
            "Epoch 742/6000: train_loss=16.0695, val_loss=16.9636, \n",
            "Epoch 743/6000: train_loss=15.8214, val_loss=17.3948, \n",
            "Epoch 744/6000: train_loss=15.9570, val_loss=18.2148, \n",
            "Epoch 745/6000: train_loss=16.1753, val_loss=16.9319, \n",
            "Epoch 746/6000: train_loss=15.8425, val_loss=17.3907, \n",
            "Epoch 747/6000: train_loss=16.1275, val_loss=18.9025, \n",
            "Epoch 748/6000: train_loss=15.8616, val_loss=17.0610, \n",
            "Epoch 749/6000: train_loss=15.8816, val_loss=16.8688, \n",
            "Epoch 750/6000: train_loss=15.8856, val_loss=18.1168, \n",
            "Epoch 751/6000: train_loss=15.7621, val_loss=17.8155, \n",
            "Epoch 752/6000: train_loss=16.2953, val_loss=16.7745, \n",
            "Epoch 753/6000: train_loss=15.7343, val_loss=17.8752, \n",
            "Epoch 754/6000: train_loss=15.9688, val_loss=18.6239, \n",
            "Epoch 755/6000: train_loss=16.1518, val_loss=16.7142, \n",
            "Epoch 756/6000: train_loss=15.7684, val_loss=18.1034, \n",
            "Epoch 757/6000: train_loss=15.7068, val_loss=17.9157, \n",
            "Epoch 758/6000: train_loss=16.0083, val_loss=16.8375, \n",
            "Epoch 759/6000: train_loss=15.6512, val_loss=17.7615, \n",
            "Epoch 760/6000: train_loss=16.1810, val_loss=19.0858, \n",
            "Epoch 761/6000: train_loss=15.8326, val_loss=16.6832, \n",
            "Epoch 762/6000: train_loss=15.8192, val_loss=16.7247, \n",
            "Epoch 763/6000: train_loss=15.8884, val_loss=18.4567, \n",
            "Epoch 764/6000: train_loss=15.6286, val_loss=17.8216, \n",
            "Epoch 765/6000: train_loss=15.8991, val_loss=16.8107, \n",
            "Epoch 766/6000: train_loss=15.6728, val_loss=18.1985, \n",
            "Epoch 767/6000: train_loss=15.5385, val_loss=17.5688, \n",
            "Epoch 768/6000: train_loss=15.8250, val_loss=16.7788, \n",
            "Epoch 769/6000: train_loss=15.5399, val_loss=17.5736, \n",
            "Epoch 770/6000: train_loss=15.5733, val_loss=17.6223, \n",
            "Epoch 771/6000: train_loss=15.8699, val_loss=16.5043, \n",
            "Epoch 772/6000: train_loss=15.6376, val_loss=18.1009, \n",
            "Epoch 773/6000: train_loss=15.5387, val_loss=17.8640, \n",
            "Epoch 774/6000: train_loss=15.5655, val_loss=17.0826, \n",
            "Epoch 775/6000: train_loss=15.4518, val_loss=17.5714, \n",
            "Epoch 776/6000: train_loss=15.4839, val_loss=17.7800, \n",
            "Epoch 777/6000: train_loss=15.4967, val_loss=16.8423, \n",
            "Epoch 778/6000: train_loss=15.4478, val_loss=16.8539, \n",
            "Epoch 779/6000: train_loss=15.4962, val_loss=17.6011, \n",
            "Epoch 780/6000: train_loss=15.4612, val_loss=16.9208, \n",
            "Epoch 781/6000: train_loss=15.3861, val_loss=17.5299, \n",
            "Epoch 782/6000: train_loss=15.4352, val_loss=17.8803, \n",
            "Epoch 783/6000: train_loss=15.5149, val_loss=16.8354, \n",
            "Epoch 784/6000: train_loss=15.3642, val_loss=17.1168, \n",
            "Epoch 785/6000: train_loss=15.4781, val_loss=17.9889, \n",
            "Epoch 786/6000: train_loss=15.3280, val_loss=17.1536, \n",
            "Epoch 787/6000: train_loss=15.3832, val_loss=16.8320, \n",
            "Epoch 788/6000: train_loss=15.4305, val_loss=17.8253, \n",
            "Epoch 789/6000: train_loss=15.3050, val_loss=17.2921, \n",
            "Epoch 790/6000: train_loss=15.3453, val_loss=16.8228, \n",
            "Epoch 791/6000: train_loss=15.3862, val_loss=17.8258, \n",
            "Epoch 792/6000: train_loss=15.2657, val_loss=17.1733, \n",
            "Epoch 793/6000: train_loss=15.9727, val_loss=16.4847, \n",
            "Epoch 794/6000: train_loss=15.2996, val_loss=17.6385, \n",
            "Epoch 795/6000: train_loss=15.3021, val_loss=17.6651, \n",
            "Epoch 796/6000: train_loss=15.2246, val_loss=17.1246, \n",
            "Epoch 797/6000: train_loss=15.2219, val_loss=17.1180, \n",
            "Epoch 798/6000: train_loss=15.2165, val_loss=17.1144, \n",
            "Epoch 799/6000: train_loss=15.2120, val_loss=17.3165, \n",
            "Epoch 800/6000: train_loss=15.2543, val_loss=17.6618, \n",
            "Epoch 801/6000: train_loss=15.2059, val_loss=16.9989, \n",
            "Epoch 802/6000: train_loss=15.1961, val_loss=17.1518, \n",
            "Epoch 803/6000: train_loss=15.2536, val_loss=17.8452, \n",
            "Epoch 804/6000: train_loss=15.1458, val_loss=17.0393, \n",
            "Epoch 805/6000: train_loss=15.1560, val_loss=16.8935, \n",
            "Epoch 806/6000: train_loss=15.2104, val_loss=17.4777, \n",
            "Epoch 807/6000: train_loss=15.1786, val_loss=16.8721, \n",
            "Epoch 808/6000: train_loss=15.1921, val_loss=17.8749, \n",
            "Epoch 809/6000: train_loss=15.1174, val_loss=17.3617, \n",
            "Epoch 810/6000: train_loss=15.1100, val_loss=17.0450, \n",
            "Epoch 811/6000: train_loss=15.0905, val_loss=17.0792, \n",
            "Epoch 812/6000: train_loss=15.0987, val_loss=16.9977, \n",
            "Epoch 813/6000: train_loss=15.0732, val_loss=16.9591, \n",
            "Epoch 814/6000: train_loss=15.0801, val_loss=16.9819, \n",
            "Epoch 815/6000: train_loss=15.0515, val_loss=17.2473, \n",
            "Epoch 816/6000: train_loss=15.0427, val_loss=17.2907, \n",
            "Epoch 817/6000: train_loss=15.0306, val_loss=17.1621, \n",
            "Epoch 818/6000: train_loss=15.1333, val_loss=17.5730, \n",
            "Epoch 819/6000: train_loss=15.0384, val_loss=16.7198, \n",
            "Epoch 820/6000: train_loss=15.0033, val_loss=16.9127, \n",
            "Epoch 821/6000: train_loss=14.9869, val_loss=17.0379, \n",
            "Epoch 822/6000: train_loss=14.9980, val_loss=17.4217, \n",
            "Epoch 823/6000: train_loss=14.9680, val_loss=17.1848, \n",
            "Epoch 824/6000: train_loss=14.9601, val_loss=16.9811, \n",
            "Epoch 825/6000: train_loss=15.1301, val_loss=17.9223, \n",
            "Epoch 826/6000: train_loss=14.9397, val_loss=17.0720, \n",
            "Epoch 827/6000: train_loss=15.5486, val_loss=16.5623, \n",
            "Epoch 828/6000: train_loss=15.3946, val_loss=18.6718, \n",
            "Epoch 829/6000: train_loss=14.9981, val_loss=17.4803, \n",
            "Epoch 830/6000: train_loss=15.5237, val_loss=16.1771, \n",
            "Epoch 831/6000: train_loss=15.1943, val_loss=18.0420, \n",
            "Epoch 832/6000: train_loss=15.0362, val_loss=17.6829, \n",
            "Epoch 833/6000: train_loss=15.4485, val_loss=16.2987, \n",
            "Epoch 834/6000: train_loss=15.2723, val_loss=18.4578, \n",
            "Epoch 835/6000: train_loss=15.0584, val_loss=17.9938, \n",
            "Epoch 836/6000: train_loss=15.3113, val_loss=16.4125, \n",
            "Epoch 837/6000: train_loss=14.9645, val_loss=17.3806, \n",
            "Epoch 838/6000: train_loss=15.0273, val_loss=17.4957, \n",
            "Epoch 839/6000: train_loss=15.3981, val_loss=16.3519, \n",
            "Epoch 840/6000: train_loss=14.8423, val_loss=17.3090, \n",
            "Epoch 841/6000: train_loss=15.3176, val_loss=18.6989, \n",
            "Epoch 842/6000: train_loss=14.9600, val_loss=16.5444, \n",
            "Epoch 843/6000: train_loss=15.1052, val_loss=16.3261, \n",
            "Epoch 844/6000: train_loss=15.0662, val_loss=17.9230, \n",
            "Epoch 845/6000: train_loss=14.7756, val_loss=16.9187, \n",
            "Epoch 846/6000: train_loss=14.8013, val_loss=16.6584, \n",
            "Epoch 847/6000: train_loss=14.8504, val_loss=17.3145, \n",
            "Epoch 848/6000: train_loss=14.7655, val_loss=16.7712, \n",
            "Epoch 849/6000: train_loss=14.7774, val_loss=16.7851, \n",
            "Epoch 850/6000: train_loss=14.7428, val_loss=17.0500, \n",
            "Epoch 851/6000: train_loss=14.7346, val_loss=17.1476, \n",
            "Epoch 852/6000: train_loss=14.7744, val_loss=16.7966, \n",
            "Epoch 853/6000: train_loss=14.7836, val_loss=16.7096, \n",
            "Epoch 854/6000: train_loss=14.7573, val_loss=17.2655, \n",
            "Epoch 855/6000: train_loss=14.7266, val_loss=17.0649, \n",
            "Epoch 856/6000: train_loss=15.1187, val_loss=16.0344, \n",
            "Epoch 857/6000: train_loss=14.7906, val_loss=17.3024, \n",
            "Epoch 858/6000: train_loss=14.9755, val_loss=18.0396, \n",
            "Epoch 859/6000: train_loss=15.0046, val_loss=16.4162, \n",
            "Epoch 860/6000: train_loss=14.6749, val_loss=16.9522, \n",
            "Epoch 861/6000: train_loss=15.1952, val_loss=18.6381, \n",
            "Epoch 862/6000: train_loss=15.2812, val_loss=16.0882, \n",
            "Epoch 863/6000: train_loss=14.6462, val_loss=16.6550, \n",
            "Epoch 864/6000: train_loss=15.4594, val_loss=18.9852, \n",
            "Epoch 865/6000: train_loss=15.2491, val_loss=16.1036, \n",
            "Epoch 866/6000: train_loss=14.6616, val_loss=16.5010, \n",
            "Epoch 867/6000: train_loss=15.1105, val_loss=18.5047, \n",
            "Epoch 868/6000: train_loss=14.7059, val_loss=16.5057, \n",
            "Epoch 869/6000: train_loss=14.8890, val_loss=16.0829, \n",
            "Epoch 870/6000: train_loss=15.4302, val_loss=18.8157, \n",
            "Epoch 871/6000: train_loss=14.5909, val_loss=16.4618, \n",
            "Epoch 872/6000: train_loss=14.9402, val_loss=16.0017, \n",
            "Epoch 873/6000: train_loss=15.0265, val_loss=18.2851, \n",
            "Epoch 874/6000: train_loss=14.5571, val_loss=16.8709, \n",
            "Epoch 875/6000: train_loss=14.6608, val_loss=16.6748, \n",
            "Epoch 876/6000: train_loss=14.7727, val_loss=18.0357, \n",
            "Epoch 877/6000: train_loss=14.5840, val_loss=16.5800, \n",
            "Epoch 878/6000: train_loss=14.5601, val_loss=16.4910, \n",
            "Epoch 879/6000: train_loss=14.7499, val_loss=17.6724, \n",
            "Epoch 880/6000: train_loss=14.5284, val_loss=16.9726, \n",
            "Epoch 881/6000: train_loss=14.7657, val_loss=16.2486, \n",
            "Epoch 882/6000: train_loss=14.9927, val_loss=18.4869, \n",
            "Epoch 883/6000: train_loss=14.4933, val_loss=17.1117, \n",
            "Epoch 884/6000: train_loss=14.8262, val_loss=16.1541, \n",
            "Epoch 885/6000: train_loss=14.8199, val_loss=17.8938, \n",
            "Epoch 886/6000: train_loss=14.4848, val_loss=16.5372, \n",
            "Epoch 887/6000: train_loss=15.2568, val_loss=16.1589, \n",
            "Epoch 888/6000: train_loss=14.7580, val_loss=18.1446, \n",
            "Epoch 889/6000: train_loss=14.5272, val_loss=17.4184, \n",
            "Epoch 890/6000: train_loss=14.7973, val_loss=16.1315, \n",
            "Epoch 891/6000: train_loss=14.6707, val_loss=17.5215, \n",
            "Epoch 892/6000: train_loss=14.5014, val_loss=16.9803, \n",
            "Epoch 893/6000: train_loss=14.8160, val_loss=16.0055, \n",
            "Epoch 894/6000: train_loss=14.5433, val_loss=17.5006, \n",
            "Epoch 895/6000: train_loss=14.4211, val_loss=16.9280, \n",
            "Epoch 896/6000: train_loss=14.4822, val_loss=16.4197, \n",
            "Epoch 897/6000: train_loss=14.6713, val_loss=17.7675, \n",
            "Epoch 898/6000: train_loss=14.3915, val_loss=16.7382, \n",
            "Epoch 899/6000: train_loss=14.5080, val_loss=16.1750, \n",
            "Epoch 900/6000: train_loss=14.4170, val_loss=17.0594, \n",
            "Epoch 901/6000: train_loss=14.3572, val_loss=16.8205, \n",
            "Epoch 902/6000: train_loss=14.3750, val_loss=16.5796, \n",
            "Epoch 903/6000: train_loss=14.3447, val_loss=16.8034, \n",
            "Epoch 904/6000: train_loss=14.4056, val_loss=17.1606, \n",
            "Epoch 905/6000: train_loss=14.3498, val_loss=16.3986, \n",
            "Epoch 906/6000: train_loss=14.4194, val_loss=16.1123, \n",
            "Epoch 907/6000: train_loss=14.8552, val_loss=18.1646, \n",
            "Epoch 908/6000: train_loss=14.3125, val_loss=16.3930, \n",
            "Epoch 909/6000: train_loss=14.5184, val_loss=16.0945, \n",
            "Epoch 910/6000: train_loss=14.3937, val_loss=17.2674, \n",
            "Epoch 911/6000: train_loss=14.2905, val_loss=16.8379, \n",
            "Epoch 912/6000: train_loss=14.4161, val_loss=16.3706, \n",
            "Epoch 913/6000: train_loss=14.3560, val_loss=17.2867, \n",
            "Epoch 914/6000: train_loss=14.3467, val_loss=17.1595, \n",
            "Epoch 915/6000: train_loss=14.6095, val_loss=15.7835, \n",
            "Epoch 916/6000: train_loss=14.3273, val_loss=16.8122, \n",
            "Epoch 917/6000: train_loss=14.5241, val_loss=17.5462, \n",
            "Epoch 918/6000: train_loss=14.6936, val_loss=16.1270, \n",
            "Epoch 919/6000: train_loss=14.2617, val_loss=16.6342, \n",
            "Epoch 920/6000: train_loss=14.8553, val_loss=18.5299, \n",
            "Epoch 921/6000: train_loss=14.2834, val_loss=16.2245, \n",
            "Epoch 922/6000: train_loss=14.4938, val_loss=15.8331, \n",
            "Epoch 923/6000: train_loss=14.7304, val_loss=18.0210, \n",
            "Epoch 924/6000: train_loss=14.2080, val_loss=16.7316, \n",
            "Epoch 925/6000: train_loss=14.5186, val_loss=16.1535, \n",
            "Epoch 926/6000: train_loss=14.1910, val_loss=16.6267, \n",
            "Epoch 927/6000: train_loss=14.3641, val_loss=17.4644, \n",
            "Epoch 928/6000: train_loss=14.4509, val_loss=15.9201, \n",
            "Epoch 929/6000: train_loss=14.2044, val_loss=16.1965, \n",
            "Epoch 930/6000: train_loss=14.3038, val_loss=17.2289, \n",
            "Epoch 931/6000: train_loss=14.1578, val_loss=16.5813, \n",
            "Epoch 932/6000: train_loss=14.4249, val_loss=16.0517, \n",
            "Epoch 933/6000: train_loss=14.1527, val_loss=16.7137, \n",
            "Epoch 934/6000: train_loss=14.1348, val_loss=16.4473, \n",
            "Epoch 935/6000: train_loss=14.1337, val_loss=16.3058, \n",
            "Epoch 936/6000: train_loss=14.1429, val_loss=16.2876, \n",
            "Epoch 937/6000: train_loss=14.1163, val_loss=16.6097, \n",
            "Epoch 938/6000: train_loss=14.1390, val_loss=16.9283, \n",
            "Epoch 939/6000: train_loss=14.1303, val_loss=16.4146, \n",
            "Epoch 940/6000: train_loss=14.0996, val_loss=16.6482, \n",
            "Epoch 941/6000: train_loss=14.3279, val_loss=17.4985, \n",
            "Epoch 942/6000: train_loss=14.1036, val_loss=16.2174, \n",
            "Epoch 943/6000: train_loss=14.0819, val_loss=16.5168, \n",
            "Epoch 944/6000: train_loss=14.0898, val_loss=16.7354, \n",
            "Epoch 945/6000: train_loss=14.2344, val_loss=16.1112, \n",
            "Epoch 946/6000: train_loss=14.1033, val_loss=16.9198, \n",
            "Epoch 947/6000: train_loss=14.1003, val_loss=16.9100, \n",
            "Epoch 948/6000: train_loss=14.4362, val_loss=15.9543, \n",
            "Epoch 949/6000: train_loss=14.0595, val_loss=16.7436, \n",
            "Epoch 950/6000: train_loss=14.2827, val_loss=17.4201, \n",
            "Epoch 951/6000: train_loss=15.1319, val_loss=15.6351, \n",
            "Epoch 952/6000: train_loss=14.0520, val_loss=16.2965, \n",
            "Epoch 953/6000: train_loss=14.2773, val_loss=17.4014, \n",
            "Epoch 954/6000: train_loss=14.9446, val_loss=15.8707, \n",
            "Epoch 955/6000: train_loss=14.0583, val_loss=16.9790, \n",
            "Epoch 956/6000: train_loss=15.0506, val_loss=19.2612, \n",
            "Epoch 957/6000: train_loss=14.5672, val_loss=15.9600, \n",
            "Epoch 958/6000: train_loss=14.0024, val_loss=16.4936, \n",
            "Epoch 959/6000: train_loss=14.4161, val_loss=17.7016, \n",
            "Epoch 960/6000: train_loss=14.0207, val_loss=16.1338, \n",
            "Epoch 961/6000: train_loss=13.9878, val_loss=16.6115, \n",
            "Epoch 962/6000: train_loss=13.9839, val_loss=16.6406, \n",
            "Epoch 963/6000: train_loss=13.9928, val_loss=16.8808, \n",
            "Epoch 964/6000: train_loss=14.2528, val_loss=15.9940, \n",
            "Epoch 965/6000: train_loss=14.0598, val_loss=16.9557, \n",
            "Epoch 966/6000: train_loss=13.9837, val_loss=16.4193, \n",
            "Epoch 967/6000: train_loss=14.0410, val_loss=15.8991, \n",
            "Epoch 968/6000: train_loss=14.0906, val_loss=17.1110, \n",
            "Epoch 969/6000: train_loss=13.9556, val_loss=16.2435, \n",
            "Epoch 970/6000: train_loss=14.2811, val_loss=15.7970, \n",
            "Epoch 971/6000: train_loss=14.2119, val_loss=17.4821, \n",
            "Epoch 972/6000: train_loss=13.9965, val_loss=16.8434, \n",
            "Epoch 973/6000: train_loss=14.0080, val_loss=16.0081, \n",
            "Epoch 974/6000: train_loss=13.9038, val_loss=16.3519, \n",
            "Epoch 975/6000: train_loss=13.8975, val_loss=16.3642, \n",
            "Epoch 976/6000: train_loss=13.9417, val_loss=16.8867, \n",
            "Epoch 977/6000: train_loss=13.9071, val_loss=16.2727, \n",
            "Epoch 978/6000: train_loss=14.0808, val_loss=15.8935, \n",
            "Epoch 979/6000: train_loss=13.9488, val_loss=16.8890, \n",
            "Epoch 980/6000: train_loss=13.8704, val_loss=16.3518, \n",
            "Epoch 981/6000: train_loss=13.9488, val_loss=15.7858, \n",
            "Epoch 982/6000: train_loss=13.8828, val_loss=16.3959, \n",
            "Epoch 983/6000: train_loss=13.9697, val_loss=16.9619, \n",
            "Epoch 984/6000: train_loss=13.9941, val_loss=16.1094, \n",
            "Epoch 985/6000: train_loss=13.8664, val_loss=16.4745, \n",
            "Epoch 986/6000: train_loss=14.1337, val_loss=17.5681, \n",
            "Epoch 987/6000: train_loss=14.0701, val_loss=15.7159, \n",
            "Epoch 988/6000: train_loss=13.8449, val_loss=16.4525, \n",
            "Epoch 989/6000: train_loss=13.8499, val_loss=16.5197, \n",
            "Epoch 990/6000: train_loss=14.2312, val_loss=15.7337, \n",
            "Epoch 991/6000: train_loss=13.8988, val_loss=16.8746, \n",
            "Epoch 992/6000: train_loss=13.9647, val_loss=17.1228, \n",
            "Epoch 993/6000: train_loss=13.8223, val_loss=16.0856, \n",
            "Epoch 994/6000: train_loss=13.8178, val_loss=16.1796, \n",
            "Epoch 995/6000: train_loss=13.7952, val_loss=16.5407, \n",
            "Epoch 996/6000: train_loss=13.7807, val_loss=16.4232, \n",
            "Epoch 997/6000: train_loss=13.8184, val_loss=16.1166, \n",
            "Epoch 998/6000: train_loss=13.8553, val_loss=16.5629, \n",
            "Epoch 999/6000: train_loss=13.8442, val_loss=15.6842, \n",
            "Epoch 1000/6000: train_loss=13.8199, val_loss=15.7807, \n",
            "Epoch 1001/6000: train_loss=14.0534, val_loss=17.5809, \n",
            "Epoch 1002/6000: train_loss=13.8176, val_loss=16.3273, \n",
            "Epoch 1003/6000: train_loss=13.8140, val_loss=16.1077, \n",
            "Epoch 1004/6000: train_loss=13.8607, val_loss=16.8570, \n",
            "Epoch 1005/6000: train_loss=13.8040, val_loss=16.4329, \n",
            "Epoch 1006/6000: train_loss=13.7894, val_loss=16.0717, \n",
            "Epoch 1007/6000: train_loss=13.7379, val_loss=16.2413, \n",
            "Epoch 1008/6000: train_loss=13.8508, val_loss=17.2590, \n",
            "Epoch 1009/6000: train_loss=13.7267, val_loss=16.6512, \n",
            "Epoch 1010/6000: train_loss=13.8337, val_loss=15.9069, \n",
            "Epoch 1011/6000: train_loss=13.7779, val_loss=16.5911, \n",
            "Epoch 1012/6000: train_loss=13.7440, val_loss=15.7884, \n",
            "Epoch 1013/6000: train_loss=13.7032, val_loss=15.9774, \n",
            "Epoch 1014/6000: train_loss=14.0148, val_loss=17.4597, \n",
            "Epoch 1015/6000: train_loss=13.8859, val_loss=15.9986, \n",
            "Epoch 1016/6000: train_loss=13.7455, val_loss=16.1475, \n",
            "Epoch 1017/6000: train_loss=13.9912, val_loss=17.3442, \n",
            "Epoch 1018/6000: train_loss=13.9302, val_loss=15.6005, \n",
            "Epoch 1019/6000: train_loss=13.7749, val_loss=15.7941, \n",
            "Epoch 1020/6000: train_loss=14.2926, val_loss=18.2762, \n",
            "Epoch 1021/6000: train_loss=14.1210, val_loss=15.7934, \n",
            "Epoch 1022/6000: train_loss=13.6609, val_loss=16.3149, \n",
            "Epoch 1023/6000: train_loss=14.0673, val_loss=17.5867, \n",
            "Epoch 1024/6000: train_loss=13.9101, val_loss=15.5854, \n",
            "Epoch 1025/6000: train_loss=13.6764, val_loss=16.5656, \n",
            "Epoch 1026/6000: train_loss=13.6650, val_loss=16.6991, \n",
            "Epoch 1027/6000: train_loss=13.9293, val_loss=15.7723, \n",
            "Epoch 1028/6000: train_loss=13.8076, val_loss=17.0038, \n",
            "Epoch 1029/6000: train_loss=13.6337, val_loss=15.9048, \n",
            "Epoch 1030/6000: train_loss=13.6491, val_loss=15.7733, \n",
            "Epoch 1031/6000: train_loss=13.6434, val_loss=15.8900, \n",
            "Epoch 1032/6000: train_loss=13.6109, val_loss=16.3367, \n",
            "Epoch 1033/6000: train_loss=13.6172, val_loss=16.1263, \n",
            "Epoch 1034/6000: train_loss=13.5983, val_loss=16.0438, \n",
            "Epoch 1035/6000: train_loss=13.6001, val_loss=16.3313, \n",
            "Epoch 1036/6000: train_loss=13.6296, val_loss=15.9008, \n",
            "Epoch 1037/6000: train_loss=13.6154, val_loss=16.1078, \n",
            "Epoch 1038/6000: train_loss=14.0028, val_loss=17.8399, \n",
            "Epoch 1039/6000: train_loss=13.6749, val_loss=15.7934, \n",
            "Epoch 1040/6000: train_loss=13.5588, val_loss=16.0858, \n",
            "Epoch 1041/6000: train_loss=13.5644, val_loss=15.8592, \n",
            "Epoch 1042/6000: train_loss=13.6147, val_loss=15.7524, \n",
            "Epoch 1043/6000: train_loss=13.6087, val_loss=16.6979, \n",
            "Epoch 1044/6000: train_loss=13.5600, val_loss=16.5439, \n",
            "Epoch 1045/6000: train_loss=13.5871, val_loss=16.0715, \n",
            "Epoch 1046/6000: train_loss=13.5948, val_loss=16.6645, \n",
            "Epoch 1047/6000: train_loss=13.6113, val_loss=16.8561, \n",
            "Epoch 1048/6000: train_loss=13.7691, val_loss=15.8431, \n",
            "Epoch 1049/6000: train_loss=13.6629, val_loss=16.9520, \n",
            "Epoch 1050/6000: train_loss=13.5209, val_loss=15.9783, \n",
            "Epoch 1051/6000: train_loss=13.5155, val_loss=16.3037, \n",
            "Epoch 1052/6000: train_loss=13.5051, val_loss=16.0407, \n",
            "Epoch 1053/6000: train_loss=14.3160, val_loss=15.4418, \n",
            "Epoch 1054/6000: train_loss=13.8805, val_loss=17.4146, \n",
            "Epoch 1055/6000: train_loss=13.5162, val_loss=16.2774, \n",
            "Epoch 1056/6000: train_loss=13.7349, val_loss=15.4977, \n",
            "Epoch 1057/6000: train_loss=13.6167, val_loss=16.8022, \n",
            "Epoch 1058/6000: train_loss=13.5274, val_loss=15.9698, \n",
            "Epoch 1059/6000: train_loss=13.4875, val_loss=16.4249, \n",
            "Epoch 1060/6000: train_loss=13.6317, val_loss=17.0968, \n",
            "Epoch 1061/6000: train_loss=13.5485, val_loss=15.8742, \n",
            "Epoch 1062/6000: train_loss=13.4634, val_loss=16.0460, \n",
            "Epoch 1063/6000: train_loss=13.4654, val_loss=16.2886, \n",
            "Epoch 1064/6000: train_loss=13.4452, val_loss=15.9896, \n",
            "Epoch 1065/6000: train_loss=13.5210, val_loss=16.4780, \n",
            "Epoch 1066/6000: train_loss=13.5125, val_loss=15.6480, \n",
            "Epoch 1067/6000: train_loss=13.4536, val_loss=16.2812, \n",
            "Epoch 1068/6000: train_loss=13.4227, val_loss=16.1842, \n",
            "Epoch 1069/6000: train_loss=14.1222, val_loss=15.6472, \n",
            "Epoch 1070/6000: train_loss=13.5940, val_loss=16.9950, \n",
            "Epoch 1071/6000: train_loss=13.4871, val_loss=16.6923, \n",
            "Epoch 1072/6000: train_loss=13.9120, val_loss=15.4417, \n",
            "Epoch 1073/6000: train_loss=14.0572, val_loss=17.8498, \n",
            "Epoch 1074/6000: train_loss=13.4530, val_loss=16.3474, \n",
            "Epoch 1075/6000: train_loss=13.9475, val_loss=15.2056, \n",
            "Epoch 1076/6000: train_loss=13.7660, val_loss=17.3648, \n",
            "Epoch 1077/6000: train_loss=13.4070, val_loss=16.3319, \n",
            "Epoch 1078/6000: train_loss=13.5844, val_loss=16.1043, \n",
            "Epoch 1079/6000: train_loss=13.7733, val_loss=17.7297, \n",
            "Epoch 1080/6000: train_loss=13.3883, val_loss=16.0224, \n",
            "Epoch 1081/6000: train_loss=13.7724, val_loss=15.3746, \n",
            "Epoch 1082/6000: train_loss=13.6418, val_loss=17.2018, \n",
            "Epoch 1083/6000: train_loss=13.4109, val_loss=15.8246, \n",
            "Epoch 1084/6000: train_loss=13.3518, val_loss=16.2445, \n",
            "Epoch 1085/6000: train_loss=13.4366, val_loss=16.5082, \n",
            "Epoch 1086/6000: train_loss=13.3807, val_loss=15.7087, \n",
            "Epoch 1087/6000: train_loss=13.4782, val_loss=15.6384, \n",
            "Epoch 1088/6000: train_loss=13.4369, val_loss=16.8592, \n",
            "Epoch 1089/6000: train_loss=13.4917, val_loss=16.0721, \n",
            "Epoch 1090/6000: train_loss=13.3525, val_loss=16.1788, \n",
            "Epoch 1091/6000: train_loss=13.3213, val_loss=15.8993, \n",
            "Epoch 1092/6000: train_loss=13.4733, val_loss=16.4761, \n",
            "Epoch 1093/6000: train_loss=13.4290, val_loss=15.4063, \n",
            "Epoch 1094/6000: train_loss=13.2990, val_loss=15.8993, \n",
            "Epoch 1095/6000: train_loss=13.3626, val_loss=16.7871, \n",
            "Epoch 1096/6000: train_loss=13.3136, val_loss=16.5496, \n",
            "Epoch 1097/6000: train_loss=13.6041, val_loss=15.6691, \n",
            "Epoch 1098/6000: train_loss=13.7375, val_loss=17.5459, \n",
            "Epoch 1099/6000: train_loss=13.2976, val_loss=15.6674, \n",
            "Epoch 1100/6000: train_loss=13.3652, val_loss=15.5078, \n",
            "Epoch 1101/6000: train_loss=13.8418, val_loss=17.7921, \n",
            "Epoch 1102/6000: train_loss=13.2527, val_loss=15.9441, \n",
            "Epoch 1103/6000: train_loss=13.5790, val_loss=15.6671, \n",
            "Epoch 1104/6000: train_loss=13.7999, val_loss=17.7690, \n",
            "Epoch 1105/6000: train_loss=13.3822, val_loss=15.6170, \n",
            "Epoch 1106/6000: train_loss=13.3944, val_loss=15.5555, \n",
            "Epoch 1107/6000: train_loss=14.0185, val_loss=18.1845, \n",
            "Epoch 1108/6000: train_loss=13.2702, val_loss=15.7652, \n",
            "Epoch 1109/6000: train_loss=13.2450, val_loss=15.8319, \n",
            "Epoch 1110/6000: train_loss=13.3159, val_loss=16.6983, \n",
            "Epoch 1111/6000: train_loss=13.3555, val_loss=15.5558, \n",
            "Epoch 1112/6000: train_loss=13.2355, val_loss=16.4027, \n",
            "Epoch 1113/6000: train_loss=13.2792, val_loss=16.5749, \n",
            "Epoch 1114/6000: train_loss=13.6859, val_loss=15.3296, \n",
            "Epoch 1115/6000: train_loss=13.6802, val_loss=17.1638, \n",
            "Epoch 1116/6000: train_loss=13.2077, val_loss=15.9565, \n",
            "Epoch 1117/6000: train_loss=13.6928, val_loss=15.3473, \n",
            "Epoch 1118/6000: train_loss=14.3547, val_loss=18.9899, \n",
            "Epoch 1119/6000: train_loss=13.1754, val_loss=16.2190, \n",
            "Epoch 1120/6000: train_loss=13.4947, val_loss=15.4670, \n",
            "Epoch 1121/6000: train_loss=13.4352, val_loss=17.1105, \n",
            "Epoch 1122/6000: train_loss=13.1584, val_loss=15.8986, \n",
            "Epoch 1123/6000: train_loss=13.2529, val_loss=15.6300, \n",
            "Epoch 1124/6000: train_loss=13.1877, val_loss=16.2625, \n",
            "Epoch 1125/6000: train_loss=13.2101, val_loss=16.2743, \n",
            "Epoch 1126/6000: train_loss=13.2881, val_loss=15.3036, \n",
            "Epoch 1127/6000: train_loss=13.1592, val_loss=16.0695, \n",
            "Epoch 1128/6000: train_loss=13.2527, val_loss=16.7514, \n",
            "Epoch 1129/6000: train_loss=13.5655, val_loss=15.5575, \n",
            "Epoch 1130/6000: train_loss=13.1453, val_loss=15.9881, \n",
            "Epoch 1131/6000: train_loss=13.1177, val_loss=16.1967, \n",
            "Epoch 1132/6000: train_loss=13.1098, val_loss=15.9254, \n",
            "Epoch 1133/6000: train_loss=13.1197, val_loss=15.9890, \n",
            "Epoch 1134/6000: train_loss=13.1314, val_loss=15.6422, \n",
            "Epoch 1135/6000: train_loss=13.1079, val_loss=15.6850, \n",
            "Epoch 1136/6000: train_loss=13.1283, val_loss=15.6749, \n",
            "Epoch 1137/6000: train_loss=13.1070, val_loss=16.1901, \n",
            "Epoch 1138/6000: train_loss=13.0846, val_loss=16.0108, \n",
            "Epoch 1139/6000: train_loss=13.0893, val_loss=16.0720, \n",
            "Epoch 1140/6000: train_loss=13.1075, val_loss=16.2924, \n",
            "Epoch 1141/6000: train_loss=13.0840, val_loss=16.0738, \n",
            "Epoch 1142/6000: train_loss=13.1737, val_loss=15.3565, \n",
            "Epoch 1143/6000: train_loss=13.3580, val_loss=16.7644, \n",
            "Epoch 1144/6000: train_loss=13.0562, val_loss=15.8822, \n",
            "Epoch 1145/6000: train_loss=13.2634, val_loss=15.5812, \n",
            "Epoch 1146/6000: train_loss=13.0477, val_loss=16.1645, \n",
            "Epoch 1147/6000: train_loss=13.0907, val_loss=16.3702, \n",
            "Epoch 1148/6000: train_loss=13.0535, val_loss=15.6828, \n",
            "Epoch 1149/6000: train_loss=13.1468, val_loss=16.4076, \n",
            "Epoch 1150/6000: train_loss=13.0366, val_loss=15.9800, \n",
            "Epoch 1151/6000: train_loss=13.0586, val_loss=15.5095, \n",
            "Epoch 1152/6000: train_loss=13.1362, val_loss=16.6199, \n",
            "Epoch 1153/6000: train_loss=13.0266, val_loss=16.0942, \n",
            "Epoch 1154/6000: train_loss=13.0691, val_loss=15.6821, \n",
            "Epoch 1155/6000: train_loss=13.0082, val_loss=15.7336, \n",
            "Epoch 1156/6000: train_loss=13.1412, val_loss=15.2799, \n",
            "Epoch 1157/6000: train_loss=13.1283, val_loss=16.2841, \n",
            "Epoch 1158/6000: train_loss=13.1618, val_loss=16.5722, \n",
            "Epoch 1159/6000: train_loss=13.6731, val_loss=15.3337, \n",
            "Epoch 1160/6000: train_loss=13.1701, val_loss=16.7842, \n",
            "Epoch 1161/6000: train_loss=12.9797, val_loss=15.8254, \n",
            "Epoch 1162/6000: train_loss=13.0076, val_loss=15.6680, \n",
            "Epoch 1163/6000: train_loss=13.4726, val_loss=17.2741, \n",
            "Epoch 1164/6000: train_loss=13.0558, val_loss=15.3710, \n",
            "Epoch 1165/6000: train_loss=13.1314, val_loss=15.3560, \n",
            "Epoch 1166/6000: train_loss=13.4906, val_loss=17.5533, \n",
            "Epoch 1167/6000: train_loss=13.1089, val_loss=15.8357, \n",
            "Epoch 1168/6000: train_loss=13.3173, val_loss=15.6246, \n",
            "Epoch 1169/6000: train_loss=13.9983, val_loss=18.4437, \n",
            "Epoch 1170/6000: train_loss=13.4716, val_loss=15.0591, \n",
            "Epoch 1171/6000: train_loss=13.0783, val_loss=16.3478, \n",
            "Epoch 1172/6000: train_loss=13.1286, val_loss=16.5051, \n",
            "Epoch 1173/6000: train_loss=13.5299, val_loss=15.1662, \n",
            "Epoch 1174/6000: train_loss=13.9433, val_loss=18.4866, \n",
            "Epoch 1175/6000: train_loss=13.0994, val_loss=15.6511, \n",
            "Epoch 1176/6000: train_loss=13.3530, val_loss=15.4744, \n",
            "Epoch 1177/6000: train_loss=13.3766, val_loss=17.3061, \n",
            "Epoch 1178/6000: train_loss=13.0654, val_loss=15.2490, \n",
            "Epoch 1179/6000: train_loss=12.9716, val_loss=16.1304, \n",
            "Epoch 1180/6000: train_loss=13.2706, val_loss=16.9617, \n",
            "Epoch 1181/6000: train_loss=13.5528, val_loss=15.1371, \n",
            "Epoch 1182/6000: train_loss=12.9605, val_loss=16.2000, \n",
            "Epoch 1183/6000: train_loss=13.0801, val_loss=16.5653, \n",
            "Epoch 1184/6000: train_loss=14.0372, val_loss=15.4443, \n",
            "Epoch 1185/6000: train_loss=13.9757, val_loss=18.5795, \n",
            "Epoch 1186/6000: train_loss=12.8982, val_loss=15.9046, \n",
            "Epoch 1187/6000: train_loss=13.1917, val_loss=15.3019, \n",
            "Epoch 1188/6000: train_loss=13.8466, val_loss=18.0462, \n",
            "Epoch 1189/6000: train_loss=13.0809, val_loss=15.1225, \n",
            "Epoch 1190/6000: train_loss=13.1443, val_loss=15.0733, \n",
            "Epoch 1191/6000: train_loss=13.4527, val_loss=17.3325, \n",
            "Epoch 1192/6000: train_loss=12.8723, val_loss=15.5991, \n",
            "Epoch 1193/6000: train_loss=13.1840, val_loss=15.3854, \n",
            "Epoch 1194/6000: train_loss=13.1358, val_loss=16.9366, \n",
            "Epoch 1195/6000: train_loss=12.8515, val_loss=15.7912, \n",
            "Epoch 1196/6000: train_loss=12.9712, val_loss=15.1326, \n",
            "Epoch 1197/6000: train_loss=13.1681, val_loss=16.6807, \n",
            "Epoch 1198/6000: train_loss=13.0050, val_loss=15.2057, \n",
            "Epoch 1199/6000: train_loss=12.8362, val_loss=15.9729, \n",
            "Epoch 1200/6000: train_loss=12.8328, val_loss=15.9928, \n",
            "Epoch 1201/6000: train_loss=12.8831, val_loss=15.3115, \n",
            "Epoch 1202/6000: train_loss=12.9425, val_loss=16.0609, \n",
            "Epoch 1203/6000: train_loss=12.8316, val_loss=15.3609, \n",
            "Epoch 1204/6000: train_loss=13.0662, val_loss=15.2612, \n",
            "Epoch 1205/6000: train_loss=13.2404, val_loss=17.4131, \n",
            "Epoch 1206/6000: train_loss=12.8066, val_loss=15.8036, \n",
            "Epoch 1207/6000: train_loss=12.8481, val_loss=15.1656, \n",
            "Epoch 1208/6000: train_loss=12.8318, val_loss=15.6757, \n",
            "Epoch 1209/6000: train_loss=12.8731, val_loss=15.1693, \n",
            "Epoch 1210/6000: train_loss=12.8539, val_loss=16.1423, \n",
            "Epoch 1211/6000: train_loss=12.8388, val_loss=16.1278, \n",
            "Epoch 1212/6000: train_loss=13.4100, val_loss=15.1597, \n",
            "Epoch 1213/6000: train_loss=12.7997, val_loss=16.0126, \n",
            "Epoch 1214/6000: train_loss=13.0221, val_loss=16.5891, \n",
            "Epoch 1215/6000: train_loss=13.1890, val_loss=15.1812, \n",
            "Epoch 1216/6000: train_loss=12.8777, val_loss=16.5326, \n",
            "Epoch 1217/6000: train_loss=12.7585, val_loss=16.0995, \n",
            "Epoch 1218/6000: train_loss=13.0455, val_loss=15.1197, \n",
            "Epoch 1219/6000: train_loss=12.9135, val_loss=16.3266, \n",
            "Epoch 1220/6000: train_loss=12.9591, val_loss=15.1690, \n",
            "Epoch 1221/6000: train_loss=12.7592, val_loss=15.3626, \n",
            "Epoch 1222/6000: train_loss=13.1454, val_loss=17.0193, \n",
            "Epoch 1223/6000: train_loss=12.8172, val_loss=15.1595, \n",
            "Epoch 1224/6000: train_loss=12.7624, val_loss=15.2635, \n",
            "Epoch 1225/6000: train_loss=12.8187, val_loss=16.2597, \n",
            "Epoch 1226/6000: train_loss=12.7836, val_loss=15.3936, \n",
            "Epoch 1227/6000: train_loss=12.8753, val_loss=15.0989, \n",
            "Epoch 1228/6000: train_loss=12.8647, val_loss=16.2688, \n",
            "Epoch 1229/6000: train_loss=12.7217, val_loss=15.5255, \n",
            "Epoch 1230/6000: train_loss=12.7612, val_loss=16.1606, \n",
            "Epoch 1231/6000: train_loss=12.7803, val_loss=16.4482, \n",
            "Epoch 1232/6000: train_loss=13.0225, val_loss=15.1540, \n",
            "Epoch 1233/6000: train_loss=12.6967, val_loss=15.7477, \n",
            "Epoch 1234/6000: train_loss=12.7805, val_loss=16.0872, \n",
            "Epoch 1235/6000: train_loss=12.7750, val_loss=15.3194, \n",
            "Epoch 1236/6000: train_loss=12.7313, val_loss=16.1852, \n",
            "Epoch 1237/6000: train_loss=12.6698, val_loss=15.8130, \n",
            "Epoch 1238/6000: train_loss=12.8662, val_loss=15.2467, \n",
            "Epoch 1239/6000: train_loss=12.7649, val_loss=16.3236, \n",
            "Epoch 1240/6000: train_loss=12.7341, val_loss=16.0739, \n",
            "Epoch 1241/6000: train_loss=12.9255, val_loss=14.9702, \n",
            "Epoch 1242/6000: train_loss=12.6841, val_loss=15.8143, \n",
            "Epoch 1243/6000: train_loss=12.6438, val_loss=15.7188, \n",
            "Epoch 1244/6000: train_loss=12.7409, val_loss=15.3959, \n",
            "Epoch 1245/6000: train_loss=12.9734, val_loss=16.7991, \n",
            "Epoch 1246/6000: train_loss=12.8933, val_loss=15.0115, \n",
            "Epoch 1247/6000: train_loss=12.6270, val_loss=15.4082, \n",
            "Epoch 1248/6000: train_loss=12.7730, val_loss=16.2614, \n",
            "Epoch 1249/6000: train_loss=12.9496, val_loss=14.9979, \n",
            "Epoch 1250/6000: train_loss=12.9639, val_loss=16.7873, \n",
            "Epoch 1251/6000: train_loss=12.6255, val_loss=15.8755, \n",
            "Epoch 1252/6000: train_loss=12.6487, val_loss=15.4511, \n",
            "Epoch 1253/6000: train_loss=12.6443, val_loss=15.5799, \n",
            "Epoch 1254/6000: train_loss=12.6804, val_loss=16.0612, \n",
            "Epoch 1255/6000: train_loss=12.8368, val_loss=15.0887, \n",
            "Epoch 1256/6000: train_loss=12.9522, val_loss=16.7230, \n",
            "Epoch 1257/6000: train_loss=12.6944, val_loss=15.2594, \n",
            "Epoch 1258/6000: train_loss=12.6524, val_loss=15.3657, \n",
            "Epoch 1259/6000: train_loss=12.9461, val_loss=16.9688, \n",
            "Epoch 1260/6000: train_loss=12.8565, val_loss=15.0922, \n",
            "Epoch 1261/6000: train_loss=12.7179, val_loss=16.1951, \n",
            "Epoch 1262/6000: train_loss=12.6155, val_loss=15.5055, \n",
            "Epoch 1263/6000: train_loss=12.9850, val_loss=14.7499, \n",
            "Epoch 1264/6000: train_loss=12.7556, val_loss=15.8503, \n",
            "Epoch 1265/6000: train_loss=12.7229, val_loss=14.9675, \n",
            "Epoch 1266/6000: train_loss=12.6442, val_loss=15.4851, \n",
            "Epoch 1267/6000: train_loss=13.3289, val_loss=17.8875, \n",
            "Epoch 1268/6000: train_loss=12.8824, val_loss=15.1739, \n",
            "Epoch 1269/6000: train_loss=12.6105, val_loss=15.1798, \n",
            "Epoch 1270/6000: train_loss=12.6547, val_loss=15.5479, \n",
            "Epoch 1271/6000: train_loss=12.6747, val_loss=15.1092, \n",
            "Epoch 1272/6000: train_loss=12.6010, val_loss=15.6972, \n",
            "Epoch 1273/6000: train_loss=12.6888, val_loss=16.3827, \n",
            "Epoch 1274/6000: train_loss=12.5621, val_loss=15.4820, \n",
            "Epoch 1275/6000: train_loss=12.6079, val_loss=14.8938, \n",
            "Epoch 1276/6000: train_loss=12.5800, val_loss=15.0299, \n",
            "Epoch 1277/6000: train_loss=12.9672, val_loss=16.7346, \n",
            "Epoch 1278/6000: train_loss=12.6379, val_loss=15.4556, \n",
            "Epoch 1279/6000: train_loss=12.5573, val_loss=16.0532, \n",
            "Epoch 1280/6000: train_loss=12.6445, val_loss=15.2352, \n",
            "Epoch 1281/6000: train_loss=12.5291, val_loss=15.2946, \n",
            "Epoch 1282/6000: train_loss=12.8664, val_loss=16.5892, \n",
            "Epoch 1283/6000: train_loss=12.8459, val_loss=14.9299, \n",
            "Epoch 1284/6000: train_loss=12.5754, val_loss=15.9764, \n",
            "Epoch 1285/6000: train_loss=12.5022, val_loss=15.4056, \n",
            "Epoch 1286/6000: train_loss=12.5759, val_loss=15.0958, \n",
            "Epoch 1287/6000: train_loss=12.5404, val_loss=15.6867, \n",
            "Epoch 1288/6000: train_loss=12.7352, val_loss=16.3243, \n",
            "Epoch 1289/6000: train_loss=12.7904, val_loss=14.9917, \n",
            "Epoch 1290/6000: train_loss=12.7639, val_loss=16.5758, \n",
            "Epoch 1291/6000: train_loss=12.4948, val_loss=15.4689, \n",
            "Epoch 1292/6000: train_loss=12.5383, val_loss=15.2566, \n",
            "Epoch 1293/6000: train_loss=12.8895, val_loss=16.7963, \n",
            "Epoch 1294/6000: train_loss=12.7942, val_loss=14.9289, \n",
            "Epoch 1295/6000: train_loss=12.4913, val_loss=15.1710, \n",
            "Epoch 1296/6000: train_loss=13.1607, val_loss=17.2476, \n",
            "Epoch 1297/6000: train_loss=13.3698, val_loss=14.8443, \n",
            "Epoch 1298/6000: train_loss=12.6498, val_loss=16.4302, \n",
            "Epoch 1299/6000: train_loss=12.6166, val_loss=16.2555, \n",
            "Epoch 1300/6000: train_loss=12.6823, val_loss=15.0314, \n",
            "Epoch 1301/6000: train_loss=12.5514, val_loss=15.9536, \n",
            "Epoch 1302/6000: train_loss=12.5122, val_loss=15.0488, \n",
            "Epoch 1303/6000: train_loss=12.4963, val_loss=15.6098, \n",
            "Epoch 1304/6000: train_loss=12.4616, val_loss=15.5335, \n",
            "Epoch 1305/6000: train_loss=12.5435, val_loss=15.0123, \n",
            "Epoch 1306/6000: train_loss=12.4722, val_loss=15.6574, \n",
            "Epoch 1307/6000: train_loss=12.4616, val_loss=15.7407, \n",
            "Epoch 1308/6000: train_loss=12.7560, val_loss=15.0199, \n",
            "Epoch 1309/6000: train_loss=12.4396, val_loss=15.5371, \n",
            "Epoch 1310/6000: train_loss=12.4493, val_loss=15.5549, \n",
            "Epoch 1311/6000: train_loss=12.4371, val_loss=15.5780, \n",
            "Epoch 1312/6000: train_loss=12.8030, val_loss=15.1069, \n",
            "Epoch 1313/6000: train_loss=12.5431, val_loss=16.3143, \n",
            "Epoch 1314/6000: train_loss=12.6675, val_loss=16.4275, \n",
            "Epoch 1315/6000: train_loss=12.7436, val_loss=14.6643, \n",
            "Epoch 1316/6000: train_loss=12.5442, val_loss=15.8074, \n",
            "Epoch 1317/6000: train_loss=12.4329, val_loss=15.7860, \n",
            "Epoch 1318/6000: train_loss=12.5739, val_loss=15.2343, \n",
            "Epoch 1319/6000: train_loss=12.4694, val_loss=16.1737, \n",
            "Epoch 1320/6000: train_loss=12.4476, val_loss=15.2023, \n",
            "Epoch 1321/6000: train_loss=12.4268, val_loss=14.9060, \n",
            "Epoch 1322/6000: train_loss=12.6380, val_loss=16.0997, \n",
            "Epoch 1323/6000: train_loss=12.4463, val_loss=14.9554, \n",
            "Epoch 1324/6000: train_loss=12.3792, val_loss=15.4968, \n",
            "Epoch 1325/6000: train_loss=12.4069, val_loss=15.6941, \n",
            "Epoch 1326/6000: train_loss=12.6562, val_loss=14.9590, \n",
            "Epoch 1327/6000: train_loss=12.4133, val_loss=15.5477, \n",
            "Epoch 1328/6000: train_loss=12.6934, val_loss=16.2783, \n",
            "Epoch 1329/6000: train_loss=12.5189, val_loss=14.7821, \n",
            "Epoch 1330/6000: train_loss=12.4670, val_loss=15.8245, \n",
            "Epoch 1331/6000: train_loss=12.4037, val_loss=15.6133, \n",
            "Epoch 1332/6000: train_loss=12.6720, val_loss=14.6953, \n",
            "Epoch 1333/6000: train_loss=12.5385, val_loss=15.9227, \n",
            "Epoch 1334/6000: train_loss=12.3644, val_loss=15.0473, \n",
            "Epoch 1335/6000: train_loss=12.3618, val_loss=15.5077, \n",
            "Epoch 1336/6000: train_loss=12.3613, val_loss=15.2672, \n",
            "Epoch 1337/6000: train_loss=12.3449, val_loss=15.1258, \n",
            "Epoch 1338/6000: train_loss=12.5736, val_loss=14.6500, \n",
            "Epoch 1339/6000: train_loss=12.3513, val_loss=15.2378, \n",
            "Epoch 1340/6000: train_loss=12.4204, val_loss=15.2936, \n",
            "Epoch 1341/6000: train_loss=12.5189, val_loss=16.3300, \n",
            "Epoch 1342/6000: train_loss=12.3495, val_loss=15.0711, \n",
            "Epoch 1343/6000: train_loss=12.3398, val_loss=14.9587, \n",
            "Epoch 1344/6000: train_loss=12.3294, val_loss=15.1322, \n",
            "Epoch 1345/6000: train_loss=12.3326, val_loss=15.1267, \n",
            "Epoch 1346/6000: train_loss=12.3446, val_loss=15.2879, \n",
            "Epoch 1347/6000: train_loss=12.4266, val_loss=16.1380, \n",
            "Epoch 1348/6000: train_loss=12.4441, val_loss=14.8648, \n",
            "Epoch 1349/6000: train_loss=12.3035, val_loss=15.2320, \n",
            "Epoch 1350/6000: train_loss=12.3182, val_loss=15.0354, \n",
            "Epoch 1351/6000: train_loss=12.3082, val_loss=15.1270, \n",
            "Epoch 1352/6000: train_loss=12.3669, val_loss=15.8032, \n",
            "Epoch 1353/6000: train_loss=12.3423, val_loss=15.1555, \n",
            "Epoch 1354/6000: train_loss=12.2928, val_loss=15.3233, \n",
            "Epoch 1355/6000: train_loss=12.7911, val_loss=16.5306, \n",
            "Epoch 1356/6000: train_loss=13.1014, val_loss=14.5791, \n",
            "Epoch 1357/6000: train_loss=12.3725, val_loss=16.0783, \n",
            "Epoch 1358/6000: train_loss=12.3144, val_loss=15.6906, \n",
            "Epoch 1359/6000: train_loss=12.2794, val_loss=15.1480, \n",
            "Epoch 1360/6000: train_loss=12.3826, val_loss=15.3542, \n",
            "Epoch 1361/6000: train_loss=12.3048, val_loss=15.0044, \n",
            "Epoch 1362/6000: train_loss=12.7594, val_loss=17.0932, \n",
            "Epoch 1363/6000: train_loss=12.3531, val_loss=15.1339, \n",
            "Epoch 1364/6000: train_loss=12.3111, val_loss=15.0959, \n",
            "Epoch 1365/6000: train_loss=13.2689, val_loss=17.6386, \n",
            "Epoch 1366/6000: train_loss=12.9073, val_loss=14.5634, \n",
            "Epoch 1367/6000: train_loss=12.2617, val_loss=15.3991, \n",
            "Epoch 1368/6000: train_loss=12.8805, val_loss=16.9065, \n",
            "Epoch 1369/6000: train_loss=12.9634, val_loss=14.5972, \n",
            "Epoch 1370/6000: train_loss=12.5347, val_loss=16.2967, \n",
            "Epoch 1371/6000: train_loss=12.2442, val_loss=15.2219, \n",
            "Epoch 1372/6000: train_loss=12.3900, val_loss=15.0655, \n",
            "Epoch 1373/6000: train_loss=12.5658, val_loss=16.6296, \n",
            "Epoch 1374/6000: train_loss=12.4194, val_loss=14.9202, \n",
            "Epoch 1375/6000: train_loss=12.2354, val_loss=15.1522, \n",
            "Epoch 1376/6000: train_loss=12.3083, val_loss=15.5303, \n",
            "Epoch 1377/6000: train_loss=12.9207, val_loss=14.5462, \n",
            "Epoch 1378/6000: train_loss=13.2268, val_loss=17.7838, \n",
            "Epoch 1379/6000: train_loss=12.5308, val_loss=15.1028, \n",
            "Epoch 1380/6000: train_loss=12.2575, val_loss=15.8826, \n",
            "Epoch 1381/6000: train_loss=13.0763, val_loss=17.6106, \n",
            "Epoch 1382/6000: train_loss=13.2661, val_loss=14.7646, \n",
            "Epoch 1383/6000: train_loss=12.4825, val_loss=16.0066, \n",
            "Epoch 1384/6000: train_loss=12.2058, val_loss=15.2084, \n",
            "Epoch 1385/6000: train_loss=12.3597, val_loss=14.8785, \n",
            "Epoch 1386/6000: train_loss=13.1226, val_loss=17.5420, \n",
            "Epoch 1387/6000: train_loss=13.2831, val_loss=14.7507, \n",
            "Epoch 1388/6000: train_loss=12.3047, val_loss=15.6780, \n",
            "Epoch 1389/6000: train_loss=12.2989, val_loss=15.4670, \n",
            "Epoch 1390/6000: train_loss=13.1606, val_loss=14.4725, \n",
            "Epoch 1391/6000: train_loss=14.0038, val_loss=18.7644, \n",
            "Epoch 1392/6000: train_loss=13.2871, val_loss=14.8292, \n",
            "Epoch 1393/6000: train_loss=12.3226, val_loss=14.9636, \n",
            "Epoch 1394/6000: train_loss=13.1120, val_loss=17.4709, \n",
            "Epoch 1395/6000: train_loss=13.5561, val_loss=14.6114, \n",
            "Epoch 1396/6000: train_loss=12.7766, val_loss=17.0072, \n",
            "Epoch 1397/6000: train_loss=12.3734, val_loss=14.7853, \n",
            "Epoch 1398/6000: train_loss=12.1855, val_loss=14.9602, \n",
            "Epoch 1399/6000: train_loss=12.9465, val_loss=17.0561, \n",
            "Epoch 1400/6000: train_loss=13.6720, val_loss=14.7234, \n",
            "Epoch 1401/6000: train_loss=13.6851, val_loss=18.3065, \n",
            "Epoch 1402/6000: train_loss=12.2915, val_loss=14.6891, \n",
            "Epoch 1403/6000: train_loss=12.3161, val_loss=15.0009, \n",
            "Epoch 1404/6000: train_loss=12.8739, val_loss=17.4663, \n",
            "Epoch 1405/6000: train_loss=12.3748, val_loss=14.8726, \n",
            "Epoch 1406/6000: train_loss=12.2574, val_loss=15.6055, \n",
            "Epoch 1407/6000: train_loss=12.6020, val_loss=14.3655, \n",
            "Epoch 1408/6000: train_loss=12.1454, val_loss=15.1562, \n",
            "Epoch 1409/6000: train_loss=12.3531, val_loss=16.1218, \n",
            "Epoch 1410/6000: train_loss=13.0764, val_loss=14.7357, \n",
            "Epoch 1411/6000: train_loss=12.2945, val_loss=16.0185, \n",
            "Epoch 1412/6000: train_loss=12.1549, val_loss=15.2459, \n",
            "Epoch 1413/6000: train_loss=12.1712, val_loss=15.4724, \n",
            "Epoch 1414/6000: train_loss=12.1324, val_loss=15.0915, \n",
            "Epoch 1415/6000: train_loss=12.2627, val_loss=14.6745, \n",
            "Epoch 1416/6000: train_loss=12.7128, val_loss=16.7826, \n",
            "Epoch 1417/6000: train_loss=12.4501, val_loss=14.5205, \n",
            "Epoch 1418/6000: train_loss=12.4112, val_loss=16.2261, \n",
            "Epoch 1419/6000: train_loss=12.1161, val_loss=15.2310, \n",
            "Epoch 1420/6000: train_loss=12.8574, val_loss=14.6761, \n",
            "Epoch 1421/6000: train_loss=12.7895, val_loss=16.9883, \n",
            "Epoch 1422/6000: train_loss=12.3597, val_loss=14.6381, \n",
            "Epoch 1423/6000: train_loss=12.1179, val_loss=15.2575, \n",
            "Epoch 1424/6000: train_loss=12.4418, val_loss=16.2667, \n",
            "Epoch 1425/6000: train_loss=12.6622, val_loss=14.7029, \n",
            "Epoch 1426/6000: train_loss=12.8072, val_loss=16.9565, \n",
            "Epoch 1427/6000: train_loss=12.2816, val_loss=14.3393, \n",
            "Epoch 1428/6000: train_loss=12.1140, val_loss=14.9553, \n",
            "Epoch 1429/6000: train_loss=12.1056, val_loss=15.5506, \n",
            "Epoch 1430/6000: train_loss=12.2233, val_loss=15.2001, \n",
            "Epoch 1431/6000: train_loss=12.9450, val_loss=17.5800, \n",
            "Epoch 1432/6000: train_loss=12.2612, val_loss=14.5507, \n",
            "Epoch 1433/6000: train_loss=12.1148, val_loss=14.5660, \n",
            "Epoch 1434/6000: train_loss=13.0715, val_loss=17.3746, \n",
            "Epoch 1435/6000: train_loss=12.8533, val_loss=14.9041, \n",
            "Epoch 1436/6000: train_loss=12.0929, val_loss=15.1965, \n",
            "Epoch 1437/6000: train_loss=12.4084, val_loss=16.2741, \n",
            "Epoch 1438/6000: train_loss=12.4358, val_loss=14.2856, \n",
            "Epoch 1439/6000: train_loss=12.1526, val_loss=14.6326, \n",
            "Epoch 1440/6000: train_loss=12.8233, val_loss=17.3961, \n",
            "Epoch 1441/6000: train_loss=12.6559, val_loss=14.7918, \n",
            "Epoch 1442/6000: train_loss=12.0605, val_loss=15.4116, \n",
            "Epoch 1443/6000: train_loss=12.3762, val_loss=15.9910, \n",
            "Epoch 1444/6000: train_loss=12.6382, val_loss=14.4091, \n",
            "Epoch 1445/6000: train_loss=12.2552, val_loss=16.0637, \n",
            "Epoch 1446/6000: train_loss=12.0759, val_loss=14.9185, \n",
            "Epoch 1447/6000: train_loss=12.5076, val_loss=14.4814, \n",
            "Epoch 1448/6000: train_loss=13.5362, val_loss=18.1418, \n",
            "Epoch 1449/6000: train_loss=12.8324, val_loss=14.4014, \n",
            "Epoch 1450/6000: train_loss=12.1488, val_loss=15.5439, \n",
            "Epoch 1451/6000: train_loss=12.0265, val_loss=15.0754, \n",
            "Epoch 1452/6000: train_loss=12.2856, val_loss=14.6517, \n",
            "Epoch 1453/6000: train_loss=12.5704, val_loss=16.4824, \n",
            "Epoch 1454/6000: train_loss=12.3383, val_loss=14.1986, \n",
            "Epoch 1455/6000: train_loss=12.0595, val_loss=15.1834, \n",
            "Epoch 1456/6000: train_loss=12.3492, val_loss=16.2533, \n",
            "Epoch 1457/6000: train_loss=13.6012, val_loss=14.8807, \n",
            "Epoch 1458/6000: train_loss=12.8696, val_loss=17.0494, \n",
            "Epoch 1459/6000: train_loss=12.0780, val_loss=14.5006, \n",
            "Epoch 1460/6000: train_loss=12.1094, val_loss=14.4342, \n",
            "Epoch 1461/6000: train_loss=12.3961, val_loss=16.4117, \n",
            "Epoch 1462/6000: train_loss=12.4444, val_loss=14.6470, \n",
            "Epoch 1463/6000: train_loss=12.0701, val_loss=15.4321, \n",
            "Epoch 1464/6000: train_loss=12.0070, val_loss=15.2110, \n",
            "Epoch 1465/6000: train_loss=11.9871, val_loss=14.8642, \n",
            "Epoch 1466/6000: train_loss=11.9833, val_loss=15.1424, \n",
            "Epoch 1467/6000: train_loss=11.9968, val_loss=14.9240, \n",
            "Epoch 1468/6000: train_loss=12.0322, val_loss=15.3572, \n",
            "Epoch 1469/6000: train_loss=11.9892, val_loss=14.7179, \n",
            "Epoch 1470/6000: train_loss=12.0950, val_loss=15.6257, \n",
            "Epoch 1471/6000: train_loss=12.2068, val_loss=14.5812, \n",
            "Epoch 1472/6000: train_loss=11.9627, val_loss=14.9409, \n",
            "Epoch 1473/6000: train_loss=11.9848, val_loss=14.6806, \n",
            "Epoch 1474/6000: train_loss=11.9688, val_loss=14.8015, \n",
            "Epoch 1475/6000: train_loss=12.0276, val_loss=15.5735, \n",
            "Epoch 1476/6000: train_loss=11.9812, val_loss=14.7974, \n",
            "Epoch 1477/6000: train_loss=11.9735, val_loss=15.1468, \n",
            "Epoch 1478/6000: train_loss=11.9679, val_loss=14.9816, \n",
            "Epoch 1479/6000: train_loss=12.2231, val_loss=14.4921, \n",
            "Epoch 1480/6000: train_loss=13.1295, val_loss=17.9184, \n",
            "Epoch 1481/6000: train_loss=12.4475, val_loss=14.4869, \n",
            "Epoch 1482/6000: train_loss=11.9365, val_loss=14.9922, \n",
            "Epoch 1483/6000: train_loss=12.5672, val_loss=16.5027, \n",
            "Epoch 1484/6000: train_loss=14.3851, val_loss=14.8782, \n",
            "Epoch 1485/6000: train_loss=12.9530, val_loss=17.2226, \n",
            "Epoch 1486/6000: train_loss=12.0143, val_loss=14.7905, \n",
            "Epoch 1487/6000: train_loss=12.9503, val_loss=14.5521, \n",
            "Epoch 1488/6000: train_loss=14.6730, val_loss=19.9239, \n",
            "Epoch 1489/6000: train_loss=13.0839, val_loss=14.2718, \n",
            "Epoch 1490/6000: train_loss=11.9248, val_loss=14.9039, \n",
            "Epoch 1491/6000: train_loss=12.4852, val_loss=16.5257, \n",
            "Epoch 1492/6000: train_loss=12.3009, val_loss=14.6182, \n",
            "Epoch 1493/6000: train_loss=11.9714, val_loss=15.5172, \n",
            "Epoch 1494/6000: train_loss=11.9305, val_loss=14.6762, \n",
            "Epoch 1495/6000: train_loss=11.9145, val_loss=14.7722, \n",
            "Epoch 1496/6000: train_loss=11.9392, val_loss=15.2991, \n",
            "Epoch 1497/6000: train_loss=12.0346, val_loss=14.5957, \n",
            "Epoch 1498/6000: train_loss=11.9668, val_loss=15.4546, \n",
            "Epoch 1499/6000: train_loss=11.8986, val_loss=15.0219, \n",
            "Epoch 1500/6000: train_loss=11.9131, val_loss=15.2364, \n",
            "Epoch 1501/6000: train_loss=11.8884, val_loss=14.8317, \n",
            "Epoch 1502/6000: train_loss=11.9565, val_loss=14.3965, \n",
            "Epoch 1503/6000: train_loss=11.9206, val_loss=15.1721, \n",
            "Epoch 1504/6000: train_loss=11.9056, val_loss=14.9998, \n",
            "Epoch 1505/6000: train_loss=11.9473, val_loss=14.8620, \n",
            "Epoch 1506/6000: train_loss=11.9370, val_loss=15.3278, \n",
            "Epoch 1507/6000: train_loss=12.3529, val_loss=14.1887, \n",
            "Epoch 1508/6000: train_loss=12.3664, val_loss=16.1854, \n",
            "Epoch 1509/6000: train_loss=11.8681, val_loss=14.9751, \n",
            "Epoch 1510/6000: train_loss=12.2465, val_loss=14.6737, \n",
            "Epoch 1511/6000: train_loss=11.9869, val_loss=15.6998, \n",
            "Epoch 1512/6000: train_loss=11.8653, val_loss=14.7204, \n",
            "Epoch 1513/6000: train_loss=11.9381, val_loss=14.4740, \n",
            "Epoch 1514/6000: train_loss=12.0150, val_loss=15.4569, \n",
            "Epoch 1515/6000: train_loss=11.8445, val_loss=14.9794, \n",
            "Epoch 1516/6000: train_loss=12.1614, val_loss=14.5318, \n",
            "Epoch 1517/6000: train_loss=12.7944, val_loss=17.1257, \n",
            "Epoch 1518/6000: train_loss=12.4791, val_loss=14.2359, \n",
            "Epoch 1519/6000: train_loss=11.8814, val_loss=14.9859, \n",
            "Epoch 1520/6000: train_loss=11.9773, val_loss=15.4829, \n",
            "Epoch 1521/6000: train_loss=12.3498, val_loss=14.5172, \n",
            "Epoch 1522/6000: train_loss=12.2902, val_loss=16.4007, \n",
            "Epoch 1523/6000: train_loss=11.8416, val_loss=14.7364, \n",
            "Epoch 1524/6000: train_loss=12.1457, val_loss=14.3792, \n",
            "Epoch 1525/6000: train_loss=12.3914, val_loss=16.6589, \n",
            "Epoch 1526/6000: train_loss=12.1743, val_loss=14.5349, \n",
            "Epoch 1527/6000: train_loss=11.8138, val_loss=14.8922, \n",
            "Epoch 1528/6000: train_loss=11.8161, val_loss=14.9246, \n",
            "Epoch 1529/6000: train_loss=12.1392, val_loss=14.2500, \n",
            "Epoch 1530/6000: train_loss=12.3835, val_loss=16.4187, \n",
            "Epoch 1531/6000: train_loss=12.0077, val_loss=14.4398, \n",
            "Epoch 1532/6000: train_loss=11.8044, val_loss=14.9587, \n",
            "Epoch 1533/6000: train_loss=11.9761, val_loss=15.5725, \n",
            "Epoch 1534/6000: train_loss=12.4529, val_loss=14.3513, \n",
            "Epoch 1535/6000: train_loss=12.1658, val_loss=15.9800, \n",
            "Epoch 1536/6000: train_loss=11.7944, val_loss=14.8005, \n",
            "Epoch 1537/6000: train_loss=11.8241, val_loss=15.2169, \n",
            "Epoch 1538/6000: train_loss=11.7927, val_loss=14.6423, \n",
            "Epoch 1539/6000: train_loss=11.9152, val_loss=14.2544, \n",
            "Epoch 1540/6000: train_loss=12.1083, val_loss=15.6509, \n",
            "Epoch 1541/6000: train_loss=11.8004, val_loss=14.8284, \n",
            "Epoch 1542/6000: train_loss=11.9253, val_loss=14.9689, \n",
            "Epoch 1543/6000: train_loss=12.0526, val_loss=16.1512, \n",
            "Epoch 1544/6000: train_loss=11.9320, val_loss=14.4633, \n",
            "Epoch 1545/6000: train_loss=12.1387, val_loss=15.7044, \n",
            "Epoch 1546/6000: train_loss=12.0640, val_loss=14.0198, \n",
            "Epoch 1547/6000: train_loss=11.8074, val_loss=15.1956, \n",
            "Epoch 1548/6000: train_loss=11.7839, val_loss=15.3434, \n",
            "Epoch 1549/6000: train_loss=11.9596, val_loss=14.6727, \n",
            "Epoch 1550/6000: train_loss=12.4673, val_loss=16.8852, \n",
            "Epoch 1551/6000: train_loss=12.1612, val_loss=14.1555, \n",
            "Epoch 1552/6000: train_loss=12.0015, val_loss=15.5074, \n",
            "Epoch 1553/6000: train_loss=11.7655, val_loss=14.6095, \n",
            "Epoch 1554/6000: train_loss=11.8599, val_loss=14.9015, \n",
            "Epoch 1555/6000: train_loss=12.3929, val_loss=16.8736, \n",
            "Epoch 1556/6000: train_loss=12.2506, val_loss=14.4564, \n",
            "Epoch 1557/6000: train_loss=11.9154, val_loss=15.1894, \n",
            "Epoch 1558/6000: train_loss=11.7446, val_loss=14.8896, \n",
            "Epoch 1559/6000: train_loss=12.0719, val_loss=14.5635, \n",
            "Epoch 1560/6000: train_loss=12.6492, val_loss=17.3281, \n",
            "Epoch 1561/6000: train_loss=12.6353, val_loss=14.3344, \n",
            "Epoch 1562/6000: train_loss=11.8494, val_loss=15.1343, \n",
            "Epoch 1563/6000: train_loss=11.7403, val_loss=14.8911, \n",
            "Epoch 1564/6000: train_loss=11.7354, val_loss=14.8816, \n",
            "Epoch 1565/6000: train_loss=11.7750, val_loss=15.2035, \n",
            "Epoch 1566/6000: train_loss=11.8305, val_loss=14.4387, \n",
            "Epoch 1567/6000: train_loss=11.7584, val_loss=14.8804, \n",
            "Epoch 1568/6000: train_loss=11.9644, val_loss=14.1856, \n",
            "Epoch 1569/6000: train_loss=11.8636, val_loss=15.2710, \n",
            "Epoch 1570/6000: train_loss=11.7414, val_loss=15.1612, \n",
            "Epoch 1571/6000: train_loss=12.0293, val_loss=14.3255, \n",
            "Epoch 1572/6000: train_loss=12.8919, val_loss=17.4366, \n",
            "Epoch 1573/6000: train_loss=12.7115, val_loss=14.5035, \n",
            "Epoch 1574/6000: train_loss=11.7270, val_loss=15.0853, \n",
            "Epoch 1575/6000: train_loss=11.7506, val_loss=15.3120, \n",
            "Epoch 1576/6000: train_loss=12.4599, val_loss=14.3418, \n",
            "Epoch 1577/6000: train_loss=13.4916, val_loss=18.1202, \n",
            "Epoch 1578/6000: train_loss=12.9083, val_loss=14.0252, \n",
            "Epoch 1579/6000: train_loss=11.7778, val_loss=15.2871, \n",
            "Epoch 1580/6000: train_loss=11.7419, val_loss=15.3065, \n",
            "Epoch 1581/6000: train_loss=13.0734, val_loss=14.8607, \n",
            "Epoch 1582/6000: train_loss=14.8880, val_loss=20.4317, \n",
            "Epoch 1583/6000: train_loss=13.3325, val_loss=14.3585, \n",
            "Epoch 1584/6000: train_loss=11.7013, val_loss=14.7639, \n",
            "Epoch 1585/6000: train_loss=12.5249, val_loss=16.7759, \n",
            "Epoch 1586/6000: train_loss=12.0557, val_loss=14.3506, \n",
            "Epoch 1587/6000: train_loss=11.7780, val_loss=15.3698, \n",
            "Epoch 1588/6000: train_loss=11.7005, val_loss=15.0575, \n",
            "Epoch 1589/6000: train_loss=11.7299, val_loss=14.5851, \n",
            "Epoch 1590/6000: train_loss=11.8282, val_loss=15.5264, \n",
            "Epoch 1591/6000: train_loss=11.9339, val_loss=14.1590, \n",
            "Epoch 1592/6000: train_loss=11.7751, val_loss=15.1405, \n",
            "Epoch 1593/6000: train_loss=11.6753, val_loss=14.4661, \n",
            "Epoch 1594/6000: train_loss=11.6733, val_loss=14.4438, \n",
            "Epoch 1595/6000: train_loss=11.7396, val_loss=15.4475, \n",
            "Epoch 1596/6000: train_loss=12.1578, val_loss=14.4665, \n",
            "Epoch 1597/6000: train_loss=12.0166, val_loss=15.9951, \n",
            "Epoch 1598/6000: train_loss=11.6798, val_loss=14.3715, \n",
            "Epoch 1599/6000: train_loss=11.6623, val_loss=14.6188, \n",
            "Epoch 1600/6000: train_loss=11.7509, val_loss=15.6198, \n",
            "Epoch 1601/6000: train_loss=11.8859, val_loss=14.7640, \n",
            "Epoch 1602/6000: train_loss=11.6339, val_loss=14.9626, \n",
            "Epoch 1603/6000: train_loss=11.7412, val_loss=14.9903, \n",
            "Epoch 1604/6000: train_loss=11.6591, val_loss=14.2534, \n",
            "Epoch 1605/6000: train_loss=11.6660, val_loss=14.6240, \n",
            "Epoch 1606/6000: train_loss=12.0568, val_loss=14.0306, \n",
            "Epoch 1607/6000: train_loss=11.6327, val_loss=15.0353, \n",
            "Epoch 1608/6000: train_loss=11.6162, val_loss=14.7586, \n",
            "Epoch 1609/6000: train_loss=11.6483, val_loss=14.5187, \n",
            "Epoch 1610/6000: train_loss=11.6162, val_loss=14.6229, \n",
            "Epoch 1611/6000: train_loss=11.6167, val_loss=14.6339, \n",
            "Epoch 1612/6000: train_loss=11.6997, val_loss=15.2377, \n",
            "Epoch 1613/6000: train_loss=11.7002, val_loss=14.3583, \n",
            "Epoch 1614/6000: train_loss=11.6174, val_loss=14.7471, \n",
            "Epoch 1615/6000: train_loss=11.7137, val_loss=14.1659, \n",
            "Epoch 1616/6000: train_loss=11.8623, val_loss=15.5227, \n",
            "Epoch 1617/6000: train_loss=11.6030, val_loss=14.7846, \n",
            "Epoch 1618/6000: train_loss=11.9540, val_loss=14.4215, \n",
            "Epoch 1619/6000: train_loss=11.8929, val_loss=15.9805, \n",
            "Epoch 1620/6000: train_loss=11.7142, val_loss=14.4368, \n",
            "Epoch 1621/6000: train_loss=11.6142, val_loss=14.8695, \n",
            "Epoch 1622/6000: train_loss=11.6136, val_loss=14.7076, \n",
            "Epoch 1623/6000: train_loss=11.5990, val_loss=14.5305, \n",
            "Epoch 1624/6000: train_loss=11.6414, val_loss=14.9798, \n",
            "Epoch 1625/6000: train_loss=11.6092, val_loss=14.8547, \n",
            "Epoch 1626/6000: train_loss=11.6186, val_loss=14.4905, \n",
            "Epoch 1627/6000: train_loss=11.6868, val_loss=15.1593, \n",
            "Epoch 1628/6000: train_loss=11.9524, val_loss=14.0730, \n",
            "Epoch 1629/6000: train_loss=11.8026, val_loss=15.5656, \n",
            "Epoch 1630/6000: train_loss=11.6941, val_loss=14.5097, \n",
            "Epoch 1631/6000: train_loss=12.0659, val_loss=16.2356, \n",
            "Epoch 1632/6000: train_loss=11.7433, val_loss=14.2577, \n",
            "Epoch 1633/6000: train_loss=11.7179, val_loss=15.4500, \n",
            "Epoch 1634/6000: train_loss=11.5553, val_loss=14.6589, \n",
            "Epoch 1635/6000: train_loss=11.6064, val_loss=14.3352, \n",
            "Epoch 1636/6000: train_loss=11.7863, val_loss=15.3572, \n",
            "Epoch 1637/6000: train_loss=11.7363, val_loss=14.0618, \n",
            "Epoch 1638/6000: train_loss=11.6452, val_loss=15.0800, \n",
            "Epoch 1639/6000: train_loss=11.5536, val_loss=14.5261, \n",
            "Epoch 1640/6000: train_loss=11.6104, val_loss=14.1858, \n",
            "Epoch 1641/6000: train_loss=11.6177, val_loss=14.9404, \n",
            "Epoch 1642/6000: train_loss=11.5902, val_loss=14.2547, \n",
            "Epoch 1643/6000: train_loss=11.5655, val_loss=15.0597, \n",
            "Epoch 1644/6000: train_loss=11.6218, val_loss=14.4401, \n",
            "Epoch 1645/6000: train_loss=11.5539, val_loss=14.5702, \n",
            "Epoch 1646/6000: train_loss=11.6616, val_loss=15.3386, \n",
            "Epoch 1647/6000: train_loss=11.7073, val_loss=14.1810, \n",
            "Epoch 1648/6000: train_loss=11.9404, val_loss=15.8168, \n",
            "Epoch 1649/6000: train_loss=11.9644, val_loss=14.0499, \n",
            "Epoch 1650/6000: train_loss=11.6711, val_loss=15.3713, \n",
            "Epoch 1651/6000: train_loss=11.6195, val_loss=14.2334, \n",
            "Epoch 1652/6000: train_loss=11.5104, val_loss=14.6048, \n",
            "Epoch 1653/6000: train_loss=11.6966, val_loss=15.3929, \n",
            "Epoch 1654/6000: train_loss=12.0835, val_loss=13.8416, \n",
            "Epoch 1655/6000: train_loss=12.2153, val_loss=16.3223, \n",
            "Epoch 1656/6000: train_loss=11.8871, val_loss=14.3303, \n",
            "Epoch 1657/6000: train_loss=11.6603, val_loss=15.5391, \n",
            "Epoch 1658/6000: train_loss=11.4971, val_loss=14.6237, \n",
            "Epoch 1659/6000: train_loss=11.6515, val_loss=14.0166, \n",
            "Epoch 1660/6000: train_loss=11.6986, val_loss=15.1885, \n",
            "Epoch 1661/6000: train_loss=12.5703, val_loss=14.1047, \n",
            "Epoch 1662/6000: train_loss=11.9333, val_loss=15.9863, \n",
            "Epoch 1663/6000: train_loss=11.5194, val_loss=14.2606, \n",
            "Epoch 1664/6000: train_loss=11.6652, val_loss=13.8983, \n",
            "Epoch 1665/6000: train_loss=12.4244, val_loss=16.4737, \n",
            "Epoch 1666/6000: train_loss=12.4843, val_loss=14.2771, \n",
            "Epoch 1667/6000: train_loss=12.2794, val_loss=16.8780, \n",
            "Epoch 1668/6000: train_loss=12.0182, val_loss=14.6030, \n",
            "Epoch 1669/6000: train_loss=11.4999, val_loss=14.5414, \n",
            "Epoch 1670/6000: train_loss=11.8506, val_loss=15.5044, \n",
            "Epoch 1671/6000: train_loss=11.9348, val_loss=13.7465, \n",
            "Epoch 1672/6000: train_loss=12.0215, val_loss=16.0373, \n",
            "Epoch 1673/6000: train_loss=12.0405, val_loss=14.2001, \n",
            "Epoch 1674/6000: train_loss=11.6765, val_loss=15.5873, \n",
            "Epoch 1675/6000: train_loss=11.5441, val_loss=14.3529, \n",
            "Epoch 1676/6000: train_loss=11.5705, val_loss=14.0488, \n",
            "Epoch 1677/6000: train_loss=12.1395, val_loss=16.0723, \n",
            "Epoch 1678/6000: train_loss=11.8738, val_loss=14.0726, \n",
            "Epoch 1679/6000: train_loss=11.9619, val_loss=16.0586, \n",
            "Epoch 1680/6000: train_loss=11.4562, val_loss=14.7174, \n",
            "Epoch 1681/6000: train_loss=11.4950, val_loss=14.2720, \n",
            "Epoch 1682/6000: train_loss=11.4835, val_loss=14.9705, \n",
            "Epoch 1683/6000: train_loss=11.4728, val_loss=15.1688, \n",
            "Epoch 1684/6000: train_loss=11.4625, val_loss=15.0439, \n",
            "Epoch 1685/6000: train_loss=11.4524, val_loss=14.2976, \n",
            "Epoch 1686/6000: train_loss=11.4681, val_loss=14.1146, \n",
            "Epoch 1687/6000: train_loss=11.4451, val_loss=14.5027, \n",
            "Epoch 1688/6000: train_loss=11.4472, val_loss=14.9288, \n",
            "Epoch 1689/6000: train_loss=11.8456, val_loss=14.0903, \n",
            "Epoch 1690/6000: train_loss=11.5366, val_loss=14.8651, \n",
            "Epoch 1691/6000: train_loss=11.7790, val_loss=13.7421, \n",
            "Epoch 1692/6000: train_loss=11.7575, val_loss=15.4021, \n",
            "Epoch 1693/6000: train_loss=11.5232, val_loss=14.1181, \n",
            "Epoch 1694/6000: train_loss=11.4199, val_loss=14.7802, \n",
            "Epoch 1695/6000: train_loss=11.5153, val_loss=15.1016, \n",
            "Epoch 1696/6000: train_loss=11.5568, val_loss=14.0155, \n",
            "Epoch 1697/6000: train_loss=11.9661, val_loss=15.9282, \n",
            "Epoch 1698/6000: train_loss=11.6285, val_loss=14.2027, \n",
            "Epoch 1699/6000: train_loss=12.2671, val_loss=16.6822, \n",
            "Epoch 1700/6000: train_loss=11.6717, val_loss=13.8640, \n",
            "Epoch 1701/6000: train_loss=11.4486, val_loss=14.4076, \n",
            "Epoch 1702/6000: train_loss=11.5851, val_loss=15.0369, \n",
            "Epoch 1703/6000: train_loss=12.9440, val_loss=14.3498, \n",
            "Epoch 1704/6000: train_loss=12.7670, val_loss=17.7131, \n",
            "Epoch 1705/6000: train_loss=12.4179, val_loss=14.4294, \n",
            "Epoch 1706/6000: train_loss=11.5156, val_loss=14.9164, \n",
            "Epoch 1707/6000: train_loss=11.4300, val_loss=14.4825, \n",
            "Epoch 1708/6000: train_loss=11.5452, val_loss=13.8557, \n",
            "Epoch 1709/6000: train_loss=11.9176, val_loss=15.7768, \n",
            "Epoch 1710/6000: train_loss=11.4989, val_loss=13.9067, \n",
            "Epoch 1711/6000: train_loss=11.5934, val_loss=15.2017, \n",
            "Epoch 1712/6000: train_loss=11.5498, val_loss=14.5684, \n",
            "Epoch 1713/6000: train_loss=11.5243, val_loss=15.4216, \n",
            "Epoch 1714/6000: train_loss=11.3724, val_loss=14.4401, \n",
            "Epoch 1715/6000: train_loss=11.6713, val_loss=13.5528, \n",
            "Epoch 1716/6000: train_loss=11.7092, val_loss=15.0089, \n",
            "Epoch 1717/6000: train_loss=11.8036, val_loss=13.6328, \n",
            "Epoch 1718/6000: train_loss=11.4236, val_loss=14.9678, \n",
            "Epoch 1719/6000: train_loss=11.4031, val_loss=14.8680, \n",
            "Epoch 1720/6000: train_loss=11.6690, val_loss=13.7311, \n",
            "Epoch 1721/6000: train_loss=11.4724, val_loss=14.3383, \n",
            "Epoch 1722/6000: train_loss=11.3699, val_loss=14.2683, \n",
            "Epoch 1723/6000: train_loss=11.4608, val_loss=15.2288, \n",
            "Epoch 1724/6000: train_loss=11.4596, val_loss=15.1166, \n",
            "Epoch 1725/6000: train_loss=11.6287, val_loss=13.7274, \n",
            "Epoch 1726/6000: train_loss=11.9209, val_loss=15.6971, \n",
            "Epoch 1727/6000: train_loss=11.4536, val_loss=14.1750, \n",
            "Epoch 1728/6000: train_loss=11.3815, val_loss=15.0863, \n",
            "Epoch 1729/6000: train_loss=11.4136, val_loss=15.2196, \n",
            "Epoch 1730/6000: train_loss=11.3783, val_loss=14.0367, \n",
            "Epoch 1731/6000: train_loss=11.5878, val_loss=14.8479, \n",
            "Epoch 1732/6000: train_loss=11.5440, val_loss=13.4533, \n",
            "Epoch 1733/6000: train_loss=11.6633, val_loss=15.2703, \n",
            "Epoch 1734/6000: train_loss=11.3718, val_loss=14.7323, \n",
            "Epoch 1735/6000: train_loss=11.5373, val_loss=14.5671, \n",
            "Epoch 1736/6000: train_loss=11.8152, val_loss=15.8308, \n",
            "Epoch 1737/6000: train_loss=11.6133, val_loss=13.5736, \n",
            "Epoch 1738/6000: train_loss=11.5032, val_loss=14.9843, \n",
            "Epoch 1739/6000: train_loss=11.3569, val_loss=15.0500, \n",
            "Epoch 1740/6000: train_loss=11.4773, val_loss=14.7372, \n",
            "Epoch 1741/6000: train_loss=11.3091, val_loss=14.4602, \n",
            "Epoch 1742/6000: train_loss=11.3807, val_loss=14.1759, \n",
            "Epoch 1743/6000: train_loss=11.3823, val_loss=13.7466, \n",
            "Epoch 1744/6000: train_loss=11.3492, val_loss=14.8641, \n",
            "Epoch 1745/6000: train_loss=11.3847, val_loss=14.8219, \n",
            "Epoch 1746/6000: train_loss=11.3043, val_loss=14.6522, \n",
            "Epoch 1747/6000: train_loss=11.3359, val_loss=13.9098, \n",
            "Epoch 1748/6000: train_loss=11.4129, val_loss=13.8125, \n",
            "Epoch 1749/6000: train_loss=11.3008, val_loss=14.5558, \n",
            "Epoch 1750/6000: train_loss=11.2899, val_loss=14.4845, \n",
            "Epoch 1751/6000: train_loss=11.2884, val_loss=14.4525, \n",
            "Epoch 1752/6000: train_loss=11.3304, val_loss=14.6314, \n",
            "Epoch 1753/6000: train_loss=11.3605, val_loss=14.0325, \n",
            "Epoch 1754/6000: train_loss=11.2739, val_loss=14.4219, \n",
            "Epoch 1755/6000: train_loss=11.4809, val_loss=14.0582, \n",
            "Epoch 1756/6000: train_loss=11.2889, val_loss=14.3257, \n",
            "Epoch 1757/6000: train_loss=11.3130, val_loss=14.0236, \n",
            "Epoch 1758/6000: train_loss=11.2798, val_loss=14.0485, \n",
            "Epoch 1759/6000: train_loss=11.4088, val_loss=14.8232, \n",
            "Epoch 1760/6000: train_loss=11.3658, val_loss=13.9967, \n",
            "Epoch 1761/6000: train_loss=11.2932, val_loss=14.6889, \n",
            "Epoch 1762/6000: train_loss=11.2685, val_loss=14.6939, \n",
            "Epoch 1763/6000: train_loss=11.3543, val_loss=14.9401, \n",
            "Epoch 1764/6000: train_loss=11.2643, val_loss=14.1712, \n",
            "Epoch 1765/6000: train_loss=11.2890, val_loss=13.9519, \n",
            "Epoch 1766/6000: train_loss=11.6246, val_loss=15.4791, \n",
            "Epoch 1767/6000: train_loss=11.8987, val_loss=13.9225, \n",
            "Epoch 1768/6000: train_loss=11.3869, val_loss=14.8448, \n",
            "Epoch 1769/6000: train_loss=11.2881, val_loss=13.9397, \n",
            "Epoch 1770/6000: train_loss=11.2661, val_loss=14.0058, \n",
            "Epoch 1771/6000: train_loss=11.4052, val_loss=14.9475, \n",
            "Epoch 1772/6000: train_loss=11.2855, val_loss=14.2689, \n",
            "Epoch 1773/6000: train_loss=11.3251, val_loss=14.3198, \n",
            "Epoch 1774/6000: train_loss=12.2968, val_loss=16.6816, \n",
            "Epoch 1775/6000: train_loss=12.4220, val_loss=13.5136, \n",
            "Epoch 1776/6000: train_loss=12.9265, val_loss=17.3492, \n",
            "Epoch 1777/6000: train_loss=11.2772, val_loss=14.3211, \n",
            "Epoch 1778/6000: train_loss=11.7031, val_loss=14.3012, \n",
            "Epoch 1779/6000: train_loss=12.0646, val_loss=16.4186, \n",
            "Epoch 1780/6000: train_loss=11.9915, val_loss=13.6002, \n",
            "Epoch 1781/6000: train_loss=11.7522, val_loss=15.5523, \n",
            "Epoch 1782/6000: train_loss=11.6812, val_loss=13.9753, \n",
            "Epoch 1783/6000: train_loss=11.2670, val_loss=14.6528, \n",
            "Epoch 1784/6000: train_loss=11.2505, val_loss=14.5883, \n",
            "Epoch 1785/6000: train_loss=11.3393, val_loss=13.8949, \n",
            "Epoch 1786/6000: train_loss=11.2742, val_loss=14.5874, \n",
            "Epoch 1787/6000: train_loss=11.2094, val_loss=14.3963, \n",
            "Epoch 1788/6000: train_loss=11.2390, val_loss=14.6565, \n",
            "Epoch 1789/6000: train_loss=11.2207, val_loss=14.5091, \n",
            "Epoch 1790/6000: train_loss=11.2242, val_loss=14.2346, \n",
            "Epoch 1791/6000: train_loss=11.2737, val_loss=13.8402, \n",
            "Epoch 1792/6000: train_loss=11.2206, val_loss=14.6016, \n",
            "Epoch 1793/6000: train_loss=11.1962, val_loss=14.6023, \n",
            "Epoch 1794/6000: train_loss=11.2077, val_loss=14.5325, \n",
            "Epoch 1795/6000: train_loss=11.2251, val_loss=13.8531, \n",
            "Epoch 1796/6000: train_loss=11.2867, val_loss=14.5390, \n",
            "Epoch 1797/6000: train_loss=11.3279, val_loss=13.8774, \n",
            "Epoch 1798/6000: train_loss=11.5524, val_loss=15.5522, \n",
            "Epoch 1799/6000: train_loss=11.6764, val_loss=13.7751, \n",
            "Epoch 1800/6000: train_loss=11.2244, val_loss=13.9489, \n",
            "Epoch 1801/6000: train_loss=11.5275, val_loss=15.5175, \n",
            "Epoch 1802/6000: train_loss=11.5251, val_loss=13.9702, \n",
            "Epoch 1803/6000: train_loss=11.7131, val_loss=15.5576, \n",
            "Epoch 1804/6000: train_loss=11.3751, val_loss=13.5239, \n",
            "Epoch 1805/6000: train_loss=11.2435, val_loss=13.5751, \n",
            "Epoch 1806/6000: train_loss=11.5709, val_loss=15.4000, \n",
            "Epoch 1807/6000: train_loss=12.1176, val_loss=14.0218, \n",
            "Epoch 1808/6000: train_loss=11.6141, val_loss=15.7398, \n",
            "Epoch 1809/6000: train_loss=11.3913, val_loss=15.0648, \n",
            "Epoch 1810/6000: train_loss=11.4231, val_loss=13.7194, \n",
            "Epoch 1811/6000: train_loss=11.8887, val_loss=16.1946, \n",
            "Epoch 1812/6000: train_loss=11.7175, val_loss=13.9386, \n",
            "Epoch 1813/6000: train_loss=11.1983, val_loss=14.7449, \n",
            "Epoch 1814/6000: train_loss=11.1590, val_loss=14.3510, \n",
            "Epoch 1815/6000: train_loss=11.1510, val_loss=14.3111, \n",
            "Epoch 1816/6000: train_loss=11.6208, val_loss=15.6980, \n",
            "Epoch 1817/6000: train_loss=11.1691, val_loss=13.8981, \n",
            "Epoch 1818/6000: train_loss=11.3938, val_loss=13.6833, \n",
            "Epoch 1819/6000: train_loss=11.3445, val_loss=14.9370, \n",
            "Epoch 1820/6000: train_loss=11.2886, val_loss=14.2276, \n",
            "Epoch 1821/6000: train_loss=11.2001, val_loss=14.8198, \n",
            "Epoch 1822/6000: train_loss=11.1556, val_loss=13.9474, \n",
            "Epoch 1823/6000: train_loss=11.2286, val_loss=13.5218, \n",
            "Epoch 1824/6000: train_loss=11.2446, val_loss=14.6779, \n",
            "Epoch 1825/6000: train_loss=11.3549, val_loss=14.2079, \n",
            "Epoch 1826/6000: train_loss=11.1912, val_loss=14.9033, \n",
            "Epoch 1827/6000: train_loss=11.1482, val_loss=14.0409, \n",
            "Epoch 1828/6000: train_loss=11.1863, val_loss=14.2842, \n",
            "Epoch 1829/6000: train_loss=11.3439, val_loss=13.4096, \n",
            "Epoch 1830/6000: train_loss=11.3059, val_loss=14.8646, \n",
            "Epoch 1831/6000: train_loss=11.3001, val_loss=13.9708, \n",
            "Epoch 1832/6000: train_loss=11.1225, val_loss=14.7079, \n",
            "Epoch 1833/6000: train_loss=11.1342, val_loss=14.6314, \n",
            "Epoch 1834/6000: train_loss=11.1057, val_loss=14.0996, \n",
            "Epoch 1835/6000: train_loss=11.1118, val_loss=14.0180, \n",
            "Epoch 1836/6000: train_loss=11.0991, val_loss=14.1962, \n",
            "Epoch 1837/6000: train_loss=11.3297, val_loss=13.7335, \n",
            "Epoch 1838/6000: train_loss=11.4100, val_loss=15.0702, \n",
            "Epoch 1839/6000: train_loss=11.8915, val_loss=13.4609, \n",
            "Epoch 1840/6000: train_loss=11.5920, val_loss=15.5174, \n",
            "Epoch 1841/6000: train_loss=11.2344, val_loss=13.8532, \n",
            "Epoch 1842/6000: train_loss=11.4251, val_loss=13.7631, \n",
            "Epoch 1843/6000: train_loss=11.8154, val_loss=15.9245, \n",
            "Epoch 1844/6000: train_loss=12.3433, val_loss=13.4093, \n",
            "Epoch 1845/6000: train_loss=12.4243, val_loss=16.9447, \n",
            "Epoch 1846/6000: train_loss=11.2909, val_loss=13.9611, \n",
            "Epoch 1847/6000: train_loss=11.3549, val_loss=13.8922, \n",
            "Epoch 1848/6000: train_loss=11.8164, val_loss=15.8584, \n",
            "Epoch 1849/6000: train_loss=11.4369, val_loss=13.6055, \n",
            "Epoch 1850/6000: train_loss=11.1015, val_loss=14.5263, \n",
            "Epoch 1851/6000: train_loss=11.0832, val_loss=13.8417, \n",
            "Epoch 1852/6000: train_loss=11.1151, val_loss=13.6160, \n",
            "Epoch 1853/6000: train_loss=11.3820, val_loss=15.0570, \n",
            "Epoch 1854/6000: train_loss=11.1092, val_loss=14.1043, \n",
            "Epoch 1855/6000: train_loss=11.1100, val_loss=14.6170, \n",
            "Epoch 1856/6000: train_loss=11.1632, val_loss=14.5966, \n",
            "Epoch 1857/6000: train_loss=11.3971, val_loss=13.7052, \n",
            "Epoch 1858/6000: train_loss=11.3812, val_loss=15.2717, \n",
            "Epoch 1859/6000: train_loss=12.0889, val_loss=13.8149, \n",
            "Epoch 1860/6000: train_loss=12.0855, val_loss=16.5190, \n",
            "Epoch 1861/6000: train_loss=11.2877, val_loss=13.9382, \n",
            "Epoch 1862/6000: train_loss=11.5507, val_loss=13.6016, \n",
            "Epoch 1863/6000: train_loss=11.5769, val_loss=15.4261, \n",
            "Epoch 1864/6000: train_loss=12.2733, val_loss=13.7640, \n",
            "Epoch 1865/6000: train_loss=11.6681, val_loss=16.0199, \n",
            "Epoch 1866/6000: train_loss=11.0902, val_loss=14.0368, \n",
            "Epoch 1867/6000: train_loss=11.0440, val_loss=14.0677, \n",
            "Epoch 1868/6000: train_loss=11.0863, val_loss=14.0718, \n",
            "Epoch 1869/6000: train_loss=11.1213, val_loss=13.8560, \n",
            "Epoch 1870/6000: train_loss=11.6070, val_loss=15.9343, \n",
            "Epoch 1871/6000: train_loss=12.0135, val_loss=14.0321, \n",
            "Epoch 1872/6000: train_loss=11.3281, val_loss=15.3016, \n",
            "Epoch 1873/6000: train_loss=11.1463, val_loss=13.6060, \n",
            "Epoch 1874/6000: train_loss=11.2239, val_loss=13.4854, \n",
            "Epoch 1875/6000: train_loss=11.3264, val_loss=15.2835, \n",
            "Epoch 1876/6000: train_loss=13.0529, val_loss=14.4585, \n",
            "Epoch 1877/6000: train_loss=13.5589, val_loss=18.9522, \n",
            "Epoch 1878/6000: train_loss=11.5516, val_loss=14.0301, \n",
            "Epoch 1879/6000: train_loss=11.0508, val_loss=14.4725, \n",
            "Epoch 1880/6000: train_loss=11.0189, val_loss=13.9318, \n",
            "Epoch 1881/6000: train_loss=11.0100, val_loss=13.9583, \n",
            "Epoch 1882/6000: train_loss=11.0103, val_loss=14.0159, \n",
            "Epoch 1883/6000: train_loss=11.6745, val_loss=13.6746, \n",
            "Epoch 1884/6000: train_loss=11.5567, val_loss=15.8096, \n",
            "Epoch 1885/6000: train_loss=11.3775, val_loss=13.7996, \n",
            "Epoch 1886/6000: train_loss=10.9974, val_loss=13.8811, \n",
            "Epoch 1887/6000: train_loss=11.0199, val_loss=13.6227, \n",
            "Epoch 1888/6000: train_loss=11.0326, val_loss=13.9464, \n",
            "Epoch 1889/6000: train_loss=11.0660, val_loss=14.8710, \n",
            "Epoch 1890/6000: train_loss=10.9919, val_loss=13.9704, \n",
            "Epoch 1891/6000: train_loss=11.1460, val_loss=14.5458, \n",
            "Epoch 1892/6000: train_loss=11.2201, val_loss=13.4966, \n",
            "Epoch 1893/6000: train_loss=11.0275, val_loss=14.3736, \n",
            "Epoch 1894/6000: train_loss=11.0678, val_loss=13.7772, \n",
            "Epoch 1895/6000: train_loss=11.0078, val_loss=13.8948, \n",
            "Epoch 1896/6000: train_loss=11.2731, val_loss=15.1910, \n",
            "Epoch 1897/6000: train_loss=11.0198, val_loss=13.6893, \n",
            "Epoch 1898/6000: train_loss=11.0511, val_loss=13.7493, \n",
            "Epoch 1899/6000: train_loss=11.0304, val_loss=14.5284, \n",
            "Epoch 1900/6000: train_loss=10.9567, val_loss=13.9775, \n",
            "Epoch 1901/6000: train_loss=10.9717, val_loss=13.8621, \n",
            "Epoch 1902/6000: train_loss=11.1077, val_loss=14.6944, \n",
            "Epoch 1903/6000: train_loss=11.0104, val_loss=13.6557, \n",
            "Epoch 1904/6000: train_loss=10.9890, val_loss=14.0879, \n",
            "Epoch 1905/6000: train_loss=10.9597, val_loss=14.0073, \n",
            "Epoch 1906/6000: train_loss=10.9612, val_loss=14.0540, \n",
            "Epoch 1907/6000: train_loss=10.9434, val_loss=14.2399, \n",
            "Epoch 1908/6000: train_loss=10.9456, val_loss=13.9228, \n",
            "Epoch 1909/6000: train_loss=11.0544, val_loss=13.7435, \n",
            "Epoch 1910/6000: train_loss=10.9598, val_loss=14.3005, \n",
            "Epoch 1911/6000: train_loss=11.1779, val_loss=14.9591, \n",
            "Epoch 1912/6000: train_loss=10.9616, val_loss=13.8556, \n",
            "Epoch 1913/6000: train_loss=11.0635, val_loss=14.7008, \n",
            "Epoch 1914/6000: train_loss=11.6681, val_loss=13.5587, \n",
            "Epoch 1915/6000: train_loss=11.5535, val_loss=15.4520, \n",
            "Epoch 1916/6000: train_loss=11.9272, val_loss=13.3966, \n",
            "Epoch 1917/6000: train_loss=11.5754, val_loss=15.5838, \n",
            "Epoch 1918/6000: train_loss=11.4565, val_loss=13.8192, \n",
            "Epoch 1919/6000: train_loss=10.9891, val_loss=14.3563, \n",
            "Epoch 1920/6000: train_loss=11.5359, val_loss=15.6172, \n",
            "Epoch 1921/6000: train_loss=12.1114, val_loss=13.1321, \n",
            "Epoch 1922/6000: train_loss=11.4894, val_loss=15.1454, \n",
            "Epoch 1923/6000: train_loss=11.5465, val_loss=13.3634, \n",
            "Epoch 1924/6000: train_loss=11.1541, val_loss=14.8752, \n",
            "Epoch 1925/6000: train_loss=10.9180, val_loss=14.0068, \n",
            "Epoch 1926/6000: train_loss=11.1446, val_loss=13.8009, \n",
            "Epoch 1927/6000: train_loss=11.3380, val_loss=15.4374, \n",
            "Epoch 1928/6000: train_loss=11.0226, val_loss=14.0229, \n",
            "Epoch 1929/6000: train_loss=11.0149, val_loss=14.9048, \n",
            "Epoch 1930/6000: train_loss=10.9417, val_loss=13.5896, \n",
            "Epoch 1931/6000: train_loss=11.0275, val_loss=14.2212, \n",
            "Epoch 1932/6000: train_loss=10.9553, val_loss=14.0208, \n",
            "Epoch 1933/6000: train_loss=10.9258, val_loss=13.8710, \n",
            "Epoch 1934/6000: train_loss=11.2317, val_loss=15.4171, \n",
            "Epoch 1935/6000: train_loss=11.5118, val_loss=13.7744, \n",
            "Epoch 1936/6000: train_loss=11.1232, val_loss=14.8082, \n",
            "Epoch 1937/6000: train_loss=10.8968, val_loss=13.9975, \n",
            "Epoch 1938/6000: train_loss=10.9457, val_loss=13.4554, \n",
            "Epoch 1939/6000: train_loss=11.2134, val_loss=14.8621, \n",
            "Epoch 1940/6000: train_loss=11.2672, val_loss=13.6632, \n",
            "Epoch 1941/6000: train_loss=10.9443, val_loss=14.0127, \n",
            "Epoch 1942/6000: train_loss=10.9773, val_loss=14.5794, \n",
            "Epoch 1943/6000: train_loss=12.0642, val_loss=13.8249, \n",
            "Epoch 1944/6000: train_loss=11.5011, val_loss=15.5723, \n",
            "Epoch 1945/6000: train_loss=11.0930, val_loss=13.4210, \n",
            "Epoch 1946/6000: train_loss=10.8870, val_loss=14.0582, \n",
            "Epoch 1947/6000: train_loss=10.8640, val_loss=13.9196, \n",
            "Epoch 1948/6000: train_loss=10.9588, val_loss=13.8808, \n",
            "Epoch 1949/6000: train_loss=10.9808, val_loss=14.7818, \n",
            "Epoch 1950/6000: train_loss=11.2052, val_loss=13.6393, \n",
            "Epoch 1951/6000: train_loss=10.9576, val_loss=14.4257, \n",
            "Epoch 1952/6000: train_loss=10.8898, val_loss=13.5514, \n",
            "Epoch 1953/6000: train_loss=10.8987, val_loss=14.1362, \n",
            "Epoch 1954/6000: train_loss=10.8727, val_loss=13.8364, \n",
            "Epoch 1955/6000: train_loss=10.8842, val_loss=14.0206, \n",
            "Epoch 1956/6000: train_loss=11.0341, val_loss=14.6898, \n",
            "Epoch 1957/6000: train_loss=10.9632, val_loss=13.2592, \n",
            "Epoch 1958/6000: train_loss=10.8401, val_loss=13.6302, \n",
            "Epoch 1959/6000: train_loss=10.9943, val_loss=14.5871, \n",
            "Epoch 1960/6000: train_loss=10.8661, val_loss=13.8374, \n",
            "Epoch 1961/6000: train_loss=10.8915, val_loss=13.7742, \n",
            "Epoch 1962/6000: train_loss=10.8293, val_loss=13.8182, \n",
            "Epoch 1963/6000: train_loss=10.8346, val_loss=13.6251, \n",
            "Epoch 1964/6000: train_loss=10.9484, val_loss=14.5882, \n",
            "Epoch 1965/6000: train_loss=11.3721, val_loss=13.5434, \n",
            "Epoch 1966/6000: train_loss=10.9319, val_loss=14.2935, \n",
            "Epoch 1967/6000: train_loss=11.0214, val_loss=13.2242, \n",
            "Epoch 1968/6000: train_loss=10.8188, val_loss=13.8509, \n",
            "Epoch 1969/6000: train_loss=11.3873, val_loss=13.3661, \n",
            "Epoch 1970/6000: train_loss=10.8563, val_loss=13.6574, \n",
            "Epoch 1971/6000: train_loss=10.9107, val_loss=14.5420, \n",
            "Epoch 1972/6000: train_loss=10.9785, val_loss=13.4902, \n",
            "Epoch 1973/6000: train_loss=10.9048, val_loss=14.2213, \n",
            "Epoch 1974/6000: train_loss=10.8100, val_loss=13.7820, \n",
            "Epoch 1975/6000: train_loss=10.8298, val_loss=13.8383, \n",
            "Epoch 1976/6000: train_loss=11.3144, val_loss=15.5299, \n",
            "Epoch 1977/6000: train_loss=10.8897, val_loss=13.4008, \n",
            "Epoch 1978/6000: train_loss=11.0349, val_loss=14.1716, \n",
            "Epoch 1979/6000: train_loss=10.9817, val_loss=13.2727, \n",
            "Epoch 1980/6000: train_loss=10.8104, val_loss=13.8800, \n",
            "Epoch 1981/6000: train_loss=10.8661, val_loss=14.5060, \n",
            "Epoch 1982/6000: train_loss=11.1236, val_loss=13.4819, \n",
            "Epoch 1983/6000: train_loss=13.0498, val_loss=18.2042, \n",
            "Epoch 1984/6000: train_loss=11.6772, val_loss=13.6105, \n",
            "Epoch 1985/6000: train_loss=11.4067, val_loss=15.6225, \n",
            "Epoch 1986/6000: train_loss=10.9059, val_loss=13.6098, \n",
            "Epoch 1987/6000: train_loss=11.0932, val_loss=13.6913, \n",
            "Epoch 1988/6000: train_loss=11.6990, val_loss=16.1540, \n",
            "Epoch 1989/6000: train_loss=11.9950, val_loss=13.2205, \n",
            "Epoch 1990/6000: train_loss=12.3522, val_loss=16.6781, \n",
            "Epoch 1991/6000: train_loss=11.2686, val_loss=13.3195, \n",
            "Epoch 1992/6000: train_loss=10.7935, val_loss=14.0765, \n",
            "Epoch 1993/6000: train_loss=11.0015, val_loss=14.7644, \n",
            "Epoch 1994/6000: train_loss=11.5101, val_loss=13.2729, \n",
            "Epoch 1995/6000: train_loss=11.3828, val_loss=15.1537, \n",
            "Epoch 1996/6000: train_loss=11.1840, val_loss=13.2332, \n",
            "Epoch 1997/6000: train_loss=11.5400, val_loss=15.9923, \n",
            "Epoch 1998/6000: train_loss=11.0720, val_loss=13.9083, \n",
            "Epoch 1999/6000: train_loss=10.7713, val_loss=14.0931, \n",
            "Epoch 2000/6000: train_loss=10.7751, val_loss=13.7328, \n",
            "Epoch 2001/6000: train_loss=11.0080, val_loss=13.0712, \n",
            "Epoch 2002/6000: train_loss=11.7784, val_loss=16.0562, \n",
            "Epoch 2003/6000: train_loss=11.7862, val_loss=13.7900, \n",
            "Epoch 2004/6000: train_loss=10.9372, val_loss=14.9808, \n",
            "Epoch 2005/6000: train_loss=11.0226, val_loss=15.2689, \n",
            "Epoch 2006/6000: train_loss=12.1675, val_loss=13.5637, \n",
            "Epoch 2007/6000: train_loss=12.8599, val_loss=17.3334, \n",
            "Epoch 2008/6000: train_loss=11.5960, val_loss=13.1244, \n",
            "Epoch 2009/6000: train_loss=10.7597, val_loss=14.1396, \n",
            "Epoch 2010/6000: train_loss=10.7439, val_loss=14.0551, \n",
            "Epoch 2011/6000: train_loss=10.9565, val_loss=13.6034, \n",
            "Epoch 2012/6000: train_loss=10.9974, val_loss=14.7932, \n",
            "Epoch 2013/6000: train_loss=11.5225, val_loss=13.3366, \n",
            "Epoch 2014/6000: train_loss=11.1203, val_loss=15.0011, \n",
            "Epoch 2015/6000: train_loss=10.7486, val_loss=13.5461, \n",
            "Epoch 2016/6000: train_loss=10.7267, val_loss=13.4917, \n",
            "Epoch 2017/6000: train_loss=11.0240, val_loss=14.4825, \n",
            "Epoch 2018/6000: train_loss=11.9603, val_loss=13.8909, \n",
            "Epoch 2019/6000: train_loss=11.5407, val_loss=16.2297, \n",
            "Epoch 2020/6000: train_loss=10.9496, val_loss=13.4443, \n",
            "Epoch 2021/6000: train_loss=10.7293, val_loss=13.4781, \n",
            "Epoch 2022/6000: train_loss=10.9948, val_loss=14.5887, \n",
            "Epoch 2023/6000: train_loss=11.4446, val_loss=13.2421, \n",
            "Epoch 2024/6000: train_loss=11.2314, val_loss=15.0535, \n",
            "Epoch 2025/6000: train_loss=11.1799, val_loss=13.3890, \n",
            "Epoch 2026/6000: train_loss=10.9740, val_loss=14.8014, \n",
            "Epoch 2027/6000: train_loss=10.9312, val_loss=13.2934, \n",
            "Epoch 2028/6000: train_loss=11.0508, val_loss=14.7763, \n",
            "Epoch 2029/6000: train_loss=10.6899, val_loss=13.8331, \n",
            "Epoch 2030/6000: train_loss=10.9936, val_loss=13.4751, \n",
            "Epoch 2031/6000: train_loss=10.7270, val_loss=14.2568, \n",
            "Epoch 2032/6000: train_loss=10.6944, val_loss=13.6694, \n",
            "Epoch 2033/6000: train_loss=10.6765, val_loss=13.7273, \n",
            "Epoch 2034/6000: train_loss=10.7009, val_loss=13.7892, \n",
            "Epoch 2035/6000: train_loss=10.6725, val_loss=13.5587, \n",
            "Epoch 2036/6000: train_loss=10.8349, val_loss=14.3635, \n",
            "Epoch 2037/6000: train_loss=10.7783, val_loss=13.4336, \n",
            "Epoch 2038/6000: train_loss=10.6906, val_loss=13.6596, \n",
            "Epoch 2039/6000: train_loss=10.7155, val_loss=14.0021, \n",
            "Epoch 2040/6000: train_loss=10.7086, val_loss=13.8644, \n",
            "Epoch 2041/6000: train_loss=11.5493, val_loss=16.3415, \n",
            "Epoch 2042/6000: train_loss=12.0794, val_loss=13.6512, \n",
            "Epoch 2043/6000: train_loss=11.5707, val_loss=15.5176, \n",
            "Epoch 2044/6000: train_loss=11.6467, val_loss=13.0991, \n",
            "Epoch 2045/6000: train_loss=10.7705, val_loss=14.5083, \n",
            "Epoch 2046/6000: train_loss=10.9522, val_loss=15.1023, \n",
            "Epoch 2047/6000: train_loss=11.6875, val_loss=13.2418, \n",
            "Epoch 2048/6000: train_loss=11.2030, val_loss=14.9012, \n",
            "Epoch 2049/6000: train_loss=11.1141, val_loss=13.1302, \n",
            "Epoch 2050/6000: train_loss=11.0583, val_loss=15.0279, \n",
            "Epoch 2051/6000: train_loss=10.8799, val_loss=13.4079, \n",
            "Epoch 2052/6000: train_loss=10.6550, val_loss=13.6344, \n",
            "Epoch 2053/6000: train_loss=10.7138, val_loss=13.9252, \n",
            "Epoch 2054/6000: train_loss=11.1132, val_loss=13.4204, \n",
            "Epoch 2055/6000: train_loss=10.8214, val_loss=14.5866, \n",
            "Epoch 2056/6000: train_loss=10.7025, val_loss=13.4266, \n",
            "Epoch 2057/6000: train_loss=10.6555, val_loss=13.6648, \n",
            "Epoch 2058/6000: train_loss=10.6427, val_loss=13.6556, \n",
            "Epoch 2059/6000: train_loss=10.6828, val_loss=14.3501, \n",
            "Epoch 2060/6000: train_loss=10.9848, val_loss=13.4559, \n",
            "Epoch 2061/6000: train_loss=10.6299, val_loss=13.8243, \n",
            "Epoch 2062/6000: train_loss=10.8137, val_loss=13.2817, \n",
            "Epoch 2063/6000: train_loss=11.0195, val_loss=14.9544, \n",
            "Epoch 2064/6000: train_loss=10.7446, val_loss=13.1441, \n",
            "Epoch 2065/6000: train_loss=10.7237, val_loss=13.9377, \n",
            "Epoch 2066/6000: train_loss=10.7382, val_loss=13.2200, \n",
            "Epoch 2067/6000: train_loss=10.6411, val_loss=14.1479, \n",
            "Epoch 2068/6000: train_loss=10.7175, val_loss=13.6738, \n",
            "Epoch 2069/6000: train_loss=10.7129, val_loss=14.0423, \n",
            "Epoch 2070/6000: train_loss=10.6889, val_loss=13.0061, \n",
            "Epoch 2071/6000: train_loss=10.6055, val_loss=13.5430, \n",
            "Epoch 2072/6000: train_loss=10.7083, val_loss=13.2874, \n",
            "Epoch 2073/6000: train_loss=10.6207, val_loss=13.8949, \n",
            "Epoch 2074/6000: train_loss=11.2981, val_loss=13.1420, \n",
            "Epoch 2075/6000: train_loss=10.8485, val_loss=14.5641, \n",
            "Epoch 2076/6000: train_loss=10.6237, val_loss=13.8646, \n",
            "Epoch 2077/6000: train_loss=10.6437, val_loss=13.3026, \n",
            "Epoch 2078/6000: train_loss=10.7568, val_loss=14.2340, \n",
            "Epoch 2079/6000: train_loss=10.5887, val_loss=13.6091, \n",
            "Epoch 2080/6000: train_loss=10.6514, val_loss=13.9391, \n",
            "Epoch 2081/6000: train_loss=10.6471, val_loss=13.3116, \n",
            "Epoch 2082/6000: train_loss=10.6419, val_loss=13.5033, \n",
            "Epoch 2083/6000: train_loss=10.5761, val_loss=13.7073, \n",
            "Epoch 2084/6000: train_loss=10.5866, val_loss=13.4410, \n",
            "Epoch 2085/6000: train_loss=10.8049, val_loss=14.3501, \n",
            "Epoch 2086/6000: train_loss=11.4902, val_loss=13.0607, \n",
            "Epoch 2087/6000: train_loss=10.9378, val_loss=14.5702, \n",
            "Epoch 2088/6000: train_loss=10.9118, val_loss=13.1815, \n",
            "Epoch 2089/6000: train_loss=10.5689, val_loss=13.7035, \n",
            "Epoch 2090/6000: train_loss=10.6630, val_loss=14.1078, \n",
            "Epoch 2091/6000: train_loss=10.8583, val_loss=12.9196, \n",
            "Epoch 2092/6000: train_loss=10.8895, val_loss=14.6186, \n",
            "Epoch 2093/6000: train_loss=10.9389, val_loss=13.3780, \n",
            "Epoch 2094/6000: train_loss=10.7602, val_loss=14.5384, \n",
            "Epoch 2095/6000: train_loss=10.5564, val_loss=13.3398, \n",
            "Epoch 2096/6000: train_loss=10.5904, val_loss=13.7169, \n",
            "Epoch 2097/6000: train_loss=10.5492, val_loss=13.3285, \n",
            "Epoch 2098/6000: train_loss=10.5980, val_loss=13.1630, \n",
            "Epoch 2099/6000: train_loss=10.5891, val_loss=13.3902, \n",
            "Epoch 2100/6000: train_loss=11.1633, val_loss=15.3418, \n",
            "Epoch 2101/6000: train_loss=10.8185, val_loss=13.1892, \n",
            "Epoch 2102/6000: train_loss=10.6901, val_loss=14.1304, \n",
            "Epoch 2103/6000: train_loss=10.5531, val_loss=13.3639, \n",
            "Epoch 2104/6000: train_loss=11.1132, val_loss=13.2965, \n",
            "Epoch 2105/6000: train_loss=11.3141, val_loss=15.7499, \n",
            "Epoch 2106/6000: train_loss=10.5625, val_loss=13.6042, \n",
            "Epoch 2107/6000: train_loss=10.6781, val_loss=14.0084, \n",
            "Epoch 2108/6000: train_loss=10.5685, val_loss=13.2597, \n",
            "Epoch 2109/6000: train_loss=10.6154, val_loss=13.3257, \n",
            "Epoch 2110/6000: train_loss=10.7504, val_loss=14.5518, \n",
            "Epoch 2111/6000: train_loss=10.6477, val_loss=13.1079, \n",
            "Epoch 2112/6000: train_loss=10.7997, val_loss=13.9235, \n",
            "Epoch 2113/6000: train_loss=11.0373, val_loss=12.9000, \n",
            "Epoch 2114/6000: train_loss=10.8786, val_loss=14.9293, \n",
            "Epoch 2115/6000: train_loss=10.5921, val_loss=13.8917, \n",
            "Epoch 2116/6000: train_loss=10.5545, val_loss=13.8383, \n",
            "Epoch 2117/6000: train_loss=10.6314, val_loss=12.9228, \n",
            "Epoch 2118/6000: train_loss=10.5104, val_loss=13.6722, \n",
            "Epoch 2119/6000: train_loss=10.6141, val_loss=13.4466, \n",
            "Epoch 2120/6000: train_loss=10.5496, val_loss=13.2789, \n",
            "Epoch 2121/6000: train_loss=10.8046, val_loss=14.2947, \n",
            "Epoch 2122/6000: train_loss=10.9213, val_loss=12.7165, \n",
            "Epoch 2123/6000: train_loss=10.5338, val_loss=13.6726, \n",
            "Epoch 2124/6000: train_loss=10.6540, val_loss=13.3466, \n",
            "Epoch 2125/6000: train_loss=10.6908, val_loss=14.3352, \n",
            "Epoch 2126/6000: train_loss=10.6116, val_loss=12.9725, \n",
            "Epoch 2127/6000: train_loss=10.5699, val_loss=13.1867, \n",
            "Epoch 2128/6000: train_loss=10.6347, val_loss=14.1546, \n",
            "Epoch 2129/6000: train_loss=10.6042, val_loss=13.2224, \n",
            "Epoch 2130/6000: train_loss=10.5191, val_loss=13.1823, \n",
            "Epoch 2131/6000: train_loss=10.5387, val_loss=13.7189, \n",
            "Epoch 2132/6000: train_loss=10.4896, val_loss=13.1793, \n",
            "Epoch 2133/6000: train_loss=10.5534, val_loss=13.2446, \n",
            "Epoch 2134/6000: train_loss=10.5937, val_loss=14.4031, \n",
            "Epoch 2135/6000: train_loss=10.5511, val_loss=13.5597, \n",
            "Epoch 2136/6000: train_loss=10.5546, val_loss=13.8590, \n",
            "Epoch 2137/6000: train_loss=10.5099, val_loss=13.0708, \n",
            "Epoch 2138/6000: train_loss=10.4712, val_loss=13.1886, \n",
            "Epoch 2139/6000: train_loss=10.5871, val_loss=14.2027, \n",
            "Epoch 2140/6000: train_loss=10.5959, val_loss=13.1978, \n",
            "Epoch 2141/6000: train_loss=10.5274, val_loss=13.5501, \n",
            "Epoch 2142/6000: train_loss=10.6960, val_loss=12.9645, \n",
            "Epoch 2143/6000: train_loss=10.5781, val_loss=14.1146, \n",
            "Epoch 2144/6000: train_loss=10.4701, val_loss=13.5511, \n",
            "Epoch 2145/6000: train_loss=10.7631, val_loss=13.0799, \n",
            "Epoch 2146/6000: train_loss=11.0665, val_loss=14.9394, \n",
            "Epoch 2147/6000: train_loss=11.4892, val_loss=12.7805, \n",
            "Epoch 2148/6000: train_loss=11.9277, val_loss=16.3886, \n",
            "Epoch 2149/6000: train_loss=11.1052, val_loss=13.2508, \n",
            "Epoch 2150/6000: train_loss=10.4586, val_loss=13.7578, \n",
            "Epoch 2151/6000: train_loss=10.4494, val_loss=13.7804, \n",
            "Epoch 2152/6000: train_loss=11.2936, val_loss=12.9048, \n",
            "Epoch 2153/6000: train_loss=11.0033, val_loss=14.6465, \n",
            "Epoch 2154/6000: train_loss=11.7471, val_loss=12.8261, \n",
            "Epoch 2155/6000: train_loss=11.0404, val_loss=15.0234, \n",
            "Epoch 2156/6000: train_loss=10.8800, val_loss=13.1001, \n",
            "Epoch 2157/6000: train_loss=10.4973, val_loss=14.1206, \n",
            "Epoch 2158/6000: train_loss=10.9533, val_loss=13.1487, \n",
            "Epoch 2159/6000: train_loss=10.5615, val_loss=13.7298, \n",
            "Epoch 2160/6000: train_loss=10.4926, val_loss=13.2299, \n",
            "Epoch 2161/6000: train_loss=10.5879, val_loss=12.6098, \n",
            "Epoch 2162/6000: train_loss=10.8023, val_loss=14.7147, \n",
            "Epoch 2163/6000: train_loss=10.6575, val_loss=13.5072, \n",
            "Epoch 2164/6000: train_loss=10.6290, val_loss=14.1122, \n",
            "Epoch 2165/6000: train_loss=10.4485, val_loss=12.9081, \n",
            "Epoch 2166/6000: train_loss=10.5398, val_loss=13.9274, \n",
            "Epoch 2167/6000: train_loss=10.4378, val_loss=13.6893, \n",
            "Epoch 2168/6000: train_loss=10.5278, val_loss=13.3789, \n",
            "Epoch 2169/6000: train_loss=10.4027, val_loss=13.4125, \n",
            "Epoch 2170/6000: train_loss=10.4079, val_loss=13.1368, \n",
            "Epoch 2171/6000: train_loss=10.4069, val_loss=13.4040, \n",
            "Epoch 2172/6000: train_loss=10.4087, val_loss=13.3270, \n",
            "Epoch 2173/6000: train_loss=10.4270, val_loss=13.4415, \n",
            "Epoch 2174/6000: train_loss=10.4168, val_loss=12.9917, \n",
            "Epoch 2175/6000: train_loss=10.4152, val_loss=13.2146, \n",
            "Epoch 2176/6000: train_loss=10.5099, val_loss=13.9843, \n",
            "Epoch 2177/6000: train_loss=10.8019, val_loss=12.6782, \n",
            "Epoch 2178/6000: train_loss=10.9971, val_loss=14.8003, \n",
            "Epoch 2179/6000: train_loss=12.4497, val_loss=13.3441, \n",
            "Epoch 2180/6000: train_loss=12.8632, val_loss=18.0808, \n",
            "Epoch 2181/6000: train_loss=11.3738, val_loss=13.1030, \n",
            "Epoch 2182/6000: train_loss=10.7637, val_loss=14.0952, \n",
            "Epoch 2183/6000: train_loss=10.4656, val_loss=13.1978, \n",
            "Epoch 2184/6000: train_loss=10.4516, val_loss=13.2277, \n",
            "Epoch 2185/6000: train_loss=10.7464, val_loss=15.0430, \n",
            "Epoch 2186/6000: train_loss=11.2622, val_loss=13.6023, \n",
            "Epoch 2187/6000: train_loss=10.9482, val_loss=14.7507, \n",
            "Epoch 2188/6000: train_loss=11.1927, val_loss=12.5945, \n",
            "Epoch 2189/6000: train_loss=10.8812, val_loss=14.6359, \n",
            "Epoch 2190/6000: train_loss=10.5688, val_loss=14.1894, \n",
            "Epoch 2191/6000: train_loss=11.7238, val_loss=12.9874, \n",
            "Epoch 2192/6000: train_loss=11.6974, val_loss=16.3375, \n",
            "Epoch 2193/6000: train_loss=11.1308, val_loss=13.2173, \n",
            "Epoch 2194/6000: train_loss=11.1251, val_loss=15.1634, \n",
            "Epoch 2195/6000: train_loss=10.4933, val_loss=12.7839, \n",
            "Epoch 2196/6000: train_loss=10.3742, val_loss=13.1755, \n",
            "Epoch 2197/6000: train_loss=10.5295, val_loss=13.8144, \n",
            "Epoch 2198/6000: train_loss=11.1948, val_loss=13.1304, \n",
            "Epoch 2199/6000: train_loss=10.7036, val_loss=14.7614, \n",
            "Epoch 2200/6000: train_loss=10.6445, val_loss=12.8856, \n",
            "Epoch 2201/6000: train_loss=10.4234, val_loss=13.5698, \n",
            "Epoch 2202/6000: train_loss=10.4302, val_loss=13.6648, \n",
            "Epoch 2203/6000: train_loss=11.4253, val_loss=12.7355, \n",
            "Epoch 2204/6000: train_loss=11.6860, val_loss=16.2049, \n",
            "Epoch 2205/6000: train_loss=11.8113, val_loss=13.1381, \n",
            "Epoch 2206/6000: train_loss=11.1311, val_loss=14.8342, \n",
            "Epoch 2207/6000: train_loss=10.5186, val_loss=12.6728, \n",
            "Epoch 2208/6000: train_loss=10.4073, val_loss=12.9241, \n",
            "Epoch 2209/6000: train_loss=10.5682, val_loss=14.1294, \n",
            "Epoch 2210/6000: train_loss=10.9051, val_loss=12.6619, \n",
            "Epoch 2211/6000: train_loss=10.4586, val_loss=13.7991, \n",
            "Epoch 2212/6000: train_loss=10.5079, val_loss=13.2248, \n",
            "Epoch 2213/6000: train_loss=10.4064, val_loss=13.9298, \n",
            "Epoch 2214/6000: train_loss=10.3297, val_loss=13.0582, \n",
            "Epoch 2215/6000: train_loss=10.3742, val_loss=13.4481, \n",
            "Epoch 2216/6000: train_loss=10.3811, val_loss=13.1226, \n",
            "Epoch 2217/6000: train_loss=10.3309, val_loss=13.5615, \n",
            "Epoch 2218/6000: train_loss=10.3154, val_loss=13.2246, \n",
            "Epoch 2219/6000: train_loss=10.3626, val_loss=13.3225, \n",
            "Epoch 2220/6000: train_loss=10.3147, val_loss=13.2154, \n",
            "Epoch 2221/6000: train_loss=10.3112, val_loss=13.4002, \n",
            "Epoch 2222/6000: train_loss=10.3855, val_loss=13.4012, \n",
            "Epoch 2223/6000: train_loss=10.3564, val_loss=13.3331, \n",
            "Epoch 2224/6000: train_loss=10.4474, val_loss=13.8281, \n",
            "Epoch 2225/6000: train_loss=10.3412, val_loss=12.6641, \n",
            "Epoch 2226/6000: train_loss=10.3327, val_loss=12.9968, \n",
            "Epoch 2227/6000: train_loss=10.3397, val_loss=13.6029, \n",
            "Epoch 2228/6000: train_loss=10.3512, val_loss=13.6882, \n",
            "Epoch 2229/6000: train_loss=10.4210, val_loss=12.8983, \n",
            "Epoch 2230/6000: train_loss=10.2965, val_loss=13.4480, \n",
            "Epoch 2231/6000: train_loss=10.2947, val_loss=13.2062, \n",
            "Epoch 2232/6000: train_loss=10.3782, val_loss=13.0067, \n",
            "Epoch 2233/6000: train_loss=10.2811, val_loss=13.1325, \n",
            "Epoch 2234/6000: train_loss=10.2991, val_loss=12.8489, \n",
            "Epoch 2235/6000: train_loss=10.2905, val_loss=13.0904, \n",
            "Epoch 2236/6000: train_loss=10.2860, val_loss=13.5985, \n",
            "Epoch 2237/6000: train_loss=10.2819, val_loss=13.4954, \n",
            "Epoch 2238/6000: train_loss=10.4220, val_loss=13.8358, \n",
            "Epoch 2239/6000: train_loss=10.2899, val_loss=13.0340, \n",
            "Epoch 2240/6000: train_loss=10.3293, val_loss=12.9568, \n",
            "Epoch 2241/6000: train_loss=10.2855, val_loss=13.2979, \n",
            "Epoch 2242/6000: train_loss=10.4451, val_loss=14.3437, \n",
            "Epoch 2243/6000: train_loss=10.4199, val_loss=12.9179, \n",
            "Epoch 2244/6000: train_loss=10.6655, val_loss=14.0583, \n",
            "Epoch 2245/6000: train_loss=10.3355, val_loss=12.6227, \n",
            "Epoch 2246/6000: train_loss=10.2863, val_loss=13.3733, \n",
            "Epoch 2247/6000: train_loss=10.4677, val_loss=14.4436, \n",
            "Epoch 2248/6000: train_loss=10.3798, val_loss=13.2244, \n",
            "Epoch 2249/6000: train_loss=10.5084, val_loss=13.8040, \n",
            "Epoch 2250/6000: train_loss=10.4369, val_loss=12.4848, \n",
            "Epoch 2251/6000: train_loss=10.3476, val_loss=13.7529, \n",
            "Epoch 2252/6000: train_loss=10.3508, val_loss=13.4733, \n",
            "Epoch 2253/6000: train_loss=10.2561, val_loss=13.1243, \n",
            "Epoch 2254/6000: train_loss=10.5506, val_loss=13.6517, \n",
            "Epoch 2255/6000: train_loss=10.7585, val_loss=12.3799, \n",
            "Epoch 2256/6000: train_loss=10.2882, val_loss=13.6204, \n",
            "Epoch 2257/6000: train_loss=10.3452, val_loss=13.3656, \n",
            "Epoch 2258/6000: train_loss=10.3386, val_loss=13.9944, \n",
            "Epoch 2259/6000: train_loss=10.2427, val_loss=13.0650, \n",
            "Epoch 2260/6000: train_loss=10.3505, val_loss=12.4258, \n",
            "Epoch 2261/6000: train_loss=10.8371, val_loss=14.5726, \n",
            "Epoch 2262/6000: train_loss=10.5189, val_loss=13.2127, \n",
            "Epoch 2263/6000: train_loss=10.9047, val_loss=14.9609, \n",
            "Epoch 2264/6000: train_loss=10.2401, val_loss=12.8202, \n",
            "Epoch 2265/6000: train_loss=10.2940, val_loss=12.5764, \n",
            "Epoch 2266/6000: train_loss=10.8652, val_loss=14.9754, \n",
            "Epoch 2267/6000: train_loss=10.9593, val_loss=13.2426, \n",
            "Epoch 2268/6000: train_loss=11.5313, val_loss=15.9942, \n",
            "Epoch 2269/6000: train_loss=10.5642, val_loss=12.8187, \n",
            "Epoch 2270/6000: train_loss=10.5353, val_loss=14.1822, \n",
            "Epoch 2271/6000: train_loss=10.3967, val_loss=12.4465, \n",
            "Epoch 2272/6000: train_loss=10.2394, val_loss=13.0799, \n",
            "Epoch 2273/6000: train_loss=10.3987, val_loss=13.7510, \n",
            "Epoch 2274/6000: train_loss=10.6397, val_loss=12.7024, \n",
            "Epoch 2275/6000: train_loss=10.4241, val_loss=13.8648, \n",
            "Epoch 2276/6000: train_loss=10.6588, val_loss=12.5030, \n",
            "Epoch 2277/6000: train_loss=10.8380, val_loss=14.7036, \n",
            "Epoch 2278/6000: train_loss=10.2927, val_loss=12.8853, \n",
            "Epoch 2279/6000: train_loss=10.2054, val_loss=13.3231, \n",
            "Epoch 2280/6000: train_loss=10.6045, val_loss=14.1862, \n",
            "Epoch 2281/6000: train_loss=12.0326, val_loss=12.8394, \n",
            "Epoch 2282/6000: train_loss=12.0657, val_loss=16.4306, \n",
            "Epoch 2283/6000: train_loss=10.5331, val_loss=12.5521, \n",
            "Epoch 2284/6000: train_loss=10.2041, val_loss=13.4445, \n",
            "Epoch 2285/6000: train_loss=10.2191, val_loss=12.9947, \n",
            "Epoch 2286/6000: train_loss=10.2333, val_loss=13.2680, \n",
            "Epoch 2287/6000: train_loss=10.2394, val_loss=12.7318, \n",
            "Epoch 2288/6000: train_loss=10.3641, val_loss=12.8691, \n",
            "Epoch 2289/6000: train_loss=10.3693, val_loss=14.1300, \n",
            "Epoch 2290/6000: train_loss=10.3263, val_loss=12.5524, \n",
            "Epoch 2291/6000: train_loss=10.2679, val_loss=12.8113, \n",
            "Epoch 2292/6000: train_loss=10.1802, val_loss=12.9631, \n",
            "Epoch 2293/6000: train_loss=10.2661, val_loss=13.3558, \n",
            "Epoch 2294/6000: train_loss=10.2107, val_loss=13.6393, \n",
            "Epoch 2295/6000: train_loss=10.3810, val_loss=12.3967, \n",
            "Epoch 2296/6000: train_loss=10.2625, val_loss=12.2002, \n",
            "Epoch 2297/6000: train_loss=10.7151, val_loss=14.3397, \n",
            "Epoch 2298/6000: train_loss=10.8807, val_loss=13.2373, \n",
            "Epoch 2299/6000: train_loss=10.5884, val_loss=14.8630, \n",
            "Epoch 2300/6000: train_loss=10.2261, val_loss=12.6897, \n",
            "Epoch 2301/6000: train_loss=10.2429, val_loss=12.8949, \n",
            "Epoch 2302/6000: train_loss=10.1683, val_loss=12.5765, \n",
            "Epoch 2303/6000: train_loss=10.4809, val_loss=13.0511, \n",
            "Epoch 2304/6000: train_loss=10.2072, val_loss=13.7823, \n",
            "Epoch 2305/6000: train_loss=10.1961, val_loss=12.7779, \n",
            "Epoch 2306/6000: train_loss=10.2953, val_loss=13.4049, \n",
            "Epoch 2307/6000: train_loss=10.8311, val_loss=12.7785, \n",
            "Epoch 2308/6000: train_loss=10.6493, val_loss=14.7896, \n",
            "Epoch 2309/6000: train_loss=10.5304, val_loss=12.4611, \n",
            "Epoch 2310/6000: train_loss=10.6648, val_loss=14.1977, \n",
            "Epoch 2311/6000: train_loss=10.2403, val_loss=12.6449, \n",
            "Epoch 2312/6000: train_loss=10.4718, val_loss=12.6528, \n",
            "Epoch 2313/6000: train_loss=10.8618, val_loss=14.8776, \n",
            "Epoch 2314/6000: train_loss=11.4712, val_loss=12.9306, \n",
            "Epoch 2315/6000: train_loss=10.6446, val_loss=14.5563, \n",
            "Epoch 2316/6000: train_loss=10.1544, val_loss=12.7957, \n",
            "Epoch 2317/6000: train_loss=10.1502, val_loss=12.8101, \n",
            "Epoch 2318/6000: train_loss=10.1795, val_loss=13.5714, \n",
            "Epoch 2319/6000: train_loss=10.1482, val_loss=12.9323, \n",
            "Epoch 2320/6000: train_loss=10.1327, val_loss=12.5548, \n",
            "Epoch 2321/6000: train_loss=10.1312, val_loss=12.7482, \n",
            "Epoch 2322/6000: train_loss=10.1183, val_loss=12.8435, \n",
            "Epoch 2323/6000: train_loss=10.5407, val_loss=14.3920, \n",
            "Epoch 2324/6000: train_loss=10.3206, val_loss=12.7749, \n",
            "Epoch 2325/6000: train_loss=10.2503, val_loss=13.5098, \n",
            "Epoch 2326/6000: train_loss=10.4160, val_loss=12.4353, \n",
            "Epoch 2327/6000: train_loss=10.1236, val_loss=13.2069, \n",
            "Epoch 2328/6000: train_loss=10.2181, val_loss=13.5898, \n",
            "Epoch 2329/6000: train_loss=10.2786, val_loss=12.5361, \n",
            "Epoch 2330/6000: train_loss=10.2617, val_loss=13.6591, \n",
            "Epoch 2331/6000: train_loss=10.1619, val_loss=12.4652, \n",
            "Epoch 2332/6000: train_loss=10.1836, val_loss=12.3657, \n",
            "Epoch 2333/6000: train_loss=10.5887, val_loss=14.2352, \n",
            "Epoch 2334/6000: train_loss=10.6832, val_loss=12.7897, \n",
            "Epoch 2335/6000: train_loss=11.4470, val_loss=16.0605, \n",
            "Epoch 2336/6000: train_loss=10.5724, val_loss=12.7058, \n",
            "Epoch 2337/6000: train_loss=10.1189, val_loss=12.8625, \n",
            "Epoch 2338/6000: train_loss=10.0870, val_loss=13.0220, \n",
            "Epoch 2339/6000: train_loss=10.1130, val_loss=13.2830, \n",
            "Epoch 2340/6000: train_loss=10.1376, val_loss=13.2415, \n",
            "Epoch 2341/6000: train_loss=10.5743, val_loss=12.0982, \n",
            "Epoch 2342/6000: train_loss=10.6159, val_loss=14.2184, \n",
            "Epoch 2343/6000: train_loss=10.6086, val_loss=12.8433, \n",
            "Epoch 2344/6000: train_loss=10.4281, val_loss=14.2747, \n",
            "Epoch 2345/6000: train_loss=10.1473, val_loss=12.6996, \n",
            "Epoch 2346/6000: train_loss=10.1929, val_loss=12.4543, \n",
            "Epoch 2347/6000: train_loss=10.3666, val_loss=13.7076, \n",
            "Epoch 2348/6000: train_loss=10.0789, val_loss=13.1154, \n",
            "Epoch 2349/6000: train_loss=10.2906, val_loss=12.9604, \n",
            "Epoch 2350/6000: train_loss=10.2162, val_loss=13.7593, \n",
            "Epoch 2351/6000: train_loss=10.1779, val_loss=12.6125, \n",
            "Epoch 2352/6000: train_loss=10.1808, val_loss=13.3117, \n",
            "Epoch 2353/6000: train_loss=10.3127, val_loss=12.1949, \n",
            "Epoch 2354/6000: train_loss=10.1138, val_loss=13.2381, \n",
            "Epoch 2355/6000: train_loss=10.0615, val_loss=12.9990, \n",
            "Epoch 2356/6000: train_loss=10.0659, val_loss=12.9530, \n",
            "Epoch 2357/6000: train_loss=10.0630, val_loss=13.3049, \n",
            "Epoch 2358/6000: train_loss=10.0717, val_loss=13.4547, \n",
            "Epoch 2359/6000: train_loss=10.0787, val_loss=12.8363, \n",
            "Epoch 2360/6000: train_loss=10.1583, val_loss=13.1205, \n",
            "Epoch 2361/6000: train_loss=10.1090, val_loss=12.3994, \n",
            "Epoch 2362/6000: train_loss=10.3752, val_loss=13.9063, \n",
            "Epoch 2363/6000: train_loss=10.0543, val_loss=12.9107, \n",
            "Epoch 2364/6000: train_loss=10.0578, val_loss=12.9240, \n",
            "Epoch 2365/6000: train_loss=10.5228, val_loss=12.2848, \n",
            "Epoch 2366/6000: train_loss=10.7836, val_loss=15.0117, \n",
            "Epoch 2367/6000: train_loss=10.8411, val_loss=13.0073, \n",
            "Epoch 2368/6000: train_loss=10.7474, val_loss=14.8396, \n",
            "Epoch 2369/6000: train_loss=10.4592, val_loss=12.2340, \n",
            "Epoch 2370/6000: train_loss=10.0718, val_loss=12.7786, \n",
            "Epoch 2371/6000: train_loss=10.8431, val_loss=14.8128, \n",
            "Epoch 2372/6000: train_loss=11.3325, val_loss=12.9472, \n",
            "Epoch 2373/6000: train_loss=12.5542, val_loss=17.8482, \n",
            "Epoch 2374/6000: train_loss=13.2305, val_loss=13.6256, \n",
            "Epoch 2375/6000: train_loss=12.4071, val_loss=16.9305, \n",
            "Epoch 2376/6000: train_loss=11.1651, val_loss=13.0906, \n",
            "Epoch 2377/6000: train_loss=10.2127, val_loss=14.3515, \n",
            "Epoch 2378/6000: train_loss=10.3479, val_loss=14.1993, \n",
            "Epoch 2379/6000: train_loss=10.7674, val_loss=12.3142, \n",
            "Epoch 2380/6000: train_loss=11.2367, val_loss=15.4981, \n",
            "Epoch 2381/6000: train_loss=10.8151, val_loss=12.6232, \n",
            "Epoch 2382/6000: train_loss=10.3769, val_loss=14.1303, \n",
            "Epoch 2383/6000: train_loss=10.3572, val_loss=12.5213, \n",
            "Epoch 2384/6000: train_loss=10.2672, val_loss=13.7952, \n",
            "Epoch 2385/6000: train_loss=10.0836, val_loss=12.9987, \n",
            "Epoch 2386/6000: train_loss=10.2403, val_loss=12.7111, \n",
            "Epoch 2387/6000: train_loss=10.7393, val_loss=14.3308, \n",
            "Epoch 2388/6000: train_loss=11.3643, val_loss=11.8256, \n",
            "Epoch 2389/6000: train_loss=11.8224, val_loss=16.2384, \n",
            "Epoch 2390/6000: train_loss=11.3418, val_loss=13.2071, \n",
            "Epoch 2391/6000: train_loss=10.4732, val_loss=14.6353, \n",
            "Epoch 2392/6000: train_loss=10.1443, val_loss=13.0639, \n",
            "Epoch 2393/6000: train_loss=10.8867, val_loss=12.0529, \n",
            "Epoch 2394/6000: train_loss=13.0917, val_loss=17.7956, \n",
            "Epoch 2395/6000: train_loss=12.0356, val_loss=13.2209, \n",
            "Epoch 2396/6000: train_loss=11.4303, val_loss=15.7027, \n",
            "Epoch 2397/6000: train_loss=10.5616, val_loss=12.3267, \n",
            "Epoch 2398/6000: train_loss=10.1200, val_loss=12.5145, \n",
            "Epoch 2399/6000: train_loss=10.2719, val_loss=14.1804, \n",
            "Epoch 2400/6000: train_loss=10.1341, val_loss=12.7631, \n",
            "Epoch 2401/6000: train_loss=10.0137, val_loss=12.9888, \n",
            "Epoch 2402/6000: train_loss=10.1497, val_loss=12.3123, \n",
            "Epoch 2403/6000: train_loss=10.0776, val_loss=13.6444, \n",
            "Epoch 2404/6000: train_loss=10.0244, val_loss=13.2733, \n",
            "Epoch 2405/6000: train_loss=10.0188, val_loss=13.0825, \n",
            "Epoch 2406/6000: train_loss=9.9801, val_loss=12.3344, \n",
            "Epoch 2407/6000: train_loss=10.4928, val_loss=12.0780, \n",
            "Epoch 2408/6000: train_loss=10.3617, val_loss=14.0629, \n",
            "Epoch 2409/6000: train_loss=10.7123, val_loss=12.8448, \n",
            "Epoch 2410/6000: train_loss=9.9927, val_loss=13.2129, \n",
            "Epoch 2411/6000: train_loss=10.1412, val_loss=13.4733, \n",
            "Epoch 2412/6000: train_loss=10.1198, val_loss=12.3993, \n",
            "Epoch 2413/6000: train_loss=9.9810, val_loss=13.0952, \n",
            "Epoch 2414/6000: train_loss=9.9638, val_loss=12.8781, \n",
            "Epoch 2415/6000: train_loss=10.0727, val_loss=13.3832, \n",
            "Epoch 2416/6000: train_loss=9.9859, val_loss=12.9787, \n",
            "Epoch 2417/6000: train_loss=10.3873, val_loss=12.3944, \n",
            "Epoch 2418/6000: train_loss=11.0761, val_loss=15.0128, \n",
            "Epoch 2419/6000: train_loss=10.3570, val_loss=12.2484, \n",
            "Epoch 2420/6000: train_loss=10.1866, val_loss=13.7899, \n",
            "Epoch 2421/6000: train_loss=9.9922, val_loss=13.3742, \n",
            "Epoch 2422/6000: train_loss=10.3948, val_loss=12.6608, \n",
            "Epoch 2423/6000: train_loss=10.5823, val_loss=14.7998, \n",
            "Epoch 2424/6000: train_loss=11.1014, val_loss=12.8680, \n",
            "Epoch 2425/6000: train_loss=11.3631, val_loss=15.6518, \n",
            "Epoch 2426/6000: train_loss=10.2435, val_loss=11.7926, \n",
            "Epoch 2427/6000: train_loss=9.9664, val_loss=12.4346, \n",
            "Epoch 2428/6000: train_loss=10.0403, val_loss=13.7048, \n",
            "Epoch 2429/6000: train_loss=10.2808, val_loss=13.1836, \n",
            "Epoch 2430/6000: train_loss=10.2710, val_loss=14.2012, \n",
            "Epoch 2431/6000: train_loss=10.1717, val_loss=12.0944, \n",
            "Epoch 2432/6000: train_loss=9.9959, val_loss=12.6116, \n",
            "Epoch 2433/6000: train_loss=10.0138, val_loss=12.3378, \n",
            "Epoch 2434/6000: train_loss=9.9555, val_loss=13.2644, \n",
            "Epoch 2435/6000: train_loss=9.9216, val_loss=13.0258, \n",
            "Epoch 2436/6000: train_loss=10.2134, val_loss=12.4277, \n",
            "Epoch 2437/6000: train_loss=10.0274, val_loss=13.3668, \n",
            "Epoch 2438/6000: train_loss=9.9169, val_loss=12.9339, \n",
            "Epoch 2439/6000: train_loss=10.0329, val_loss=12.3298, \n",
            "Epoch 2440/6000: train_loss=9.9058, val_loss=12.7553, \n",
            "Epoch 2441/6000: train_loss=10.3211, val_loss=12.4935, \n",
            "Epoch 2442/6000: train_loss=10.1132, val_loss=13.5570, \n",
            "Epoch 2443/6000: train_loss=10.2836, val_loss=12.4859, \n",
            "Epoch 2444/6000: train_loss=9.9104, val_loss=12.8715, \n",
            "Epoch 2445/6000: train_loss=9.9112, val_loss=12.6529, \n",
            "Epoch 2446/6000: train_loss=9.9168, val_loss=12.3937, \n",
            "Epoch 2447/6000: train_loss=9.9408, val_loss=12.3110, \n",
            "Epoch 2448/6000: train_loss=9.8982, val_loss=12.9863, \n",
            "Epoch 2449/6000: train_loss=10.0053, val_loss=13.4057, \n",
            "Epoch 2450/6000: train_loss=9.9948, val_loss=12.4785, \n",
            "Epoch 2451/6000: train_loss=10.0095, val_loss=13.6563, \n",
            "Epoch 2452/6000: train_loss=10.0409, val_loss=13.7365, \n",
            "Epoch 2453/6000: train_loss=10.2781, val_loss=12.2363, \n",
            "Epoch 2454/6000: train_loss=11.0786, val_loss=15.0157, \n",
            "Epoch 2455/6000: train_loss=11.1778, val_loss=13.0001, \n",
            "Epoch 2456/6000: train_loss=10.9229, val_loss=15.4431, \n",
            "Epoch 2457/6000: train_loss=9.9925, val_loss=12.1021, \n",
            "Epoch 2458/6000: train_loss=10.2374, val_loss=11.5539, \n",
            "Epoch 2459/6000: train_loss=11.4695, val_loss=15.4727, \n",
            "Epoch 2460/6000: train_loss=10.8293, val_loss=12.4220, \n",
            "Epoch 2461/6000: train_loss=10.1538, val_loss=14.3632, \n",
            "Epoch 2462/6000: train_loss=10.0096, val_loss=12.9839, \n",
            "Epoch 2463/6000: train_loss=9.9205, val_loss=12.4766, \n",
            "Epoch 2464/6000: train_loss=10.2823, val_loss=13.6837, \n",
            "Epoch 2465/6000: train_loss=10.3514, val_loss=12.2438, \n",
            "Epoch 2466/6000: train_loss=10.3099, val_loss=14.1332, \n",
            "Epoch 2467/6000: train_loss=9.8976, val_loss=12.5906, \n",
            "Epoch 2468/6000: train_loss=9.8816, val_loss=12.5909, \n",
            "Epoch 2469/6000: train_loss=10.0289, val_loss=13.4379, \n",
            "Epoch 2470/6000: train_loss=10.3648, val_loss=12.3860, \n",
            "Epoch 2471/6000: train_loss=10.7550, val_loss=14.8168, \n",
            "Epoch 2472/6000: train_loss=10.2686, val_loss=12.2847, \n",
            "Epoch 2473/6000: train_loss=10.1035, val_loss=13.8947, \n",
            "Epoch 2474/6000: train_loss=9.9416, val_loss=12.7591, \n",
            "Epoch 2475/6000: train_loss=9.8556, val_loss=12.8080, \n",
            "Epoch 2476/6000: train_loss=9.8759, val_loss=12.8439, \n",
            "Epoch 2477/6000: train_loss=10.0058, val_loss=12.2359, \n",
            "Epoch 2478/6000: train_loss=10.0841, val_loss=13.7751, \n",
            "Epoch 2479/6000: train_loss=10.0691, val_loss=12.4655, \n",
            "Epoch 2480/6000: train_loss=10.2925, val_loss=13.9826, \n",
            "Epoch 2481/6000: train_loss=9.9377, val_loss=12.4457, \n",
            "Epoch 2482/6000: train_loss=9.8682, val_loss=12.6963, \n",
            "Epoch 2483/6000: train_loss=9.8442, val_loss=12.9868, \n",
            "Epoch 2484/6000: train_loss=9.9493, val_loss=12.3121, \n",
            "Epoch 2485/6000: train_loss=10.1134, val_loss=13.4437, \n",
            "Epoch 2486/6000: train_loss=9.8862, val_loss=12.3582, \n",
            "Epoch 2487/6000: train_loss=9.8658, val_loss=12.6267, \n",
            "Epoch 2488/6000: train_loss=9.8258, val_loss=12.7684, \n",
            "Epoch 2489/6000: train_loss=9.8341, val_loss=12.8902, \n",
            "Epoch 2490/6000: train_loss=10.1251, val_loss=12.1128, \n",
            "Epoch 2491/6000: train_loss=10.1531, val_loss=13.8293, \n",
            "Epoch 2492/6000: train_loss=9.9870, val_loss=12.6467, \n",
            "Epoch 2493/6000: train_loss=9.8694, val_loss=12.8060, \n",
            "Epoch 2494/6000: train_loss=10.7651, val_loss=15.1818, \n",
            "Epoch 2495/6000: train_loss=10.7067, val_loss=12.2180, \n",
            "Epoch 2496/6000: train_loss=9.9725, val_loss=13.1259, \n",
            "Epoch 2497/6000: train_loss=9.8683, val_loss=12.4264, \n",
            "Epoch 2498/6000: train_loss=9.8302, val_loss=12.9044, \n",
            "Epoch 2499/6000: train_loss=9.8481, val_loss=12.8627, \n",
            "Epoch 2500/6000: train_loss=9.8037, val_loss=12.6150, \n",
            "Epoch 2501/6000: train_loss=9.8214, val_loss=12.2519, \n",
            "Epoch 2502/6000: train_loss=9.8022, val_loss=12.6852, \n",
            "Epoch 2503/6000: train_loss=9.8155, val_loss=12.9759, \n",
            "Epoch 2504/6000: train_loss=10.1023, val_loss=14.0754, \n",
            "Epoch 2505/6000: train_loss=10.0284, val_loss=12.3414, \n",
            "Epoch 2506/6000: train_loss=10.0105, val_loss=13.2449, \n",
            "Epoch 2507/6000: train_loss=9.8305, val_loss=12.3439, \n",
            "Epoch 2508/6000: train_loss=9.7986, val_loss=12.8331, \n",
            "Epoch 2509/6000: train_loss=9.9295, val_loss=12.8823, \n",
            "Epoch 2510/6000: train_loss=9.8050, val_loss=13.1319, \n",
            "Epoch 2511/6000: train_loss=10.3879, val_loss=13.8457, \n",
            "Epoch 2512/6000: train_loss=9.8753, val_loss=12.2405, \n",
            "Epoch 2513/6000: train_loss=9.8111, val_loss=12.9494, \n",
            "Epoch 2514/6000: train_loss=9.7811, val_loss=12.7092, \n",
            "Epoch 2515/6000: train_loss=9.7918, val_loss=12.4925, \n",
            "Epoch 2516/6000: train_loss=9.8261, val_loss=12.7466, \n",
            "Epoch 2517/6000: train_loss=9.7879, val_loss=12.9492, \n",
            "Epoch 2518/6000: train_loss=9.8135, val_loss=12.8439, \n",
            "Epoch 2519/6000: train_loss=9.8052, val_loss=12.9559, \n",
            "Epoch 2520/6000: train_loss=9.8020, val_loss=12.2792, \n",
            "Epoch 2521/6000: train_loss=9.7880, val_loss=12.5918, \n",
            "Epoch 2522/6000: train_loss=9.7972, val_loss=13.3122, \n",
            "Epoch 2523/6000: train_loss=9.7844, val_loss=12.9786, \n",
            "Epoch 2524/6000: train_loss=9.8274, val_loss=12.0006, \n",
            "Epoch 2525/6000: train_loss=9.7832, val_loss=12.2418, \n",
            "Epoch 2526/6000: train_loss=9.7740, val_loss=13.0260, \n",
            "Epoch 2527/6000: train_loss=9.8288, val_loss=12.6943, \n",
            "Epoch 2528/6000: train_loss=10.0250, val_loss=13.6106, \n",
            "Epoch 2529/6000: train_loss=9.9807, val_loss=12.0542, \n",
            "Epoch 2530/6000: train_loss=10.0466, val_loss=13.4799, \n",
            "Epoch 2531/6000: train_loss=9.9088, val_loss=12.3195, \n",
            "Epoch 2532/6000: train_loss=9.7409, val_loss=12.7412, \n",
            "Epoch 2533/6000: train_loss=9.8049, val_loss=12.7000, \n",
            "Epoch 2534/6000: train_loss=9.9729, val_loss=13.5673, \n",
            "Epoch 2535/6000: train_loss=9.8999, val_loss=11.9142, \n",
            "Epoch 2536/6000: train_loss=9.7922, val_loss=12.0442, \n",
            "Epoch 2537/6000: train_loss=9.9753, val_loss=13.2642, \n",
            "Epoch 2538/6000: train_loss=10.9174, val_loss=12.6176, \n",
            "Epoch 2539/6000: train_loss=11.4525, val_loss=16.0103, \n",
            "Epoch 2540/6000: train_loss=10.5750, val_loss=12.0527, \n",
            "Epoch 2541/6000: train_loss=9.8767, val_loss=12.8814, \n",
            "Epoch 2542/6000: train_loss=9.7527, val_loss=12.8206, \n",
            "Epoch 2543/6000: train_loss=10.3051, val_loss=12.7981, \n",
            "Epoch 2544/6000: train_loss=10.8400, val_loss=15.3518, \n",
            "Epoch 2545/6000: train_loss=11.2351, val_loss=12.2464, \n",
            "Epoch 2546/6000: train_loss=10.2635, val_loss=13.8289, \n",
            "Epoch 2547/6000: train_loss=9.7830, val_loss=12.6588, \n",
            "Epoch 2548/6000: train_loss=9.8081, val_loss=12.9097, \n",
            "Epoch 2549/6000: train_loss=9.8003, val_loss=13.1245, \n",
            "Epoch 2550/6000: train_loss=10.6836, val_loss=11.9389, \n",
            "Epoch 2551/6000: train_loss=12.1088, val_loss=16.6831, \n",
            "Epoch 2552/6000: train_loss=11.7915, val_loss=12.9526, \n",
            "Epoch 2553/6000: train_loss=10.9601, val_loss=15.5667, \n",
            "Epoch 2554/6000: train_loss=9.7722, val_loss=12.5337, \n",
            "Epoch 2555/6000: train_loss=9.7119, val_loss=12.4965, \n",
            "Epoch 2556/6000: train_loss=10.2213, val_loss=13.9625, \n",
            "Epoch 2557/6000: train_loss=10.6953, val_loss=12.4773, \n",
            "Epoch 2558/6000: train_loss=10.2134, val_loss=14.1478, \n",
            "Epoch 2559/6000: train_loss=9.9497, val_loss=12.3499, \n",
            "Epoch 2560/6000: train_loss=9.8932, val_loss=12.1215, \n",
            "Epoch 2561/6000: train_loss=10.1394, val_loss=13.2223, \n",
            "Epoch 2562/6000: train_loss=10.5575, val_loss=11.6810, \n",
            "Epoch 2563/6000: train_loss=10.4571, val_loss=14.5116, \n",
            "Epoch 2564/6000: train_loss=10.4510, val_loss=12.2461, \n",
            "Epoch 2565/6000: train_loss=10.0820, val_loss=13.6730, \n",
            "Epoch 2566/6000: train_loss=9.7549, val_loss=12.4396, \n",
            "Epoch 2567/6000: train_loss=9.7252, val_loss=12.8489, \n",
            "Epoch 2568/6000: train_loss=9.8023, val_loss=13.4559, \n",
            "Epoch 2569/6000: train_loss=9.9389, val_loss=12.2995, \n",
            "Epoch 2570/6000: train_loss=10.7288, val_loss=14.4382, \n",
            "Epoch 2571/6000: train_loss=9.9258, val_loss=11.6750, \n",
            "Epoch 2572/6000: train_loss=9.7352, val_loss=12.8018, \n",
            "Epoch 2573/6000: train_loss=9.6832, val_loss=12.9464, \n",
            "Epoch 2574/6000: train_loss=9.6827, val_loss=13.0856, \n",
            "Epoch 2575/6000: train_loss=9.8417, val_loss=13.3554, \n",
            "Epoch 2576/6000: train_loss=9.6912, val_loss=12.3834, \n",
            "Epoch 2577/6000: train_loss=9.7796, val_loss=13.0835, \n",
            "Epoch 2578/6000: train_loss=9.8599, val_loss=12.4688, \n",
            "Epoch 2579/6000: train_loss=9.7079, val_loss=12.6090, \n",
            "Epoch 2580/6000: train_loss=9.6984, val_loss=12.6802, \n",
            "Epoch 2581/6000: train_loss=9.9795, val_loss=13.3379, \n",
            "Epoch 2582/6000: train_loss=9.8228, val_loss=12.4573, \n",
            "Epoch 2583/6000: train_loss=9.6621, val_loss=12.7994, \n",
            "Epoch 2584/6000: train_loss=9.6552, val_loss=12.4927, \n",
            "Epoch 2585/6000: train_loss=9.6623, val_loss=12.4614, \n",
            "Epoch 2586/6000: train_loss=9.6717, val_loss=12.8198, \n",
            "Epoch 2587/6000: train_loss=9.7307, val_loss=13.0898, \n",
            "Epoch 2588/6000: train_loss=9.6775, val_loss=12.7614, \n",
            "Epoch 2589/6000: train_loss=9.7021, val_loss=12.9615, \n",
            "Epoch 2590/6000: train_loss=9.6985, val_loss=12.4839, \n",
            "Epoch 2591/6000: train_loss=9.6629, val_loss=12.2493, \n",
            "Epoch 2592/6000: train_loss=9.6632, val_loss=12.9217, \n",
            "Epoch 2593/6000: train_loss=9.7490, val_loss=12.8163, \n",
            "Epoch 2594/6000: train_loss=9.7265, val_loss=12.3643, \n",
            "Epoch 2595/6000: train_loss=9.9187, val_loss=11.4978, \n",
            "Epoch 2596/6000: train_loss=10.2117, val_loss=14.1228, \n",
            "Epoch 2597/6000: train_loss=10.2651, val_loss=12.4418, \n",
            "Epoch 2598/6000: train_loss=10.1668, val_loss=14.1625, \n",
            "Epoch 2599/6000: train_loss=10.2373, val_loss=11.8726, \n",
            "Epoch 2600/6000: train_loss=10.0770, val_loss=13.4260, \n",
            "Epoch 2601/6000: train_loss=9.6795, val_loss=12.9507, \n",
            "Epoch 2602/6000: train_loss=9.8665, val_loss=12.4657, \n",
            "Epoch 2603/6000: train_loss=10.0581, val_loss=13.8256, \n",
            "Epoch 2604/6000: train_loss=10.2428, val_loss=12.0523, \n",
            "Epoch 2605/6000: train_loss=9.8865, val_loss=13.4437, \n",
            "Epoch 2606/6000: train_loss=9.6396, val_loss=12.7470, \n",
            "Epoch 2607/6000: train_loss=9.6652, val_loss=12.3887, \n",
            "Epoch 2608/6000: train_loss=9.6193, val_loss=12.4291, \n",
            "Epoch 2609/6000: train_loss=9.6951, val_loss=12.9305, \n",
            "Epoch 2610/6000: train_loss=9.7328, val_loss=12.3431, \n",
            "Epoch 2611/6000: train_loss=9.6077, val_loss=12.6537, \n",
            "Epoch 2612/6000: train_loss=9.7515, val_loss=13.0414, \n",
            "Epoch 2613/6000: train_loss=10.1141, val_loss=11.9026, \n",
            "Epoch 2614/6000: train_loss=9.8385, val_loss=13.3822, \n",
            "Epoch 2615/6000: train_loss=9.5993, val_loss=12.7600, \n",
            "Epoch 2616/6000: train_loss=10.0892, val_loss=12.4486, \n",
            "Epoch 2617/6000: train_loss=10.2458, val_loss=14.4671, \n",
            "Epoch 2618/6000: train_loss=10.3873, val_loss=12.5140, \n",
            "Epoch 2619/6000: train_loss=10.3124, val_loss=14.1173, \n",
            "Epoch 2620/6000: train_loss=9.9810, val_loss=11.7024, \n",
            "Epoch 2621/6000: train_loss=9.6836, val_loss=12.2367, \n",
            "Epoch 2622/6000: train_loss=9.8606, val_loss=13.7801, \n",
            "Epoch 2623/6000: train_loss=10.5745, val_loss=12.6915, \n",
            "Epoch 2624/6000: train_loss=10.9495, val_loss=15.3551, \n",
            "Epoch 2625/6000: train_loss=10.9636, val_loss=12.4920, \n",
            "Epoch 2626/6000: train_loss=10.4365, val_loss=14.4236, \n",
            "Epoch 2627/6000: train_loss=9.6126, val_loss=12.1358, \n",
            "Epoch 2628/6000: train_loss=9.5989, val_loss=12.0976, \n",
            "Epoch 2629/6000: train_loss=9.8417, val_loss=13.3329, \n",
            "Epoch 2630/6000: train_loss=10.5074, val_loss=12.7262, \n",
            "Epoch 2631/6000: train_loss=11.2646, val_loss=16.0422, \n",
            "Epoch 2632/6000: train_loss=11.5337, val_loss=12.4527, \n",
            "Epoch 2633/6000: train_loss=10.2940, val_loss=13.7618, \n",
            "Epoch 2634/6000: train_loss=9.7408, val_loss=12.1744, \n",
            "Epoch 2635/6000: train_loss=9.8007, val_loss=13.5149, \n",
            "Epoch 2636/6000: train_loss=9.7300, val_loss=13.1941, \n",
            "Epoch 2637/6000: train_loss=9.9701, val_loss=12.3718, \n",
            "Epoch 2638/6000: train_loss=10.7835, val_loss=15.1516, \n",
            "Epoch 2639/6000: train_loss=10.3791, val_loss=12.0684, \n",
            "Epoch 2640/6000: train_loss=9.8619, val_loss=13.2158, \n",
            "Epoch 2641/6000: train_loss=9.5592, val_loss=12.3323, \n",
            "Epoch 2642/6000: train_loss=9.6397, val_loss=12.0490, \n",
            "Epoch 2643/6000: train_loss=10.3301, val_loss=14.5096, \n",
            "Epoch 2644/6000: train_loss=9.7180, val_loss=12.2515, \n",
            "Epoch 2645/6000: train_loss=9.5498, val_loss=12.4505, \n",
            "Epoch 2646/6000: train_loss=9.6699, val_loss=12.9005, \n",
            "Epoch 2647/6000: train_loss=9.5850, val_loss=12.2213, \n",
            "Epoch 2648/6000: train_loss=9.5479, val_loss=12.5406, \n",
            "Epoch 2649/6000: train_loss=9.5948, val_loss=12.8520, \n",
            "Epoch 2650/6000: train_loss=9.5836, val_loss=12.2856, \n",
            "Epoch 2651/6000: train_loss=9.5638, val_loss=12.5375, \n",
            "Epoch 2652/6000: train_loss=9.5538, val_loss=12.7242, \n",
            "Epoch 2653/6000: train_loss=9.5599, val_loss=12.3533, \n",
            "Epoch 2654/6000: train_loss=9.6179, val_loss=12.8100, \n",
            "Epoch 2655/6000: train_loss=9.7093, val_loss=11.9017, \n",
            "Epoch 2656/6000: train_loss=9.5684, val_loss=12.1734, \n",
            "Epoch 2657/6000: train_loss=9.6963, val_loss=13.3775, \n",
            "Epoch 2658/6000: train_loss=9.6731, val_loss=12.3924, \n",
            "Epoch 2659/6000: train_loss=9.5312, val_loss=12.3385, \n",
            "Epoch 2660/6000: train_loss=9.5870, val_loss=11.9993, \n",
            "Epoch 2661/6000: train_loss=9.5165, val_loss=12.4694, \n",
            "Epoch 2662/6000: train_loss=9.5267, val_loss=12.7039, \n",
            "Epoch 2663/6000: train_loss=9.5749, val_loss=12.8671, \n",
            "Epoch 2664/6000: train_loss=9.5267, val_loss=12.4238, \n",
            "Epoch 2665/6000: train_loss=9.5263, val_loss=12.1417, \n",
            "Epoch 2666/6000: train_loss=9.5934, val_loss=12.6369, \n",
            "Epoch 2667/6000: train_loss=9.7893, val_loss=11.9946, \n",
            "Epoch 2668/6000: train_loss=9.9206, val_loss=13.9366, \n",
            "Epoch 2669/6000: train_loss=9.5616, val_loss=12.4330, \n",
            "Epoch 2670/6000: train_loss=9.5218, val_loss=12.4131, \n",
            "Epoch 2671/6000: train_loss=9.6047, val_loss=12.0506, \n",
            "Epoch 2672/6000: train_loss=9.5072, val_loss=12.4683, \n",
            "Epoch 2673/6000: train_loss=9.6295, val_loss=12.2897, \n",
            "Epoch 2674/6000: train_loss=9.5450, val_loss=12.8166, \n",
            "Epoch 2675/6000: train_loss=9.5245, val_loss=12.0470, \n",
            "Epoch 2676/6000: train_loss=9.5195, val_loss=12.3783, \n",
            "Epoch 2677/6000: train_loss=9.5166, val_loss=12.3239, \n",
            "Epoch 2678/6000: train_loss=9.5238, val_loss=12.8014, \n",
            "Epoch 2679/6000: train_loss=9.5340, val_loss=12.5347, \n",
            "Epoch 2680/6000: train_loss=9.5282, val_loss=12.4238, \n",
            "Epoch 2681/6000: train_loss=9.5005, val_loss=12.3367, \n",
            "Epoch 2682/6000: train_loss=9.4820, val_loss=12.5789, \n",
            "Epoch 2683/6000: train_loss=9.9382, val_loss=13.5992, \n",
            "Epoch 2684/6000: train_loss=9.8310, val_loss=12.0827, \n",
            "Epoch 2685/6000: train_loss=9.4854, val_loss=12.4989, \n",
            "Epoch 2686/6000: train_loss=10.1506, val_loss=14.0532, \n",
            "Epoch 2687/6000: train_loss=10.1112, val_loss=11.6560, \n",
            "Epoch 2688/6000: train_loss=10.0252, val_loss=13.8542, \n",
            "Epoch 2689/6000: train_loss=9.7353, val_loss=12.4042, \n",
            "Epoch 2690/6000: train_loss=9.4783, val_loss=12.5421, \n",
            "Epoch 2691/6000: train_loss=9.4857, val_loss=11.9720, \n",
            "Epoch 2692/6000: train_loss=9.4982, val_loss=11.9260, \n",
            "Epoch 2693/6000: train_loss=9.6338, val_loss=12.9577, \n",
            "Epoch 2694/6000: train_loss=9.6502, val_loss=12.5140, \n",
            "Epoch 2695/6000: train_loss=9.4771, val_loss=12.4514, \n",
            "Epoch 2696/6000: train_loss=9.4851, val_loss=12.0183, \n",
            "Epoch 2697/6000: train_loss=9.5014, val_loss=11.9987, \n",
            "Epoch 2698/6000: train_loss=10.5389, val_loss=14.7692, \n",
            "Epoch 2699/6000: train_loss=10.1034, val_loss=11.8773, \n",
            "Epoch 2700/6000: train_loss=10.4266, val_loss=14.2948, \n",
            "Epoch 2701/6000: train_loss=10.2308, val_loss=11.9836, \n",
            "Epoch 2702/6000: train_loss=9.5179, val_loss=13.1080, \n",
            "Epoch 2703/6000: train_loss=9.5010, val_loss=12.7786, \n",
            "Epoch 2704/6000: train_loss=9.4615, val_loss=12.0609, \n",
            "Epoch 2705/6000: train_loss=9.4977, val_loss=11.5526, \n",
            "Epoch 2706/6000: train_loss=9.4615, val_loss=12.0465, \n",
            "Epoch 2707/6000: train_loss=9.5211, val_loss=12.8055, \n",
            "Epoch 2708/6000: train_loss=9.6611, val_loss=12.1875, \n",
            "Epoch 2709/6000: train_loss=10.0062, val_loss=13.7318, \n",
            "Epoch 2710/6000: train_loss=9.9770, val_loss=11.6715, \n",
            "Epoch 2711/6000: train_loss=11.2292, val_loss=15.5671, \n",
            "Epoch 2712/6000: train_loss=10.2221, val_loss=11.7846, \n",
            "Epoch 2713/6000: train_loss=9.6202, val_loss=13.1298, \n",
            "Epoch 2714/6000: train_loss=9.5691, val_loss=11.9932, \n",
            "Epoch 2715/6000: train_loss=9.4626, val_loss=12.5178, \n",
            "Epoch 2716/6000: train_loss=9.8446, val_loss=13.4094, \n",
            "Epoch 2717/6000: train_loss=9.9640, val_loss=11.9759, \n",
            "Epoch 2718/6000: train_loss=10.4598, val_loss=14.4938, \n",
            "Epoch 2719/6000: train_loss=10.5610, val_loss=12.0563, \n",
            "Epoch 2720/6000: train_loss=9.5019, val_loss=12.8330, \n",
            "Epoch 2721/6000: train_loss=9.6868, val_loss=13.1094, \n",
            "Epoch 2722/6000: train_loss=9.8915, val_loss=11.3547, \n",
            "Epoch 2723/6000: train_loss=9.7413, val_loss=12.7300, \n",
            "Epoch 2724/6000: train_loss=9.8507, val_loss=11.9325, \n",
            "Epoch 2725/6000: train_loss=9.9433, val_loss=13.8108, \n",
            "Epoch 2726/6000: train_loss=9.4206, val_loss=12.3832, \n",
            "Epoch 2727/6000: train_loss=9.4354, val_loss=11.8880, \n",
            "Epoch 2728/6000: train_loss=9.4868, val_loss=12.2162, \n",
            "Epoch 2729/6000: train_loss=9.4332, val_loss=12.6032, \n",
            "Epoch 2730/6000: train_loss=9.4489, val_loss=12.8137, \n",
            "Epoch 2731/6000: train_loss=9.4038, val_loss=11.9849, \n",
            "Epoch 2732/6000: train_loss=9.4239, val_loss=11.7431, \n",
            "Epoch 2733/6000: train_loss=9.4291, val_loss=12.5041, \n",
            "Epoch 2734/6000: train_loss=9.9084, val_loss=11.9495, \n",
            "Epoch 2735/6000: train_loss=9.4486, val_loss=12.5759, \n",
            "Epoch 2736/6000: train_loss=9.5206, val_loss=11.7465, \n",
            "Epoch 2737/6000: train_loss=9.5160, val_loss=12.6299, \n",
            "Epoch 2738/6000: train_loss=9.3825, val_loss=12.2060, \n",
            "Epoch 2739/6000: train_loss=9.4218, val_loss=12.4024, \n",
            "Epoch 2740/6000: train_loss=9.3861, val_loss=12.1599, \n",
            "Epoch 2741/6000: train_loss=9.6354, val_loss=11.5483, \n",
            "Epoch 2742/6000: train_loss=9.7634, val_loss=13.1611, \n",
            "Epoch 2743/6000: train_loss=9.7208, val_loss=11.6761, \n",
            "Epoch 2744/6000: train_loss=9.3860, val_loss=12.4154, \n",
            "Epoch 2745/6000: train_loss=9.3984, val_loss=12.3585, \n",
            "Epoch 2746/6000: train_loss=9.5633, val_loss=12.8306, \n",
            "Epoch 2747/6000: train_loss=9.8627, val_loss=11.6916, \n",
            "Epoch 2748/6000: train_loss=9.6225, val_loss=13.0219, \n",
            "Epoch 2749/6000: train_loss=9.3763, val_loss=12.3063, \n",
            "Epoch 2750/6000: train_loss=9.4048, val_loss=11.9326, \n",
            "Epoch 2751/6000: train_loss=9.5546, val_loss=11.8021, \n",
            "Epoch 2752/6000: train_loss=9.6548, val_loss=13.3056, \n",
            "Epoch 2753/6000: train_loss=9.5368, val_loss=11.8410, \n",
            "Epoch 2754/6000: train_loss=9.4236, val_loss=12.4305, \n",
            "Epoch 2755/6000: train_loss=9.4224, val_loss=11.8067, \n",
            "Epoch 2756/6000: train_loss=9.4618, val_loss=11.7600, \n",
            "Epoch 2757/6000: train_loss=9.5680, val_loss=12.8138, \n",
            "Epoch 2758/6000: train_loss=9.6056, val_loss=11.9089, \n",
            "Epoch 2759/6000: train_loss=9.6300, val_loss=13.2021, \n",
            "Epoch 2760/6000: train_loss=9.6404, val_loss=11.6476, \n",
            "Epoch 2761/6000: train_loss=9.5534, val_loss=12.8881, \n",
            "Epoch 2762/6000: train_loss=9.4182, val_loss=12.7924, \n",
            "Epoch 2763/6000: train_loss=9.6470, val_loss=11.8404, \n",
            "Epoch 2764/6000: train_loss=10.0300, val_loss=13.6557, \n",
            "Epoch 2765/6000: train_loss=9.6191, val_loss=11.6683, \n",
            "Epoch 2766/6000: train_loss=10.0788, val_loss=14.0095, \n",
            "Epoch 2767/6000: train_loss=9.5215, val_loss=12.0787, \n",
            "Epoch 2768/6000: train_loss=9.4945, val_loss=11.9001, \n",
            "Epoch 2769/6000: train_loss=9.9894, val_loss=13.8450, \n",
            "Epoch 2770/6000: train_loss=11.2710, val_loss=12.0700, \n",
            "Epoch 2771/6000: train_loss=10.6394, val_loss=14.7345, \n",
            "Epoch 2772/6000: train_loss=10.1396, val_loss=11.2442, \n",
            "Epoch 2773/6000: train_loss=10.0144, val_loss=13.6225, \n",
            "Epoch 2774/6000: train_loss=9.3766, val_loss=12.4058, \n",
            "Epoch 2775/6000: train_loss=9.3757, val_loss=12.8678, \n",
            "Epoch 2776/6000: train_loss=9.4104, val_loss=12.6072, \n",
            "Epoch 2777/6000: train_loss=9.4628, val_loss=11.5422, \n",
            "Epoch 2778/6000: train_loss=9.7960, val_loss=13.1127, \n",
            "Epoch 2779/6000: train_loss=9.4489, val_loss=11.9536, \n",
            "Epoch 2780/6000: train_loss=9.3924, val_loss=12.3279, \n",
            "Epoch 2781/6000: train_loss=9.5064, val_loss=13.1930, \n",
            "Epoch 2782/6000: train_loss=9.4039, val_loss=11.8260, \n",
            "Epoch 2783/6000: train_loss=9.4615, val_loss=12.3916, \n",
            "Epoch 2784/6000: train_loss=9.3458, val_loss=12.0093, \n",
            "Epoch 2785/6000: train_loss=9.3252, val_loss=12.4159, \n",
            "Epoch 2786/6000: train_loss=9.3654, val_loss=12.7261, \n",
            "Epoch 2787/6000: train_loss=9.5409, val_loss=12.0899, \n",
            "Epoch 2788/6000: train_loss=9.3722, val_loss=12.5867, \n",
            "Epoch 2789/6000: train_loss=9.3100, val_loss=12.3048, \n",
            "Epoch 2790/6000: train_loss=9.3118, val_loss=11.7785, \n",
            "Epoch 2791/6000: train_loss=9.5201, val_loss=12.5561, \n",
            "Epoch 2792/6000: train_loss=9.5883, val_loss=11.7415, \n",
            "Epoch 2793/6000: train_loss=9.8666, val_loss=13.8285, \n",
            "Epoch 2794/6000: train_loss=9.4197, val_loss=11.8006, \n",
            "Epoch 2795/6000: train_loss=9.3338, val_loss=12.2343, \n",
            "Epoch 2796/6000: train_loss=9.6113, val_loss=11.7064, \n",
            "Epoch 2797/6000: train_loss=9.3421, val_loss=12.0313, \n",
            "Epoch 2798/6000: train_loss=9.3353, val_loss=12.3845, \n",
            "Epoch 2799/6000: train_loss=9.9892, val_loss=11.6457, \n",
            "Epoch 2800/6000: train_loss=9.8011, val_loss=13.3629, \n",
            "Epoch 2801/6000: train_loss=9.3352, val_loss=12.1361, \n",
            "Epoch 2802/6000: train_loss=9.6322, val_loss=13.1868, \n",
            "Epoch 2803/6000: train_loss=9.2842, val_loss=11.8664, \n",
            "Epoch 2804/6000: train_loss=9.4528, val_loss=11.7184, \n",
            "Epoch 2805/6000: train_loss=9.5236, val_loss=12.7723, \n",
            "Epoch 2806/6000: train_loss=9.7288, val_loss=11.5389, \n",
            "Epoch 2807/6000: train_loss=9.6408, val_loss=13.1775, \n",
            "Epoch 2808/6000: train_loss=9.3110, val_loss=12.0512, \n",
            "Epoch 2809/6000: train_loss=9.3107, val_loss=11.8413, \n",
            "Epoch 2810/6000: train_loss=9.3106, val_loss=12.3223, \n",
            "Epoch 2811/6000: train_loss=9.2648, val_loss=12.2818, \n",
            "Epoch 2812/6000: train_loss=9.4476, val_loss=12.8039, \n",
            "Epoch 2813/6000: train_loss=9.3072, val_loss=11.6737, \n",
            "Epoch 2814/6000: train_loss=9.3209, val_loss=12.0628, \n",
            "Epoch 2815/6000: train_loss=9.4587, val_loss=12.0374, \n",
            "Epoch 2816/6000: train_loss=9.3890, val_loss=12.8007, \n",
            "Epoch 2817/6000: train_loss=9.2546, val_loss=11.7099, \n",
            "Epoch 2818/6000: train_loss=9.2749, val_loss=11.7731, \n",
            "Epoch 2819/6000: train_loss=9.2505, val_loss=12.2844, \n",
            "Epoch 2820/6000: train_loss=9.2735, val_loss=12.4121, \n",
            "Epoch 2821/6000: train_loss=9.2795, val_loss=12.6476, \n",
            "Epoch 2822/6000: train_loss=9.5153, val_loss=11.4754, \n",
            "Epoch 2823/6000: train_loss=9.2417, val_loss=11.6104, \n",
            "Epoch 2824/6000: train_loss=9.2670, val_loss=11.8929, \n",
            "Epoch 2825/6000: train_loss=9.2381, val_loss=11.6682, \n",
            "Epoch 2826/6000: train_loss=9.2401, val_loss=12.3083, \n",
            "Epoch 2827/6000: train_loss=9.2798, val_loss=12.0910, \n",
            "Epoch 2828/6000: train_loss=9.2443, val_loss=12.2900, \n",
            "Epoch 2829/6000: train_loss=9.2833, val_loss=12.3374, \n",
            "Epoch 2830/6000: train_loss=9.6497, val_loss=11.7476, \n",
            "Epoch 2831/6000: train_loss=9.9278, val_loss=13.8399, \n",
            "Epoch 2832/6000: train_loss=9.4580, val_loss=11.4697, \n",
            "Epoch 2833/6000: train_loss=9.3601, val_loss=12.2442, \n",
            "Epoch 2834/6000: train_loss=9.3086, val_loss=11.8307, \n",
            "Epoch 2835/6000: train_loss=9.4738, val_loss=13.2443, \n",
            "Epoch 2836/6000: train_loss=9.2933, val_loss=12.1274, \n",
            "Epoch 2837/6000: train_loss=9.2646, val_loss=11.6929, \n",
            "Epoch 2838/6000: train_loss=9.3750, val_loss=12.3774, \n",
            "Epoch 2839/6000: train_loss=9.7971, val_loss=11.5255, \n",
            "Epoch 2840/6000: train_loss=9.5696, val_loss=13.2943, \n",
            "Epoch 2841/6000: train_loss=9.2322, val_loss=12.0621, \n",
            "Epoch 2842/6000: train_loss=9.5143, val_loss=11.5945, \n",
            "Epoch 2843/6000: train_loss=9.2181, val_loss=12.1298, \n",
            "Epoch 2844/6000: train_loss=9.1982, val_loss=11.8018, \n",
            "Epoch 2845/6000: train_loss=9.2733, val_loss=12.1941, \n",
            "Epoch 2846/6000: train_loss=9.2500, val_loss=11.7610, \n",
            "Epoch 2847/6000: train_loss=9.2946, val_loss=11.8553, \n",
            "Epoch 2848/6000: train_loss=9.5754, val_loss=13.1107, \n",
            "Epoch 2849/6000: train_loss=9.6637, val_loss=11.5950, \n",
            "Epoch 2850/6000: train_loss=9.4681, val_loss=12.9472, \n",
            "Epoch 2851/6000: train_loss=9.1993, val_loss=11.9480, \n",
            "Epoch 2852/6000: train_loss=9.1834, val_loss=12.0051, \n",
            "Epoch 2853/6000: train_loss=9.1925, val_loss=11.7551, \n",
            "Epoch 2854/6000: train_loss=9.1861, val_loss=11.7232, \n",
            "Epoch 2855/6000: train_loss=9.2983, val_loss=11.7513, \n",
            "Epoch 2856/6000: train_loss=9.1888, val_loss=11.6172, \n",
            "Epoch 2857/6000: train_loss=9.1905, val_loss=11.6175, \n",
            "Epoch 2858/6000: train_loss=9.1703, val_loss=11.9438, \n",
            "Epoch 2859/6000: train_loss=9.3365, val_loss=12.8530, \n",
            "Epoch 2860/6000: train_loss=9.6030, val_loss=11.6634, \n",
            "Epoch 2861/6000: train_loss=10.2580, val_loss=14.0420, \n",
            "Epoch 2862/6000: train_loss=9.5285, val_loss=11.6965, \n",
            "Epoch 2863/6000: train_loss=9.3671, val_loss=13.0046, \n",
            "Epoch 2864/6000: train_loss=9.1830, val_loss=12.1681, \n",
            "Epoch 2865/6000: train_loss=9.1745, val_loss=12.1260, \n",
            "Epoch 2866/6000: train_loss=9.5398, val_loss=11.2156, \n",
            "Epoch 2867/6000: train_loss=9.4235, val_loss=12.4152, \n",
            "Epoch 2868/6000: train_loss=9.1976, val_loss=11.5796, \n",
            "Epoch 2869/6000: train_loss=9.2218, val_loss=11.4097, \n",
            "Epoch 2870/6000: train_loss=9.2893, val_loss=12.6177, \n",
            "Epoch 2871/6000: train_loss=9.2686, val_loss=12.2522, \n",
            "Epoch 2872/6000: train_loss=9.5424, val_loss=13.1228, \n",
            "Epoch 2873/6000: train_loss=9.7872, val_loss=11.2511, \n",
            "Epoch 2874/6000: train_loss=9.3829, val_loss=12.8005, \n",
            "Epoch 2875/6000: train_loss=9.1863, val_loss=12.1497, \n",
            "Epoch 2876/6000: train_loss=9.2469, val_loss=11.7775, \n",
            "Epoch 2877/6000: train_loss=9.4011, val_loss=12.2481, \n",
            "Epoch 2878/6000: train_loss=9.6678, val_loss=11.3546, \n",
            "Epoch 2879/6000: train_loss=9.5404, val_loss=13.3762, \n",
            "Epoch 2880/6000: train_loss=9.2854, val_loss=11.9988, \n",
            "Epoch 2881/6000: train_loss=9.1590, val_loss=12.0754, \n",
            "Epoch 2882/6000: train_loss=9.1357, val_loss=11.7438, \n",
            "Epoch 2883/6000: train_loss=9.1546, val_loss=11.6851, \n",
            "Epoch 2884/6000: train_loss=9.1618, val_loss=12.4419, \n",
            "Epoch 2885/6000: train_loss=9.2041, val_loss=12.4916, \n",
            "Epoch 2886/6000: train_loss=9.2772, val_loss=12.3073, \n",
            "Epoch 2887/6000: train_loss=9.8981, val_loss=11.3568, \n",
            "Epoch 2888/6000: train_loss=10.2190, val_loss=14.1500, \n",
            "Epoch 2889/6000: train_loss=9.9986, val_loss=11.9213, \n",
            "Epoch 2890/6000: train_loss=9.7477, val_loss=13.8664, \n",
            "Epoch 2891/6000: train_loss=9.2096, val_loss=11.7300, \n",
            "Epoch 2892/6000: train_loss=9.3675, val_loss=12.6855, \n",
            "Epoch 2893/6000: train_loss=9.1515, val_loss=12.0612, \n",
            "Epoch 2894/6000: train_loss=9.2242, val_loss=11.4122, \n",
            "Epoch 2895/6000: train_loss=9.3299, val_loss=12.2525, \n",
            "Epoch 2896/6000: train_loss=9.1878, val_loss=11.7153, \n",
            "Epoch 2897/6000: train_loss=9.1486, val_loss=12.4131, \n",
            "Epoch 2898/6000: train_loss=9.1262, val_loss=12.2504, \n",
            "Epoch 2899/6000: train_loss=9.1927, val_loss=11.3829, \n",
            "Epoch 2900/6000: train_loss=9.2324, val_loss=11.7595, \n",
            "Epoch 2901/6000: train_loss=9.1153, val_loss=11.7858, \n",
            "Epoch 2902/6000: train_loss=9.3246, val_loss=12.1621, \n",
            "Epoch 2903/6000: train_loss=9.7120, val_loss=13.8267, \n",
            "Epoch 2904/6000: train_loss=9.4048, val_loss=11.5405, \n",
            "Epoch 2905/6000: train_loss=9.1502, val_loss=11.7595, \n",
            "Epoch 2906/6000: train_loss=9.2857, val_loss=11.1836, \n",
            "Epoch 2907/6000: train_loss=9.1238, val_loss=12.1720, \n",
            "Epoch 2908/6000: train_loss=9.2913, val_loss=11.7357, \n",
            "Epoch 2909/6000: train_loss=9.2002, val_loss=12.4321, \n",
            "Epoch 2910/6000: train_loss=9.0977, val_loss=11.7300, \n",
            "Epoch 2911/6000: train_loss=9.1044, val_loss=11.6863, \n",
            "Epoch 2912/6000: train_loss=9.0865, val_loss=12.1474, \n",
            "Epoch 2913/6000: train_loss=9.0705, val_loss=11.7972, \n",
            "Epoch 2914/6000: train_loss=9.1445, val_loss=11.4882, \n",
            "Epoch 2915/6000: train_loss=9.1393, val_loss=12.2738, \n",
            "Epoch 2916/6000: train_loss=9.1022, val_loss=12.1882, \n",
            "Epoch 2917/6000: train_loss=9.1103, val_loss=11.7755, \n",
            "Epoch 2918/6000: train_loss=9.0965, val_loss=11.7667, \n",
            "Epoch 2919/6000: train_loss=9.0872, val_loss=12.1091, \n",
            "Epoch 2920/6000: train_loss=9.0666, val_loss=11.7130, \n",
            "Epoch 2921/6000: train_loss=9.1140, val_loss=11.3238, \n",
            "Epoch 2922/6000: train_loss=9.4773, val_loss=12.7443, \n",
            "Epoch 2923/6000: train_loss=9.4037, val_loss=11.7023, \n",
            "Epoch 2924/6000: train_loss=9.1792, val_loss=12.6742, \n",
            "Epoch 2925/6000: train_loss=9.0708, val_loss=11.8212, \n",
            "Epoch 2926/6000: train_loss=9.0638, val_loss=11.5820, \n",
            "Epoch 2927/6000: train_loss=9.0719, val_loss=11.4789, \n",
            "Epoch 2928/6000: train_loss=9.0690, val_loss=11.6542, \n",
            "Epoch 2929/6000: train_loss=9.0575, val_loss=11.6963, \n",
            "Epoch 2930/6000: train_loss=9.0673, val_loss=11.5318, \n",
            "Epoch 2931/6000: train_loss=9.0622, val_loss=11.5944, \n",
            "Epoch 2932/6000: train_loss=9.0379, val_loss=11.7830, \n",
            "Epoch 2933/6000: train_loss=9.0427, val_loss=11.9574, \n",
            "Epoch 2934/6000: train_loss=9.0985, val_loss=12.0783, \n",
            "Epoch 2935/6000: train_loss=9.0764, val_loss=12.0595, \n",
            "Epoch 2936/6000: train_loss=9.1267, val_loss=11.8873, \n",
            "Epoch 2937/6000: train_loss=9.1373, val_loss=12.4112, \n",
            "Epoch 2938/6000: train_loss=9.7233, val_loss=11.3903, \n",
            "Epoch 2939/6000: train_loss=9.2139, val_loss=12.6396, \n",
            "Epoch 2940/6000: train_loss=9.6551, val_loss=11.7280, \n",
            "Epoch 2941/6000: train_loss=9.2671, val_loss=12.4463, \n",
            "Epoch 2942/6000: train_loss=9.1164, val_loss=11.1139, \n",
            "Epoch 2943/6000: train_loss=9.0877, val_loss=11.6530, \n",
            "Epoch 2944/6000: train_loss=9.4200, val_loss=13.4620, \n",
            "Epoch 2945/6000: train_loss=9.3225, val_loss=12.0267, \n",
            "Epoch 2946/6000: train_loss=9.2140, val_loss=12.6593, \n",
            "Epoch 2947/6000: train_loss=9.1617, val_loss=11.0169, \n",
            "Epoch 2948/6000: train_loss=9.4566, val_loss=12.4283, \n",
            "Epoch 2949/6000: train_loss=9.7348, val_loss=11.1446, \n",
            "Epoch 2950/6000: train_loss=9.4294, val_loss=13.0563, \n",
            "Epoch 2951/6000: train_loss=9.1544, val_loss=11.6622, \n",
            "Epoch 2952/6000: train_loss=9.8415, val_loss=13.5556, \n",
            "Epoch 2953/6000: train_loss=9.6594, val_loss=11.3577, \n",
            "Epoch 2954/6000: train_loss=9.0284, val_loss=12.0125, \n",
            "Epoch 2955/6000: train_loss=9.0860, val_loss=11.5794, \n",
            "Epoch 2956/6000: train_loss=9.1975, val_loss=12.1285, \n",
            "Epoch 2957/6000: train_loss=9.1760, val_loss=11.2320, \n",
            "Epoch 2958/6000: train_loss=9.2582, val_loss=12.9168, \n",
            "Epoch 2959/6000: train_loss=9.0124, val_loss=11.9997, \n",
            "Epoch 2960/6000: train_loss=9.0689, val_loss=11.9152, \n",
            "Epoch 2961/6000: train_loss=9.0278, val_loss=11.3156, \n",
            "Epoch 2962/6000: train_loss=9.1939, val_loss=11.7025, \n",
            "Epoch 2963/6000: train_loss=9.4392, val_loss=13.4846, \n",
            "Epoch 2964/6000: train_loss=9.2133, val_loss=11.5332, \n",
            "Epoch 2965/6000: train_loss=9.5329, val_loss=12.9357, \n",
            "Epoch 2966/6000: train_loss=9.3256, val_loss=11.1260, \n",
            "Epoch 2967/6000: train_loss=9.2278, val_loss=12.7625, \n",
            "Epoch 2968/6000: train_loss=9.0083, val_loss=11.8828, \n",
            "Epoch 2969/6000: train_loss=8.9945, val_loss=11.7943, \n",
            "Epoch 2970/6000: train_loss=9.0419, val_loss=11.5832, \n",
            "Epoch 2971/6000: train_loss=8.9882, val_loss=11.3599, \n",
            "Epoch 2972/6000: train_loss=9.1290, val_loss=12.3989, \n",
            "Epoch 2973/6000: train_loss=9.1685, val_loss=11.4176, \n",
            "Epoch 2974/6000: train_loss=9.1542, val_loss=12.1338, \n",
            "Epoch 2975/6000: train_loss=9.0786, val_loss=11.2739, \n",
            "Epoch 2976/6000: train_loss=9.7230, val_loss=13.7391, \n",
            "Epoch 2977/6000: train_loss=9.1855, val_loss=12.0143, \n",
            "Epoch 2978/6000: train_loss=9.0321, val_loss=11.5503, \n",
            "Epoch 2979/6000: train_loss=9.0378, val_loss=11.4386, \n",
            "Epoch 2980/6000: train_loss=8.9671, val_loss=11.4208, \n",
            "Epoch 2981/6000: train_loss=8.9785, val_loss=12.0843, \n",
            "Epoch 2982/6000: train_loss=8.9696, val_loss=11.8541, \n",
            "Epoch 2983/6000: train_loss=8.9910, val_loss=11.5458, \n",
            "Epoch 2984/6000: train_loss=9.0938, val_loss=11.5081, \n",
            "Epoch 2985/6000: train_loss=9.2637, val_loss=11.6578, \n",
            "Epoch 2986/6000: train_loss=9.4719, val_loss=13.6668, \n",
            "Epoch 2987/6000: train_loss=9.8079, val_loss=11.6673, \n",
            "Epoch 2988/6000: train_loss=9.7443, val_loss=13.2537, \n",
            "Epoch 2989/6000: train_loss=9.5796, val_loss=11.0503, \n",
            "Epoch 2990/6000: train_loss=9.3228, val_loss=12.4095, \n",
            "Epoch 2991/6000: train_loss=9.0394, val_loss=11.1051, \n",
            "Epoch 2992/6000: train_loss=9.1312, val_loss=12.4159, \n",
            "Epoch 2993/6000: train_loss=9.0902, val_loss=11.6088, \n",
            "Epoch 2994/6000: train_loss=8.9587, val_loss=11.4663, \n",
            "Epoch 2995/6000: train_loss=9.1009, val_loss=12.1739, \n",
            "Epoch 2996/6000: train_loss=9.2723, val_loss=11.1911, \n",
            "Epoch 2997/6000: train_loss=9.2513, val_loss=12.6441, \n",
            "Epoch 2998/6000: train_loss=8.9951, val_loss=11.3348, \n",
            "Epoch 2999/6000: train_loss=9.0736, val_loss=12.1646, \n",
            "Epoch 3000/6000: train_loss=8.9617, val_loss=11.5671, \n",
            "Epoch 3001/6000: train_loss=8.9216, val_loss=11.6263, \n",
            "Epoch 3002/6000: train_loss=9.1697, val_loss=11.0242, \n",
            "Epoch 3003/6000: train_loss=8.9267, val_loss=11.4249, \n",
            "Epoch 3004/6000: train_loss=8.9843, val_loss=11.4191, \n",
            "Epoch 3005/6000: train_loss=9.1920, val_loss=12.6798, \n",
            "Epoch 3006/6000: train_loss=9.2258, val_loss=11.3789, \n",
            "Epoch 3007/6000: train_loss=8.9156, val_loss=11.8088, \n",
            "Epoch 3008/6000: train_loss=8.8981, val_loss=11.4647, \n",
            "Epoch 3009/6000: train_loss=8.9291, val_loss=11.5328, \n",
            "Epoch 3010/6000: train_loss=8.9068, val_loss=11.3381, \n",
            "Epoch 3011/6000: train_loss=8.9586, val_loss=11.3818, \n",
            "Epoch 3012/6000: train_loss=8.9359, val_loss=12.2161, \n",
            "Epoch 3013/6000: train_loss=9.0007, val_loss=11.6258, \n",
            "Epoch 3014/6000: train_loss=8.9902, val_loss=11.9430, \n",
            "Epoch 3015/6000: train_loss=8.9272, val_loss=11.5733, \n",
            "Epoch 3016/6000: train_loss=8.8936, val_loss=11.5224, \n",
            "Epoch 3017/6000: train_loss=8.8936, val_loss=11.7277, \n",
            "Epoch 3018/6000: train_loss=8.8896, val_loss=11.7028, \n",
            "Epoch 3019/6000: train_loss=8.9244, val_loss=11.9226, \n",
            "Epoch 3020/6000: train_loss=8.8941, val_loss=11.5626, \n",
            "Epoch 3021/6000: train_loss=8.9287, val_loss=11.3971, \n",
            "Epoch 3022/6000: train_loss=9.1522, val_loss=12.3180, \n",
            "Epoch 3023/6000: train_loss=8.9955, val_loss=11.3483, \n",
            "Epoch 3024/6000: train_loss=9.3749, val_loss=13.1258, \n",
            "Epoch 3025/6000: train_loss=8.9195, val_loss=11.2331, \n",
            "Epoch 3026/6000: train_loss=8.9237, val_loss=11.1046, \n",
            "Epoch 3027/6000: train_loss=8.8724, val_loss=11.6441, \n",
            "Epoch 3028/6000: train_loss=8.9633, val_loss=12.3615, \n",
            "Epoch 3029/6000: train_loss=9.0497, val_loss=11.1282, \n",
            "Epoch 3030/6000: train_loss=8.9082, val_loss=11.5384, \n",
            "Epoch 3031/6000: train_loss=8.8744, val_loss=11.5634, \n",
            "Epoch 3032/6000: train_loss=9.4331, val_loss=11.2277, \n",
            "Epoch 3033/6000: train_loss=9.4178, val_loss=12.8072, \n",
            "Epoch 3034/6000: train_loss=9.4153, val_loss=11.0647, \n",
            "Epoch 3035/6000: train_loss=9.1663, val_loss=12.2792, \n",
            "Epoch 3036/6000: train_loss=9.5014, val_loss=11.0060, \n",
            "Epoch 3037/6000: train_loss=9.3825, val_loss=12.8344, \n",
            "Epoch 3038/6000: train_loss=9.1444, val_loss=11.5025, \n",
            "Epoch 3039/6000: train_loss=8.8622, val_loss=11.5533, \n",
            "Epoch 3040/6000: train_loss=8.9019, val_loss=11.1501, \n",
            "Epoch 3041/6000: train_loss=8.8965, val_loss=11.9434, \n",
            "Epoch 3042/6000: train_loss=8.8634, val_loss=11.7222, \n",
            "Epoch 3043/6000: train_loss=8.8899, val_loss=11.2511, \n",
            "Epoch 3044/6000: train_loss=9.0966, val_loss=12.1799, \n",
            "Epoch 3045/6000: train_loss=9.2353, val_loss=11.0100, \n",
            "Epoch 3046/6000: train_loss=9.2322, val_loss=12.4965, \n",
            "Epoch 3047/6000: train_loss=9.0104, val_loss=11.2479, \n",
            "Epoch 3048/6000: train_loss=8.8767, val_loss=11.2904, \n",
            "Epoch 3049/6000: train_loss=8.9058, val_loss=11.8973, \n",
            "Epoch 3050/6000: train_loss=8.8547, val_loss=11.6848, \n",
            "Epoch 3051/6000: train_loss=8.8430, val_loss=11.4082, \n",
            "Epoch 3052/6000: train_loss=8.8591, val_loss=11.4167, \n",
            "Epoch 3053/6000: train_loss=8.8328, val_loss=11.4352, \n",
            "Epoch 3054/6000: train_loss=8.8487, val_loss=11.7358, \n",
            "Epoch 3055/6000: train_loss=9.2811, val_loss=13.1942, \n",
            "Epoch 3056/6000: train_loss=9.3241, val_loss=10.9377, \n",
            "Epoch 3057/6000: train_loss=9.1523, val_loss=11.7782, \n",
            "Epoch 3058/6000: train_loss=8.8515, val_loss=11.0620, \n",
            "Epoch 3059/6000: train_loss=8.8522, val_loss=12.0044, \n",
            "Epoch 3060/6000: train_loss=9.0432, val_loss=12.3977, \n",
            "Epoch 3061/6000: train_loss=9.0508, val_loss=11.1638, \n",
            "Epoch 3062/6000: train_loss=8.9233, val_loss=12.2079, \n",
            "Epoch 3063/6000: train_loss=10.0749, val_loss=11.5534, \n",
            "Epoch 3064/6000: train_loss=9.3701, val_loss=12.8619, \n",
            "Epoch 3065/6000: train_loss=8.8995, val_loss=10.9284, \n",
            "Epoch 3066/6000: train_loss=8.8805, val_loss=11.6787, \n",
            "Epoch 3067/6000: train_loss=8.9743, val_loss=11.9987, \n",
            "Epoch 3068/6000: train_loss=9.0061, val_loss=11.2519, \n",
            "Epoch 3069/6000: train_loss=9.0102, val_loss=12.5812, \n",
            "Epoch 3070/6000: train_loss=9.1187, val_loss=11.5963, \n",
            "Epoch 3071/6000: train_loss=9.0365, val_loss=12.0557, \n",
            "Epoch 3072/6000: train_loss=9.6154, val_loss=10.7792, \n",
            "Epoch 3073/6000: train_loss=9.4093, val_loss=12.9197, \n",
            "Epoch 3074/6000: train_loss=8.8094, val_loss=11.7336, \n",
            "Epoch 3075/6000: train_loss=8.8113, val_loss=11.8135, \n",
            "Epoch 3076/6000: train_loss=8.9519, val_loss=11.8896, \n",
            "Epoch 3077/6000: train_loss=9.1444, val_loss=11.1988, \n",
            "Epoch 3078/6000: train_loss=9.0710, val_loss=12.6339, \n",
            "Epoch 3079/6000: train_loss=9.2354, val_loss=11.2461, \n",
            "Epoch 3080/6000: train_loss=9.0781, val_loss=12.2083, \n",
            "Epoch 3081/6000: train_loss=9.0155, val_loss=10.6366, \n",
            "Epoch 3082/6000: train_loss=8.9193, val_loss=11.9052, \n",
            "Epoch 3083/6000: train_loss=8.8546, val_loss=11.4305, \n",
            "Epoch 3084/6000: train_loss=8.8089, val_loss=11.5754, \n",
            "Epoch 3085/6000: train_loss=8.7992, val_loss=11.4966, \n",
            "Epoch 3086/6000: train_loss=8.7770, val_loss=11.2863, \n",
            "Epoch 3087/6000: train_loss=9.0266, val_loss=11.8273, \n",
            "Epoch 3088/6000: train_loss=9.1173, val_loss=10.9390, \n",
            "Epoch 3089/6000: train_loss=9.4201, val_loss=13.2658, \n",
            "Epoch 3090/6000: train_loss=9.0913, val_loss=11.3723, \n",
            "Epoch 3091/6000: train_loss=8.7759, val_loss=11.4700, \n",
            "Epoch 3092/6000: train_loss=8.9439, val_loss=11.8495, \n",
            "Epoch 3093/6000: train_loss=8.8510, val_loss=10.8388, \n",
            "Epoch 3094/6000: train_loss=9.2871, val_loss=12.8039, \n",
            "Epoch 3095/6000: train_loss=9.2489, val_loss=10.8661, \n",
            "Epoch 3096/6000: train_loss=9.3070, val_loss=12.6078, \n",
            "Epoch 3097/6000: train_loss=8.7906, val_loss=11.3524, \n",
            "Epoch 3098/6000: train_loss=8.7960, val_loss=12.1098, \n",
            "Epoch 3099/6000: train_loss=8.7545, val_loss=11.8044, \n",
            "Epoch 3100/6000: train_loss=8.8239, val_loss=11.0180, \n",
            "Epoch 3101/6000: train_loss=9.0129, val_loss=11.7744, \n",
            "Epoch 3102/6000: train_loss=9.1922, val_loss=10.7963, \n",
            "Epoch 3103/6000: train_loss=9.7703, val_loss=13.5616, \n",
            "Epoch 3104/6000: train_loss=9.0546, val_loss=10.9904, \n",
            "Epoch 3105/6000: train_loss=8.9022, val_loss=11.8726, \n",
            "Epoch 3106/6000: train_loss=9.6401, val_loss=11.1841, \n",
            "Epoch 3107/6000: train_loss=9.4739, val_loss=13.5284, \n",
            "Epoch 3108/6000: train_loss=9.3732, val_loss=10.9155, \n",
            "Epoch 3109/6000: train_loss=9.1205, val_loss=12.1086, \n",
            "Epoch 3110/6000: train_loss=8.9593, val_loss=10.8656, \n",
            "Epoch 3111/6000: train_loss=8.7962, val_loss=12.1790, \n",
            "Epoch 3112/6000: train_loss=8.7683, val_loss=12.0662, \n",
            "Epoch 3113/6000: train_loss=9.0515, val_loss=11.0386, \n",
            "Epoch 3114/6000: train_loss=9.2404, val_loss=12.6281, \n",
            "Epoch 3115/6000: train_loss=10.1345, val_loss=11.4223, \n",
            "Epoch 3116/6000: train_loss=9.8532, val_loss=13.8630, \n",
            "Epoch 3117/6000: train_loss=9.4953, val_loss=11.1781, \n",
            "Epoch 3118/6000: train_loss=9.2626, val_loss=12.6431, \n",
            "Epoch 3119/6000: train_loss=9.4246, val_loss=10.8355, \n",
            "Epoch 3120/6000: train_loss=9.2006, val_loss=12.7031, \n",
            "Epoch 3121/6000: train_loss=8.9514, val_loss=11.0482, \n",
            "Epoch 3122/6000: train_loss=8.6964, val_loss=11.4155, \n",
            "Epoch 3123/6000: train_loss=8.7471, val_loss=11.5727, \n",
            "Epoch 3124/6000: train_loss=9.4178, val_loss=10.9915, \n",
            "Epoch 3125/6000: train_loss=8.8578, val_loss=11.9874, \n",
            "Epoch 3126/6000: train_loss=8.7176, val_loss=11.1533, \n",
            "Epoch 3127/6000: train_loss=8.6993, val_loss=11.5983, \n",
            "Epoch 3128/6000: train_loss=8.7325, val_loss=11.7505, \n",
            "Epoch 3129/6000: train_loss=8.7545, val_loss=11.7575, \n",
            "Epoch 3130/6000: train_loss=9.0600, val_loss=10.8069, \n",
            "Epoch 3131/6000: train_loss=8.7252, val_loss=11.4765, \n",
            "Epoch 3132/6000: train_loss=8.8321, val_loss=11.1016, \n",
            "Epoch 3133/6000: train_loss=8.7039, val_loss=11.5015, \n",
            "Epoch 3134/6000: train_loss=8.8310, val_loss=12.1198, \n",
            "Epoch 3135/6000: train_loss=8.7162, val_loss=11.0490, \n",
            "Epoch 3136/6000: train_loss=9.1376, val_loss=12.0744, \n",
            "Epoch 3137/6000: train_loss=9.0130, val_loss=10.9383, \n",
            "Epoch 3138/6000: train_loss=8.7931, val_loss=12.1118, \n",
            "Epoch 3139/6000: train_loss=8.8752, val_loss=10.7611, \n",
            "Epoch 3140/6000: train_loss=8.7543, val_loss=10.6929, \n",
            "Epoch 3141/6000: train_loss=8.7301, val_loss=11.4254, \n",
            "Epoch 3142/6000: train_loss=8.8012, val_loss=12.0259, \n",
            "Epoch 3143/6000: train_loss=8.6848, val_loss=11.5903, \n",
            "Epoch 3144/6000: train_loss=9.0162, val_loss=11.7416, \n",
            "Epoch 3145/6000: train_loss=8.7240, val_loss=11.1207, \n",
            "Epoch 3146/6000: train_loss=8.7508, val_loss=12.1353, \n",
            "Epoch 3147/6000: train_loss=8.7481, val_loss=12.0679, \n",
            "Epoch 3148/6000: train_loss=8.7599, val_loss=10.7017, \n",
            "Epoch 3149/6000: train_loss=8.9667, val_loss=10.2556, \n",
            "Epoch 3150/6000: train_loss=9.0239, val_loss=12.2019, \n",
            "Epoch 3151/6000: train_loss=8.8764, val_loss=11.0318, \n",
            "Epoch 3152/6000: train_loss=9.0436, val_loss=12.3254, \n",
            "Epoch 3153/6000: train_loss=9.1036, val_loss=10.5648, \n",
            "Epoch 3154/6000: train_loss=8.9224, val_loss=11.8233, \n",
            "Epoch 3155/6000: train_loss=9.3770, val_loss=11.1184, \n",
            "Epoch 3156/6000: train_loss=9.3168, val_loss=12.7728, \n",
            "Epoch 3157/6000: train_loss=9.7274, val_loss=10.8722, \n",
            "Epoch 3158/6000: train_loss=9.0070, val_loss=11.9857, \n",
            "Epoch 3159/6000: train_loss=9.0501, val_loss=10.9574, \n",
            "Epoch 3160/6000: train_loss=8.7249, val_loss=11.8012, \n",
            "Epoch 3161/6000: train_loss=8.9560, val_loss=12.3065, \n",
            "Epoch 3162/6000: train_loss=9.0734, val_loss=10.9916, \n",
            "Epoch 3163/6000: train_loss=9.0680, val_loss=12.5364, \n",
            "Epoch 3164/6000: train_loss=9.6900, val_loss=11.2056, \n",
            "Epoch 3165/6000: train_loss=9.9194, val_loss=13.6081, \n",
            "Epoch 3166/6000: train_loss=9.3378, val_loss=10.7337, \n",
            "Epoch 3167/6000: train_loss=8.6687, val_loss=11.4552, \n",
            "Epoch 3168/6000: train_loss=8.6461, val_loss=11.4792, \n",
            "Epoch 3169/6000: train_loss=8.6380, val_loss=11.1742, \n",
            "Epoch 3170/6000: train_loss=8.8445, val_loss=11.7631, \n",
            "Epoch 3171/6000: train_loss=8.6164, val_loss=11.1644, \n",
            "Epoch 3172/6000: train_loss=8.6174, val_loss=11.2627, \n",
            "Epoch 3173/6000: train_loss=8.6171, val_loss=11.2866, \n",
            "Epoch 3174/6000: train_loss=9.0527, val_loss=12.2740, \n",
            "Epoch 3175/6000: train_loss=9.1579, val_loss=10.8678, \n",
            "Epoch 3176/6000: train_loss=8.6377, val_loss=11.4645, \n",
            "Epoch 3177/6000: train_loss=8.6454, val_loss=11.5606, \n",
            "Epoch 3178/6000: train_loss=8.6629, val_loss=11.7402, \n",
            "Epoch 3179/6000: train_loss=8.6285, val_loss=10.7859, \n",
            "Epoch 3180/6000: train_loss=8.6673, val_loss=10.4828, \n",
            "Epoch 3181/6000: train_loss=8.7195, val_loss=11.5526, \n",
            "Epoch 3182/6000: train_loss=8.8367, val_loss=11.2964, \n",
            "Epoch 3183/6000: train_loss=9.1564, val_loss=12.7937, \n",
            "Epoch 3184/6000: train_loss=8.7907, val_loss=10.6975, \n",
            "Epoch 3185/6000: train_loss=8.6135, val_loss=11.1575, \n",
            "Epoch 3186/6000: train_loss=8.6310, val_loss=11.3937, \n",
            "Epoch 3187/6000: train_loss=8.6478, val_loss=11.5509, \n",
            "Epoch 3188/6000: train_loss=8.7174, val_loss=10.6004, \n",
            "Epoch 3189/6000: train_loss=8.6737, val_loss=10.6825, \n",
            "Epoch 3190/6000: train_loss=8.6241, val_loss=11.5283, \n",
            "Epoch 3191/6000: train_loss=8.6108, val_loss=11.5788, \n",
            "Epoch 3192/6000: train_loss=8.7036, val_loss=11.5693, \n",
            "Epoch 3193/6000: train_loss=8.7667, val_loss=10.6140, \n",
            "Epoch 3194/6000: train_loss=8.8780, val_loss=12.0967, \n",
            "Epoch 3195/6000: train_loss=8.8132, val_loss=10.9154, \n",
            "Epoch 3196/6000: train_loss=8.6316, val_loss=11.3411, \n",
            "Epoch 3197/6000: train_loss=8.5835, val_loss=11.3191, \n",
            "Epoch 3198/6000: train_loss=8.6784, val_loss=10.9324, \n",
            "Epoch 3199/6000: train_loss=8.6991, val_loss=11.8225, \n",
            "Epoch 3200/6000: train_loss=8.6403, val_loss=10.8086, \n",
            "Epoch 3201/6000: train_loss=9.1441, val_loss=12.4690, \n",
            "Epoch 3202/6000: train_loss=8.6262, val_loss=10.8223, \n",
            "Epoch 3203/6000: train_loss=8.6049, val_loss=11.5591, \n",
            "Epoch 3204/6000: train_loss=8.7417, val_loss=11.2712, \n",
            "Epoch 3205/6000: train_loss=8.6125, val_loss=11.5071, \n",
            "Epoch 3206/6000: train_loss=8.7379, val_loss=10.4023, \n",
            "Epoch 3207/6000: train_loss=8.6419, val_loss=11.0473, \n",
            "Epoch 3208/6000: train_loss=8.6110, val_loss=11.4362, \n",
            "Epoch 3209/6000: train_loss=8.6740, val_loss=11.0137, \n",
            "Epoch 3210/6000: train_loss=8.5846, val_loss=11.2738, \n",
            "Epoch 3211/6000: train_loss=8.6126, val_loss=11.0446, \n",
            "Epoch 3212/6000: train_loss=8.5829, val_loss=11.4564, \n",
            "Epoch 3213/6000: train_loss=8.6874, val_loss=12.3206, \n",
            "Epoch 3214/6000: train_loss=8.6988, val_loss=11.0336, \n",
            "Epoch 3215/6000: train_loss=8.6587, val_loss=11.4130, \n",
            "Epoch 3216/6000: train_loss=8.5861, val_loss=10.6486, \n",
            "Epoch 3217/6000: train_loss=8.5637, val_loss=11.1942, \n",
            "Epoch 3218/6000: train_loss=8.5571, val_loss=11.1141, \n",
            "Epoch 3219/6000: train_loss=8.5488, val_loss=11.2164, \n",
            "Epoch 3220/6000: train_loss=8.8438, val_loss=10.5804, \n",
            "Epoch 3221/6000: train_loss=8.6909, val_loss=11.6451, \n",
            "Epoch 3222/6000: train_loss=8.6955, val_loss=10.9903, \n",
            "Epoch 3223/6000: train_loss=8.5577, val_loss=11.3314, \n",
            "Epoch 3224/6000: train_loss=9.0142, val_loss=10.5305, \n",
            "Epoch 3225/6000: train_loss=8.8203, val_loss=11.6306, \n",
            "Epoch 3226/6000: train_loss=8.7856, val_loss=10.5612, \n",
            "Epoch 3227/6000: train_loss=9.1454, val_loss=12.8621, \n",
            "Epoch 3228/6000: train_loss=9.0543, val_loss=10.8297, \n",
            "Epoch 3229/6000: train_loss=9.1830, val_loss=12.3087, \n",
            "Epoch 3230/6000: train_loss=9.1924, val_loss=11.0764, \n",
            "Epoch 3231/6000: train_loss=8.8442, val_loss=12.4551, \n",
            "Epoch 3232/6000: train_loss=8.5752, val_loss=11.3889, \n",
            "Epoch 3233/6000: train_loss=8.7474, val_loss=10.1330, \n",
            "Epoch 3234/6000: train_loss=8.5704, val_loss=10.9776, \n",
            "Epoch 3235/6000: train_loss=8.9458, val_loss=11.5569, \n",
            "Epoch 3236/6000: train_loss=9.3447, val_loss=13.6494, \n",
            "Epoch 3237/6000: train_loss=8.8860, val_loss=10.3524, \n",
            "Epoch 3238/6000: train_loss=8.6187, val_loss=10.6367, \n",
            "Epoch 3239/6000: train_loss=8.5212, val_loss=11.0977, \n",
            "Epoch 3240/6000: train_loss=8.6125, val_loss=12.0062, \n",
            "Epoch 3241/6000: train_loss=8.5773, val_loss=10.9837, \n",
            "Epoch 3242/6000: train_loss=9.0147, val_loss=12.1093, \n",
            "Epoch 3243/6000: train_loss=8.5505, val_loss=10.9930, \n",
            "Epoch 3244/6000: train_loss=8.5515, val_loss=11.1888, \n",
            "Epoch 3245/6000: train_loss=8.8591, val_loss=12.1505, \n",
            "Epoch 3246/6000: train_loss=8.5293, val_loss=10.7169, \n",
            "Epoch 3247/6000: train_loss=8.8819, val_loss=10.4704, \n",
            "Epoch 3248/6000: train_loss=8.6376, val_loss=11.8240, \n",
            "Epoch 3249/6000: train_loss=8.5530, val_loss=11.1467, \n",
            "Epoch 3250/6000: train_loss=8.4995, val_loss=11.0076, \n",
            "Epoch 3251/6000: train_loss=8.6494, val_loss=11.4807, \n",
            "Epoch 3252/6000: train_loss=8.5035, val_loss=10.7791, \n",
            "Epoch 3253/6000: train_loss=8.4885, val_loss=11.3252, \n",
            "Epoch 3254/6000: train_loss=8.5158, val_loss=11.6079, \n",
            "Epoch 3255/6000: train_loss=8.5139, val_loss=10.8062, \n",
            "Epoch 3256/6000: train_loss=8.6640, val_loss=11.4455, \n",
            "Epoch 3257/6000: train_loss=8.6547, val_loss=10.9871, \n",
            "Epoch 3258/6000: train_loss=8.6659, val_loss=12.3963, \n",
            "Epoch 3259/6000: train_loss=8.6878, val_loss=11.1625, \n",
            "Epoch 3260/6000: train_loss=8.9873, val_loss=11.7266, \n",
            "Epoch 3261/6000: train_loss=9.2454, val_loss=10.1347, \n",
            "Epoch 3262/6000: train_loss=8.7446, val_loss=11.9550, \n",
            "Epoch 3263/6000: train_loss=8.5655, val_loss=11.1321, \n",
            "Epoch 3264/6000: train_loss=8.5434, val_loss=11.2630, \n",
            "Epoch 3265/6000: train_loss=8.6709, val_loss=10.5194, \n",
            "Epoch 3266/6000: train_loss=8.9415, val_loss=12.6044, \n",
            "Epoch 3267/6000: train_loss=8.8171, val_loss=11.0685, \n",
            "Epoch 3268/6000: train_loss=8.6598, val_loss=11.7347, \n",
            "Epoch 3269/6000: train_loss=8.5217, val_loss=10.5189, \n",
            "Epoch 3270/6000: train_loss=8.5123, val_loss=10.6530, \n",
            "Epoch 3271/6000: train_loss=8.5248, val_loss=11.2452, \n",
            "Epoch 3272/6000: train_loss=8.5153, val_loss=11.5828, \n",
            "Epoch 3273/6000: train_loss=9.3123, val_loss=12.6545, \n",
            "Epoch 3274/6000: train_loss=9.1227, val_loss=9.9381, \n",
            "Epoch 3275/6000: train_loss=9.2239, val_loss=12.4595, \n",
            "Epoch 3276/6000: train_loss=9.4293, val_loss=11.6958, \n",
            "Epoch 3277/6000: train_loss=8.9496, val_loss=12.8327, \n",
            "Epoch 3278/6000: train_loss=8.5355, val_loss=10.6135, \n",
            "Epoch 3279/6000: train_loss=8.6701, val_loss=11.2451, \n",
            "Epoch 3280/6000: train_loss=8.6080, val_loss=10.5276, \n",
            "Epoch 3281/6000: train_loss=8.5190, val_loss=11.0104, \n",
            "Epoch 3282/6000: train_loss=8.9242, val_loss=12.8202, \n",
            "Epoch 3283/6000: train_loss=8.9498, val_loss=10.5908, \n",
            "Epoch 3284/6000: train_loss=9.1247, val_loss=12.0332, \n",
            "Epoch 3285/6000: train_loss=9.4642, val_loss=11.0541, \n",
            "Epoch 3286/6000: train_loss=9.5244, val_loss=13.9295, \n",
            "Epoch 3287/6000: train_loss=8.5818, val_loss=10.8607, \n",
            "Epoch 3288/6000: train_loss=8.8783, val_loss=11.5532, \n",
            "Epoch 3289/6000: train_loss=8.4754, val_loss=10.9512, \n",
            "Epoch 3290/6000: train_loss=8.6028, val_loss=11.1392, \n",
            "Epoch 3291/6000: train_loss=8.4822, val_loss=11.7453, \n",
            "Epoch 3292/6000: train_loss=8.5950, val_loss=10.5991, \n",
            "Epoch 3293/6000: train_loss=8.4874, val_loss=10.5988, \n",
            "Epoch 3294/6000: train_loss=8.4964, val_loss=11.1167, \n",
            "Epoch 3295/6000: train_loss=8.5619, val_loss=10.8935, \n",
            "Epoch 3296/6000: train_loss=8.6781, val_loss=12.0047, \n",
            "Epoch 3297/6000: train_loss=9.0737, val_loss=10.6234, \n",
            "Epoch 3298/6000: train_loss=8.6967, val_loss=11.8449, \n",
            "Epoch 3299/6000: train_loss=8.7517, val_loss=10.7512, \n",
            "Epoch 3300/6000: train_loss=8.5605, val_loss=11.6548, \n",
            "Epoch 3301/6000: train_loss=8.4319, val_loss=11.0401, \n",
            "Epoch 3302/6000: train_loss=8.4686, val_loss=10.7941, \n",
            "Epoch 3303/6000: train_loss=8.7201, val_loss=12.0002, \n",
            "Epoch 3304/6000: train_loss=9.1620, val_loss=10.8722, \n",
            "Epoch 3305/6000: train_loss=10.1888, val_loss=14.5379, \n",
            "Epoch 3306/6000: train_loss=9.3569, val_loss=10.7977, \n",
            "Epoch 3307/6000: train_loss=8.7153, val_loss=11.6185, \n",
            "Epoch 3308/6000: train_loss=8.4260, val_loss=10.6867, \n",
            "Epoch 3309/6000: train_loss=8.4574, val_loss=10.5209, \n",
            "Epoch 3310/6000: train_loss=8.4453, val_loss=11.2206, \n",
            "Epoch 3311/6000: train_loss=8.3948, val_loss=11.0765, \n",
            "Epoch 3312/6000: train_loss=8.4020, val_loss=11.1489, \n",
            "Epoch 3313/6000: train_loss=8.6649, val_loss=10.7553, \n",
            "Epoch 3314/6000: train_loss=8.8428, val_loss=12.4091, \n",
            "Epoch 3315/6000: train_loss=8.5198, val_loss=10.8523, \n",
            "Epoch 3316/6000: train_loss=8.5094, val_loss=11.3701, \n",
            "Epoch 3317/6000: train_loss=8.3983, val_loss=10.5446, \n",
            "Epoch 3318/6000: train_loss=8.4028, val_loss=11.1765, \n",
            "Epoch 3319/6000: train_loss=8.9012, val_loss=10.8301, \n",
            "Epoch 3320/6000: train_loss=8.5286, val_loss=11.4949, \n",
            "Epoch 3321/6000: train_loss=8.3788, val_loss=10.8226, \n",
            "Epoch 3322/6000: train_loss=8.9648, val_loss=10.5112, \n",
            "Epoch 3323/6000: train_loss=9.2938, val_loss=13.0701, \n",
            "Epoch 3324/6000: train_loss=9.6650, val_loss=10.7627, \n",
            "Epoch 3325/6000: train_loss=9.5744, val_loss=13.1768, \n",
            "Epoch 3326/6000: train_loss=8.8362, val_loss=10.7685, \n",
            "Epoch 3327/6000: train_loss=8.6761, val_loss=12.0845, \n",
            "Epoch 3328/6000: train_loss=8.4439, val_loss=10.6640, \n",
            "Epoch 3329/6000: train_loss=8.3613, val_loss=10.7928, \n",
            "Epoch 3330/6000: train_loss=8.8954, val_loss=12.1552, \n",
            "Epoch 3331/6000: train_loss=8.5281, val_loss=10.7436, \n",
            "Epoch 3332/6000: train_loss=9.1638, val_loss=12.8789, \n",
            "Epoch 3333/6000: train_loss=9.5939, val_loss=10.7317, \n",
            "Epoch 3334/6000: train_loss=9.2287, val_loss=12.7412, \n",
            "Epoch 3335/6000: train_loss=8.6113, val_loss=10.7208, \n",
            "Epoch 3336/6000: train_loss=8.3895, val_loss=10.8103, \n",
            "Epoch 3337/6000: train_loss=8.3688, val_loss=10.7299, \n",
            "Epoch 3338/6000: train_loss=8.6465, val_loss=11.5661, \n",
            "Epoch 3339/6000: train_loss=8.7055, val_loss=10.6163, \n",
            "Epoch 3340/6000: train_loss=8.3692, val_loss=11.2602, \n",
            "Epoch 3341/6000: train_loss=8.4673, val_loss=11.3722, \n",
            "Epoch 3342/6000: train_loss=8.7307, val_loss=10.4196, \n",
            "Epoch 3343/6000: train_loss=8.6244, val_loss=11.7797, \n",
            "Epoch 3344/6000: train_loss=8.8127, val_loss=10.5910, \n",
            "Epoch 3345/6000: train_loss=8.4932, val_loss=11.4366, \n",
            "Epoch 3346/6000: train_loss=8.5244, val_loss=10.6620, \n",
            "Epoch 3347/6000: train_loss=8.5986, val_loss=11.7969, \n",
            "Epoch 3348/6000: train_loss=8.4650, val_loss=10.3755, \n",
            "Epoch 3349/6000: train_loss=8.4168, val_loss=11.0978, \n",
            "Epoch 3350/6000: train_loss=8.4774, val_loss=11.6104, \n",
            "Epoch 3351/6000: train_loss=8.7894, val_loss=11.0078, \n",
            "Epoch 3352/6000: train_loss=8.9226, val_loss=12.4256, \n",
            "Epoch 3353/6000: train_loss=9.5680, val_loss=10.5079, \n",
            "Epoch 3354/6000: train_loss=9.6833, val_loss=13.4170, \n",
            "Epoch 3355/6000: train_loss=9.0941, val_loss=10.8262, \n",
            "Epoch 3356/6000: train_loss=8.7342, val_loss=11.8579, \n",
            "Epoch 3357/6000: train_loss=8.6623, val_loss=10.4140, \n",
            "Epoch 3358/6000: train_loss=8.3616, val_loss=11.2771, \n",
            "Epoch 3359/6000: train_loss=8.3302, val_loss=11.0653, \n",
            "Epoch 3360/6000: train_loss=8.7662, val_loss=10.5153, \n",
            "Epoch 3361/6000: train_loss=9.2596, val_loss=12.7053, \n",
            "Epoch 3362/6000: train_loss=9.1748, val_loss=10.1403, \n",
            "Epoch 3363/6000: train_loss=9.2070, val_loss=12.2731, \n",
            "Epoch 3364/6000: train_loss=9.0569, val_loss=10.6011, \n",
            "Epoch 3365/6000: train_loss=8.8748, val_loss=12.4183, \n",
            "Epoch 3366/6000: train_loss=8.3798, val_loss=10.6700, \n",
            "Epoch 3367/6000: train_loss=8.3505, val_loss=10.8545, \n",
            "Epoch 3368/6000: train_loss=8.5049, val_loss=11.5361, \n",
            "Epoch 3369/6000: train_loss=8.4993, val_loss=10.7873, \n",
            "Epoch 3370/6000: train_loss=8.6158, val_loss=11.7574, \n",
            "Epoch 3371/6000: train_loss=8.4509, val_loss=10.7662, \n",
            "Epoch 3372/6000: train_loss=8.3210, val_loss=11.2582, \n",
            "Epoch 3373/6000: train_loss=8.3836, val_loss=11.2739, \n",
            "Epoch 3374/6000: train_loss=8.3045, val_loss=10.7002, \n",
            "Epoch 3375/6000: train_loss=8.3051, val_loss=10.5460, \n",
            "Epoch 3376/6000: train_loss=8.3121, val_loss=10.9468, \n",
            "Epoch 3377/6000: train_loss=8.4940, val_loss=11.6728, \n",
            "Epoch 3378/6000: train_loss=8.2855, val_loss=10.7518, \n",
            "Epoch 3379/6000: train_loss=8.3282, val_loss=10.5544, \n",
            "Epoch 3380/6000: train_loss=8.5049, val_loss=11.5424, \n",
            "Epoch 3381/6000: train_loss=8.3270, val_loss=10.6288, \n",
            "Epoch 3382/6000: train_loss=8.3085, val_loss=11.0843, \n",
            "Epoch 3383/6000: train_loss=8.3113, val_loss=11.0799, \n",
            "Epoch 3384/6000: train_loss=8.4214, val_loss=10.4113, \n",
            "Epoch 3385/6000: train_loss=8.4988, val_loss=11.4746, \n",
            "Epoch 3386/6000: train_loss=8.3001, val_loss=10.6367, \n",
            "Epoch 3387/6000: train_loss=8.2693, val_loss=10.7115, \n",
            "Epoch 3388/6000: train_loss=8.2877, val_loss=10.6655, \n",
            "Epoch 3389/6000: train_loss=8.4063, val_loss=11.2128, \n",
            "Epoch 3390/6000: train_loss=8.2892, val_loss=10.5869, \n",
            "Epoch 3391/6000: train_loss=8.3213, val_loss=11.4372, \n",
            "Epoch 3392/6000: train_loss=8.3384, val_loss=11.5487, \n",
            "Epoch 3393/6000: train_loss=8.3833, val_loss=10.2969, \n",
            "Epoch 3394/6000: train_loss=8.3130, val_loss=10.3469, \n",
            "Epoch 3395/6000: train_loss=8.3008, val_loss=10.7510, \n",
            "Epoch 3396/6000: train_loss=8.3671, val_loss=11.3304, \n",
            "Epoch 3397/6000: train_loss=8.4058, val_loss=10.6298, \n",
            "Epoch 3398/6000: train_loss=8.3831, val_loss=11.4057, \n",
            "Epoch 3399/6000: train_loss=8.2643, val_loss=11.0649, \n",
            "Epoch 3400/6000: train_loss=8.6164, val_loss=11.9313, \n",
            "Epoch 3401/6000: train_loss=9.0105, val_loss=10.3315, \n",
            "Epoch 3402/6000: train_loss=8.8939, val_loss=12.1419, \n",
            "Epoch 3403/6000: train_loss=8.7540, val_loss=10.4613, \n",
            "Epoch 3404/6000: train_loss=8.3252, val_loss=11.1296, \n",
            "Epoch 3405/6000: train_loss=8.2989, val_loss=11.1409, \n",
            "Epoch 3406/6000: train_loss=8.2883, val_loss=10.5602, \n",
            "Epoch 3407/6000: train_loss=8.4900, val_loss=11.3454, \n",
            "Epoch 3408/6000: train_loss=8.4152, val_loss=10.3533, \n",
            "Epoch 3409/6000: train_loss=8.3505, val_loss=11.4624, \n",
            "Epoch 3410/6000: train_loss=8.8075, val_loss=11.1623, \n",
            "Epoch 3411/6000: train_loss=8.3339, val_loss=11.1219, \n",
            "Epoch 3412/6000: train_loss=8.3482, val_loss=9.9410, \n",
            "Epoch 3413/6000: train_loss=8.3609, val_loss=10.8331, \n",
            "Epoch 3414/6000: train_loss=8.3103, val_loss=11.1520, \n",
            "Epoch 3415/6000: train_loss=8.4116, val_loss=11.0205, \n",
            "Epoch 3416/6000: train_loss=8.2687, val_loss=10.7705, \n",
            "Epoch 3417/6000: train_loss=8.2697, val_loss=10.2747, \n",
            "Epoch 3418/6000: train_loss=8.2923, val_loss=10.8374, \n",
            "Epoch 3419/6000: train_loss=8.3709, val_loss=11.3729, \n",
            "Epoch 3420/6000: train_loss=8.3016, val_loss=10.5280, \n",
            "Epoch 3421/6000: train_loss=8.9449, val_loss=11.8526, \n",
            "Epoch 3422/6000: train_loss=9.3535, val_loss=10.3841, \n",
            "Epoch 3423/6000: train_loss=9.1231, val_loss=13.0540, \n",
            "Epoch 3424/6000: train_loss=8.5523, val_loss=10.7668, \n",
            "Epoch 3425/6000: train_loss=8.5102, val_loss=11.0714, \n",
            "Epoch 3426/6000: train_loss=8.3332, val_loss=10.0405, \n",
            "Epoch 3427/6000: train_loss=8.2589, val_loss=10.8287, \n",
            "Epoch 3428/6000: train_loss=8.2718, val_loss=11.3131, \n",
            "Epoch 3429/6000: train_loss=8.2475, val_loss=10.5377, \n",
            "Epoch 3430/6000: train_loss=8.4723, val_loss=10.8713, \n",
            "Epoch 3431/6000: train_loss=8.2341, val_loss=10.6382, \n",
            "Epoch 3432/6000: train_loss=8.2913, val_loss=11.5512, \n",
            "Epoch 3433/6000: train_loss=8.2549, val_loss=11.0244, \n",
            "Epoch 3434/6000: train_loss=8.2549, val_loss=10.3187, \n",
            "Epoch 3435/6000: train_loss=8.2178, val_loss=10.3907, \n",
            "Epoch 3436/6000: train_loss=8.3356, val_loss=11.3461, \n",
            "Epoch 3437/6000: train_loss=8.2179, val_loss=10.8958, \n",
            "Epoch 3438/6000: train_loss=8.3364, val_loss=11.1343, \n",
            "Epoch 3439/6000: train_loss=8.1950, val_loss=10.7028, \n",
            "Epoch 3440/6000: train_loss=8.2646, val_loss=10.5901, \n",
            "Epoch 3441/6000: train_loss=8.5328, val_loss=11.9241, \n",
            "Epoch 3442/6000: train_loss=8.7275, val_loss=10.2920, \n",
            "Epoch 3443/6000: train_loss=8.5291, val_loss=11.1361, \n",
            "Epoch 3444/6000: train_loss=8.3690, val_loss=9.9513, \n",
            "Epoch 3445/6000: train_loss=8.2419, val_loss=11.2718, \n",
            "Epoch 3446/6000: train_loss=8.3618, val_loss=11.8302, \n",
            "Epoch 3447/6000: train_loss=8.2337, val_loss=10.1669, \n",
            "Epoch 3448/6000: train_loss=8.3465, val_loss=10.2820, \n",
            "Epoch 3449/6000: train_loss=8.2325, val_loss=10.6290, \n",
            "Epoch 3450/6000: train_loss=8.3245, val_loss=11.8147, \n",
            "Epoch 3451/6000: train_loss=8.4010, val_loss=10.7077, \n",
            "Epoch 3452/6000: train_loss=8.5276, val_loss=11.0873, \n",
            "Epoch 3453/6000: train_loss=8.3508, val_loss=9.8753, \n",
            "Epoch 3454/6000: train_loss=8.2048, val_loss=10.7760, \n",
            "Epoch 3455/6000: train_loss=8.2943, val_loss=11.4878, \n",
            "Epoch 3456/6000: train_loss=8.3733, val_loss=10.3375, \n",
            "Epoch 3457/6000: train_loss=8.2495, val_loss=10.8173, \n",
            "Epoch 3458/6000: train_loss=8.2041, val_loss=11.1113, \n",
            "Epoch 3459/6000: train_loss=8.2204, val_loss=11.2655, \n",
            "Epoch 3460/6000: train_loss=8.1878, val_loss=10.8330, \n",
            "Epoch 3461/6000: train_loss=8.3801, val_loss=10.5727, \n",
            "Epoch 3462/6000: train_loss=8.3424, val_loss=10.3105, \n",
            "Epoch 3463/6000: train_loss=8.9977, val_loss=12.8608, \n",
            "Epoch 3464/6000: train_loss=9.1056, val_loss=10.4574, \n",
            "Epoch 3465/6000: train_loss=8.7780, val_loss=11.5199, \n",
            "Epoch 3466/6000: train_loss=8.4904, val_loss=10.0937, \n",
            "Epoch 3467/6000: train_loss=8.4128, val_loss=11.7562, \n",
            "Epoch 3468/6000: train_loss=8.1965, val_loss=10.6130, \n",
            "Epoch 3469/6000: train_loss=8.1833, val_loss=10.7289, \n",
            "Epoch 3470/6000: train_loss=8.3504, val_loss=10.3156, \n",
            "Epoch 3471/6000: train_loss=8.2006, val_loss=11.1318, \n",
            "Epoch 3472/6000: train_loss=8.1805, val_loss=10.8479, \n",
            "Epoch 3473/6000: train_loss=8.2951, val_loss=9.9946, \n",
            "Epoch 3474/6000: train_loss=8.1914, val_loss=10.3165, \n",
            "Epoch 3475/6000: train_loss=8.3322, val_loss=10.4151, \n",
            "Epoch 3476/6000: train_loss=8.2191, val_loss=11.5582, \n",
            "Epoch 3477/6000: train_loss=8.1457, val_loss=10.9238, \n",
            "Epoch 3478/6000: train_loss=8.1887, val_loss=10.7259, \n",
            "Epoch 3479/6000: train_loss=8.2169, val_loss=10.2223, \n",
            "Epoch 3480/6000: train_loss=8.1748, val_loss=10.8822, \n",
            "Epoch 3481/6000: train_loss=8.1781, val_loss=10.6821, \n",
            "Epoch 3482/6000: train_loss=8.3696, val_loss=11.3878, \n",
            "Epoch 3483/6000: train_loss=8.1600, val_loss=10.4685, \n",
            "Epoch 3484/6000: train_loss=8.1353, val_loss=10.5152, \n",
            "Epoch 3485/6000: train_loss=8.1289, val_loss=10.7805, \n",
            "Epoch 3486/6000: train_loss=8.3447, val_loss=11.3157, \n",
            "Epoch 3487/6000: train_loss=8.4803, val_loss=10.0172, \n",
            "Epoch 3488/6000: train_loss=8.9894, val_loss=12.4378, \n",
            "Epoch 3489/6000: train_loss=9.2569, val_loss=10.6189, \n",
            "Epoch 3490/6000: train_loss=8.6536, val_loss=11.9043, \n",
            "Epoch 3491/6000: train_loss=8.1901, val_loss=10.6092, \n",
            "Epoch 3492/6000: train_loss=8.1442, val_loss=10.7975, \n",
            "Epoch 3493/6000: train_loss=8.2254, val_loss=11.0323, \n",
            "Epoch 3494/6000: train_loss=8.3804, val_loss=10.1608, \n",
            "Epoch 3495/6000: train_loss=9.0818, val_loss=12.6888, \n",
            "Epoch 3496/6000: train_loss=9.5864, val_loss=10.4427, \n",
            "Epoch 3497/6000: train_loss=9.7786, val_loss=13.2702, \n",
            "Epoch 3498/6000: train_loss=9.4519, val_loss=10.5461, \n",
            "Epoch 3499/6000: train_loss=9.2353, val_loss=13.2789, \n",
            "Epoch 3500/6000: train_loss=9.0261, val_loss=10.6900, \n",
            "Epoch 3501/6000: train_loss=8.9876, val_loss=11.9107, \n",
            "Epoch 3502/6000: train_loss=8.2229, val_loss=9.9588, \n",
            "Epoch 3503/6000: train_loss=8.1930, val_loss=11.3055, \n",
            "Epoch 3504/6000: train_loss=8.1387, val_loss=11.1983, \n",
            "Epoch 3505/6000: train_loss=8.1531, val_loss=10.2144, \n",
            "Epoch 3506/6000: train_loss=8.7796, val_loss=11.3984, \n",
            "Epoch 3507/6000: train_loss=9.9826, val_loss=10.4112, \n",
            "Epoch 3508/6000: train_loss=9.9987, val_loss=14.3437, \n",
            "Epoch 3509/6000: train_loss=10.4290, val_loss=11.1755, \n",
            "Epoch 3510/6000: train_loss=9.8389, val_loss=13.1855, \n",
            "Epoch 3511/6000: train_loss=8.4561, val_loss=10.1000, \n",
            "Epoch 3512/6000: train_loss=8.3733, val_loss=11.9144, \n",
            "Epoch 3513/6000: train_loss=8.1260, val_loss=10.9701, \n",
            "Epoch 3514/6000: train_loss=8.3307, val_loss=9.9264, \n",
            "Epoch 3515/6000: train_loss=8.3954, val_loss=10.9580, \n",
            "Epoch 3516/6000: train_loss=8.1625, val_loss=10.5228, \n",
            "Epoch 3517/6000: train_loss=8.1671, val_loss=11.1935, \n",
            "Epoch 3518/6000: train_loss=8.3743, val_loss=10.1759, \n",
            "Epoch 3519/6000: train_loss=8.3122, val_loss=11.2634, \n",
            "Epoch 3520/6000: train_loss=8.9781, val_loss=10.5768, \n",
            "Epoch 3521/6000: train_loss=8.4599, val_loss=11.7049, \n",
            "Epoch 3522/6000: train_loss=8.2010, val_loss=10.2508, \n",
            "Epoch 3523/6000: train_loss=8.0795, val_loss=10.5446, \n",
            "Epoch 3524/6000: train_loss=8.4387, val_loss=11.3366, \n",
            "Epoch 3525/6000: train_loss=8.4441, val_loss=9.9868, \n",
            "Epoch 3526/6000: train_loss=8.3098, val_loss=11.2943, \n",
            "Epoch 3527/6000: train_loss=8.6928, val_loss=10.4658, \n",
            "Epoch 3528/6000: train_loss=8.1086, val_loss=10.9010, \n",
            "Epoch 3529/6000: train_loss=8.0645, val_loss=10.5298, \n",
            "Epoch 3530/6000: train_loss=8.0588, val_loss=10.3111, \n",
            "Epoch 3531/6000: train_loss=8.0680, val_loss=10.3674, \n",
            "Epoch 3532/6000: train_loss=8.0937, val_loss=10.3616, \n",
            "Epoch 3533/6000: train_loss=8.1714, val_loss=11.1154, \n",
            "Epoch 3534/6000: train_loss=8.0880, val_loss=10.5487, \n",
            "Epoch 3535/6000: train_loss=8.2740, val_loss=10.0040, \n",
            "Epoch 3536/6000: train_loss=8.0521, val_loss=10.5385, \n",
            "Epoch 3537/6000: train_loss=8.3400, val_loss=11.5115, \n",
            "Epoch 3538/6000: train_loss=8.2454, val_loss=10.0349, \n",
            "Epoch 3539/6000: train_loss=8.0903, val_loss=10.6435, \n",
            "Epoch 3540/6000: train_loss=8.0501, val_loss=10.7551, \n",
            "Epoch 3541/6000: train_loss=8.2475, val_loss=11.4273, \n",
            "Epoch 3542/6000: train_loss=8.0494, val_loss=10.2675, \n",
            "Epoch 3543/6000: train_loss=8.1642, val_loss=10.5444, \n",
            "Epoch 3544/6000: train_loss=8.0618, val_loss=10.5569, \n",
            "Epoch 3545/6000: train_loss=8.0941, val_loss=10.9799, \n",
            "Epoch 3546/6000: train_loss=8.0660, val_loss=11.0750, \n",
            "Epoch 3547/6000: train_loss=8.4147, val_loss=9.9965, \n",
            "Epoch 3548/6000: train_loss=8.0648, val_loss=10.1921, \n",
            "Epoch 3549/6000: train_loss=8.1037, val_loss=10.5244, \n",
            "Epoch 3550/6000: train_loss=8.0559, val_loss=10.5685, \n",
            "Epoch 3551/6000: train_loss=8.0284, val_loss=10.4972, \n",
            "Epoch 3552/6000: train_loss=8.1995, val_loss=10.9665, \n",
            "Epoch 3553/6000: train_loss=8.0719, val_loss=10.4899, \n",
            "Epoch 3554/6000: train_loss=8.1274, val_loss=10.4426, \n",
            "Epoch 3555/6000: train_loss=8.0654, val_loss=10.4443, \n",
            "Epoch 3556/6000: train_loss=8.0460, val_loss=10.0831, \n",
            "Epoch 3557/6000: train_loss=8.0205, val_loss=10.5174, \n",
            "Epoch 3558/6000: train_loss=8.0318, val_loss=10.6607, \n",
            "Epoch 3559/6000: train_loss=8.0420, val_loss=10.5887, \n",
            "Epoch 3560/6000: train_loss=8.7629, val_loss=10.1969, \n",
            "Epoch 3561/6000: train_loss=8.2057, val_loss=11.2693, \n",
            "Epoch 3562/6000: train_loss=8.2538, val_loss=10.4126, \n",
            "Epoch 3563/6000: train_loss=8.0200, val_loss=10.2454, \n",
            "Epoch 3564/6000: train_loss=8.0565, val_loss=10.1938, \n",
            "Epoch 3565/6000: train_loss=8.7259, val_loss=10.3561, \n",
            "Epoch 3566/6000: train_loss=9.2025, val_loss=13.1785, \n",
            "Epoch 3567/6000: train_loss=8.4015, val_loss=10.0858, \n",
            "Epoch 3568/6000: train_loss=8.6249, val_loss=11.4337, \n",
            "Epoch 3569/6000: train_loss=8.1773, val_loss=10.2870, \n",
            "Epoch 3570/6000: train_loss=8.0001, val_loss=10.7474, \n",
            "Epoch 3571/6000: train_loss=8.0142, val_loss=10.4706, \n",
            "Epoch 3572/6000: train_loss=9.0757, val_loss=9.8034, \n",
            "Epoch 3573/6000: train_loss=10.4771, val_loss=14.3936, \n",
            "Epoch 3574/6000: train_loss=8.7338, val_loss=10.4729, \n",
            "Epoch 3575/6000: train_loss=8.2010, val_loss=11.3383, \n",
            "Epoch 3576/6000: train_loss=8.0350, val_loss=10.5349, \n",
            "Epoch 3577/6000: train_loss=8.1293, val_loss=10.0628, \n",
            "Epoch 3578/6000: train_loss=8.0816, val_loss=10.5823, \n",
            "Epoch 3579/6000: train_loss=8.5933, val_loss=9.9472, \n",
            "Epoch 3580/6000: train_loss=8.2049, val_loss=10.8918, \n",
            "Epoch 3581/6000: train_loss=8.0381, val_loss=10.2978, \n",
            "Epoch 3582/6000: train_loss=8.0437, val_loss=10.5837, \n",
            "Epoch 3583/6000: train_loss=8.7011, val_loss=12.3276, \n",
            "Epoch 3584/6000: train_loss=8.6730, val_loss=10.0800, \n",
            "Epoch 3585/6000: train_loss=8.9142, val_loss=12.2080, \n",
            "Epoch 3586/6000: train_loss=8.1822, val_loss=9.9593, \n",
            "Epoch 3587/6000: train_loss=8.1691, val_loss=11.3222, \n",
            "Epoch 3588/6000: train_loss=8.1531, val_loss=10.3692, \n",
            "Epoch 3589/6000: train_loss=7.9943, val_loss=10.4285, \n",
            "Epoch 3590/6000: train_loss=7.9757, val_loss=10.2311, \n",
            "Epoch 3591/6000: train_loss=7.9769, val_loss=10.4475, \n",
            "Epoch 3592/6000: train_loss=7.9921, val_loss=10.5356, \n",
            "Epoch 3593/6000: train_loss=8.0153, val_loss=10.0749, \n",
            "Epoch 3594/6000: train_loss=8.0739, val_loss=10.9573, \n",
            "Epoch 3595/6000: train_loss=7.9954, val_loss=10.2098, \n",
            "Epoch 3596/6000: train_loss=8.0244, val_loss=10.6275, \n",
            "Epoch 3597/6000: train_loss=7.9876, val_loss=10.4788, \n",
            "Epoch 3598/6000: train_loss=7.9625, val_loss=10.6130, \n",
            "Epoch 3599/6000: train_loss=7.9651, val_loss=10.3730, \n",
            "Epoch 3600/6000: train_loss=7.9728, val_loss=10.5897, \n",
            "Epoch 3601/6000: train_loss=7.9512, val_loss=10.4274, \n",
            "Epoch 3602/6000: train_loss=7.9608, val_loss=10.4234, \n",
            "Epoch 3603/6000: train_loss=7.9558, val_loss=10.4943, \n",
            "Epoch 3604/6000: train_loss=7.9683, val_loss=10.2882, \n",
            "Epoch 3605/6000: train_loss=8.3112, val_loss=11.3314, \n",
            "Epoch 3606/6000: train_loss=8.0014, val_loss=10.1658, \n",
            "Epoch 3607/6000: train_loss=7.9627, val_loss=10.4562, \n",
            "Epoch 3608/6000: train_loss=8.1789, val_loss=10.9950, \n",
            "Epoch 3609/6000: train_loss=8.6069, val_loss=9.9123, \n",
            "Epoch 3610/6000: train_loss=8.0760, val_loss=11.0602, \n",
            "Epoch 3611/6000: train_loss=8.1591, val_loss=10.5271, \n",
            "Epoch 3612/6000: train_loss=8.9063, val_loss=12.1834, \n",
            "Epoch 3613/6000: train_loss=8.5919, val_loss=9.5441, \n",
            "Epoch 3614/6000: train_loss=8.2262, val_loss=10.9932, \n",
            "Epoch 3615/6000: train_loss=8.1519, val_loss=10.5386, \n",
            "Epoch 3616/6000: train_loss=8.1194, val_loss=11.1256, \n",
            "Epoch 3617/6000: train_loss=8.0030, val_loss=9.8642, \n",
            "Epoch 3618/6000: train_loss=8.2117, val_loss=11.0458, \n",
            "Epoch 3619/6000: train_loss=8.3449, val_loss=10.2927, \n",
            "Epoch 3620/6000: train_loss=8.2717, val_loss=11.5572, \n",
            "Epoch 3621/6000: train_loss=7.9673, val_loss=10.1087, \n",
            "Epoch 3622/6000: train_loss=8.0223, val_loss=9.7607, \n",
            "Epoch 3623/6000: train_loss=8.6822, val_loss=12.0687, \n",
            "Epoch 3624/6000: train_loss=8.7138, val_loss=10.3006, \n",
            "Epoch 3625/6000: train_loss=8.8183, val_loss=11.9703, \n",
            "Epoch 3626/6000: train_loss=8.6283, val_loss=9.7398, \n",
            "Epoch 3627/6000: train_loss=8.3019, val_loss=11.6951, \n",
            "Epoch 3628/6000: train_loss=8.2082, val_loss=10.9174, \n",
            "Epoch 3629/6000: train_loss=7.9407, val_loss=10.5598, \n",
            "Epoch 3630/6000: train_loss=7.9732, val_loss=9.7259, \n",
            "Epoch 3631/6000: train_loss=8.0163, val_loss=9.7508, \n",
            "Epoch 3632/6000: train_loss=8.0426, val_loss=10.5755, \n",
            "Epoch 3633/6000: train_loss=7.9461, val_loss=10.6198, \n",
            "Epoch 3634/6000: train_loss=8.0413, val_loss=9.7651, \n",
            "Epoch 3635/6000: train_loss=8.0548, val_loss=10.8454, \n",
            "Epoch 3636/6000: train_loss=7.9650, val_loss=10.7664, \n",
            "Epoch 3637/6000: train_loss=7.9266, val_loss=10.4432, \n",
            "Epoch 3638/6000: train_loss=7.9600, val_loss=10.1252, \n",
            "Epoch 3639/6000: train_loss=7.9433, val_loss=10.0137, \n",
            "Epoch 3640/6000: train_loss=8.0913, val_loss=10.3505, \n",
            "Epoch 3641/6000: train_loss=8.0786, val_loss=11.1731, \n",
            "Epoch 3642/6000: train_loss=8.1549, val_loss=9.6352, \n",
            "Epoch 3643/6000: train_loss=8.5065, val_loss=11.1088, \n",
            "Epoch 3644/6000: train_loss=8.1923, val_loss=9.9955, \n",
            "Epoch 3645/6000: train_loss=8.2630, val_loss=11.6082, \n",
            "Epoch 3646/6000: train_loss=8.2151, val_loss=10.2794, \n",
            "Epoch 3647/6000: train_loss=7.8897, val_loss=10.4296, \n",
            "Epoch 3648/6000: train_loss=7.9093, val_loss=10.0292, \n",
            "Epoch 3649/6000: train_loss=8.0508, val_loss=9.6994, \n",
            "Epoch 3650/6000: train_loss=8.2093, val_loss=10.9783, \n",
            "Epoch 3651/6000: train_loss=8.1129, val_loss=10.0791, \n",
            "Epoch 3652/6000: train_loss=7.8935, val_loss=10.3474, \n",
            "Epoch 3653/6000: train_loss=8.0048, val_loss=10.7002, \n",
            "Epoch 3654/6000: train_loss=7.9425, val_loss=9.9681, \n",
            "Epoch 3655/6000: train_loss=7.9057, val_loss=10.4787, \n",
            "Epoch 3656/6000: train_loss=7.9043, val_loss=10.2047, \n",
            "Epoch 3657/6000: train_loss=7.8923, val_loss=10.4489, \n",
            "Epoch 3658/6000: train_loss=7.8746, val_loss=10.4227, \n",
            "Epoch 3659/6000: train_loss=8.0616, val_loss=10.7356, \n",
            "Epoch 3660/6000: train_loss=7.9042, val_loss=9.9748, \n",
            "Epoch 3661/6000: train_loss=7.8757, val_loss=10.3272, \n",
            "Epoch 3662/6000: train_loss=7.9023, val_loss=10.6431, \n",
            "Epoch 3663/6000: train_loss=7.8995, val_loss=10.5903, \n",
            "Epoch 3664/6000: train_loss=7.8785, val_loss=10.0951, \n",
            "Epoch 3665/6000: train_loss=7.9300, val_loss=9.7655, \n",
            "Epoch 3666/6000: train_loss=7.8808, val_loss=10.0680, \n",
            "Epoch 3667/6000: train_loss=7.8933, val_loss=10.4584, \n",
            "Epoch 3668/6000: train_loss=8.1709, val_loss=9.9844, \n",
            "Epoch 3669/6000: train_loss=8.0295, val_loss=11.0752, \n",
            "Epoch 3670/6000: train_loss=7.8776, val_loss=9.9885, \n",
            "Epoch 3671/6000: train_loss=7.9905, val_loss=9.6362, \n",
            "Epoch 3672/6000: train_loss=7.9073, val_loss=10.6071, \n",
            "Epoch 3673/6000: train_loss=7.9507, val_loss=10.3436, \n",
            "Epoch 3674/6000: train_loss=7.9393, val_loss=10.6965, \n",
            "Epoch 3675/6000: train_loss=7.9822, val_loss=9.9813, \n",
            "Epoch 3676/6000: train_loss=8.1760, val_loss=11.0681, \n",
            "Epoch 3677/6000: train_loss=8.7913, val_loss=10.1239, \n",
            "Epoch 3678/6000: train_loss=9.4320, val_loss=13.1995, \n",
            "Epoch 3679/6000: train_loss=8.3510, val_loss=9.9215, \n",
            "Epoch 3680/6000: train_loss=7.9829, val_loss=10.5526, \n",
            "Epoch 3681/6000: train_loss=7.8668, val_loss=10.1869, \n",
            "Epoch 3682/6000: train_loss=7.8606, val_loss=10.2449, \n",
            "Epoch 3683/6000: train_loss=7.8632, val_loss=10.0247, \n",
            "Epoch 3684/6000: train_loss=7.8501, val_loss=10.0533, \n",
            "Epoch 3685/6000: train_loss=8.0299, val_loss=10.6716, \n",
            "Epoch 3686/6000: train_loss=8.1883, val_loss=9.7454, \n",
            "Epoch 3687/6000: train_loss=8.0177, val_loss=10.7321, \n",
            "Epoch 3688/6000: train_loss=8.1664, val_loss=10.2447, \n",
            "Epoch 3689/6000: train_loss=8.1291, val_loss=11.0887, \n",
            "Epoch 3690/6000: train_loss=8.0855, val_loss=9.4437, \n",
            "Epoch 3691/6000: train_loss=7.9218, val_loss=10.3458, \n",
            "Epoch 3692/6000: train_loss=7.9730, val_loss=10.8006, \n",
            "Epoch 3693/6000: train_loss=7.8989, val_loss=11.0124, \n",
            "Epoch 3694/6000: train_loss=7.8733, val_loss=9.8221, \n",
            "Epoch 3695/6000: train_loss=7.9091, val_loss=9.5833, \n",
            "Epoch 3696/6000: train_loss=7.8874, val_loss=10.5089, \n",
            "Epoch 3697/6000: train_loss=7.9852, val_loss=9.9814, \n",
            "Epoch 3698/6000: train_loss=7.9665, val_loss=10.6672, \n",
            "Epoch 3699/6000: train_loss=7.9437, val_loss=9.9410, \n",
            "Epoch 3700/6000: train_loss=7.8366, val_loss=10.5677, \n",
            "Epoch 3701/6000: train_loss=8.0811, val_loss=11.2221, \n",
            "Epoch 3702/6000: train_loss=8.2323, val_loss=9.6532, \n",
            "Epoch 3703/6000: train_loss=8.5484, val_loss=11.4321, \n",
            "Epoch 3704/6000: train_loss=8.5572, val_loss=9.9806, \n",
            "Epoch 3705/6000: train_loss=8.0862, val_loss=11.2938, \n",
            "Epoch 3706/6000: train_loss=7.8802, val_loss=10.0596, \n",
            "Epoch 3707/6000: train_loss=7.8209, val_loss=9.8557, \n",
            "Epoch 3708/6000: train_loss=7.8522, val_loss=10.1959, \n",
            "Epoch 3709/6000: train_loss=7.9264, val_loss=10.1376, \n",
            "Epoch 3710/6000: train_loss=8.4396, val_loss=11.8011, \n",
            "Epoch 3711/6000: train_loss=8.4686, val_loss=9.6761, \n",
            "Epoch 3712/6000: train_loss=8.4082, val_loss=11.4228, \n",
            "Epoch 3713/6000: train_loss=7.9546, val_loss=10.2523, \n",
            "Epoch 3714/6000: train_loss=7.9375, val_loss=10.9760, \n",
            "Epoch 3715/6000: train_loss=7.8450, val_loss=10.3822, \n",
            "Epoch 3716/6000: train_loss=7.8432, val_loss=9.9577, \n",
            "Epoch 3717/6000: train_loss=7.8421, val_loss=10.1734, \n",
            "Epoch 3718/6000: train_loss=7.8853, val_loss=10.4718, \n",
            "Epoch 3719/6000: train_loss=7.8326, val_loss=9.8231, \n",
            "Epoch 3720/6000: train_loss=7.8259, val_loss=10.2249, \n",
            "Epoch 3721/6000: train_loss=7.8141, val_loss=10.4710, \n",
            "Epoch 3722/6000: train_loss=7.8867, val_loss=10.7228, \n",
            "Epoch 3723/6000: train_loss=7.9380, val_loss=9.7921, \n",
            "Epoch 3724/6000: train_loss=7.9230, val_loss=10.5806, \n",
            "Epoch 3725/6000: train_loss=7.8102, val_loss=9.9422, \n",
            "Epoch 3726/6000: train_loss=7.9859, val_loss=10.8768, \n",
            "Epoch 3727/6000: train_loss=8.3811, val_loss=9.9613, \n",
            "Epoch 3728/6000: train_loss=7.9791, val_loss=10.6943, \n",
            "Epoch 3729/6000: train_loss=7.9893, val_loss=9.7605, \n",
            "Epoch 3730/6000: train_loss=8.6285, val_loss=12.0207, \n",
            "Epoch 3731/6000: train_loss=8.1564, val_loss=10.0164, \n",
            "Epoch 3732/6000: train_loss=7.8328, val_loss=10.4189, \n",
            "Epoch 3733/6000: train_loss=7.8543, val_loss=10.3908, \n",
            "Epoch 3734/6000: train_loss=7.8617, val_loss=9.8517, \n",
            "Epoch 3735/6000: train_loss=8.0440, val_loss=10.7896, \n",
            "Epoch 3736/6000: train_loss=8.3044, val_loss=10.0821, \n",
            "Epoch 3737/6000: train_loss=8.7457, val_loss=12.3829, \n",
            "Epoch 3738/6000: train_loss=8.4082, val_loss=10.5209, \n",
            "Epoch 3739/6000: train_loss=8.8695, val_loss=12.5262, \n",
            "Epoch 3740/6000: train_loss=8.9677, val_loss=9.6570, \n",
            "Epoch 3741/6000: train_loss=8.7620, val_loss=11.7572, \n",
            "Epoch 3742/6000: train_loss=8.0005, val_loss=9.7613, \n",
            "Epoch 3743/6000: train_loss=8.1745, val_loss=11.2837, \n",
            "Epoch 3744/6000: train_loss=8.1075, val_loss=10.0951, \n",
            "Epoch 3745/6000: train_loss=7.9594, val_loss=11.0030, \n",
            "Epoch 3746/6000: train_loss=7.9750, val_loss=10.8108, \n",
            "Epoch 3747/6000: train_loss=8.3530, val_loss=9.6923, \n",
            "Epoch 3748/6000: train_loss=8.0278, val_loss=10.6854, \n",
            "Epoch 3749/6000: train_loss=7.7849, val_loss=9.6051, \n",
            "Epoch 3750/6000: train_loss=8.1276, val_loss=10.9043, \n",
            "Epoch 3751/6000: train_loss=8.2919, val_loss=10.0475, \n",
            "Epoch 3752/6000: train_loss=8.6088, val_loss=12.2276, \n",
            "Epoch 3753/6000: train_loss=8.2636, val_loss=9.9727, \n",
            "Epoch 3754/6000: train_loss=8.2285, val_loss=11.1214, \n",
            "Epoch 3755/6000: train_loss=8.4386, val_loss=9.5624, \n",
            "Epoch 3756/6000: train_loss=7.7485, val_loss=10.1587, \n",
            "Epoch 3757/6000: train_loss=7.7623, val_loss=10.2647, \n",
            "Epoch 3758/6000: train_loss=7.8138, val_loss=9.9466, \n",
            "Epoch 3759/6000: train_loss=8.2788, val_loss=11.4064, \n",
            "Epoch 3760/6000: train_loss=8.5700, val_loss=9.8629, \n",
            "Epoch 3761/6000: train_loss=9.3655, val_loss=12.9929, \n",
            "Epoch 3762/6000: train_loss=9.5475, val_loss=10.5191, \n",
            "Epoch 3763/6000: train_loss=8.7125, val_loss=12.4345, \n",
            "Epoch 3764/6000: train_loss=7.8512, val_loss=9.9154, \n",
            "Epoch 3765/6000: train_loss=7.8384, val_loss=9.4327, \n",
            "Epoch 3766/6000: train_loss=7.7655, val_loss=9.9191, \n",
            "Epoch 3767/6000: train_loss=8.1594, val_loss=10.0934, \n",
            "Epoch 3768/6000: train_loss=8.3534, val_loss=11.8520, \n",
            "Epoch 3769/6000: train_loss=7.8163, val_loss=9.6068, \n",
            "Epoch 3770/6000: train_loss=7.8332, val_loss=9.9359, \n",
            "Epoch 3771/6000: train_loss=8.3361, val_loss=10.3229, \n",
            "Epoch 3772/6000: train_loss=8.1932, val_loss=11.7220, \n",
            "Epoch 3773/6000: train_loss=8.2335, val_loss=9.4447, \n",
            "Epoch 3774/6000: train_loss=8.3629, val_loss=11.1213, \n",
            "Epoch 3775/6000: train_loss=8.0940, val_loss=9.7967, \n",
            "Epoch 3776/6000: train_loss=7.7897, val_loss=10.8377, \n",
            "Epoch 3777/6000: train_loss=7.7407, val_loss=9.9763, \n",
            "Epoch 3778/6000: train_loss=7.7999, val_loss=9.6725, \n",
            "Epoch 3779/6000: train_loss=7.9125, val_loss=10.9392, \n",
            "Epoch 3780/6000: train_loss=7.9003, val_loss=10.2434, \n",
            "Epoch 3781/6000: train_loss=7.7119, val_loss=9.8695, \n",
            "Epoch 3782/6000: train_loss=7.9249, val_loss=9.3299, \n",
            "Epoch 3783/6000: train_loss=7.9109, val_loss=10.5328, \n",
            "Epoch 3784/6000: train_loss=8.3243, val_loss=10.1921, \n",
            "Epoch 3785/6000: train_loss=7.8410, val_loss=10.8965, \n",
            "Epoch 3786/6000: train_loss=7.8619, val_loss=9.5149, \n",
            "Epoch 3787/6000: train_loss=7.7787, val_loss=9.9289, \n",
            "Epoch 3788/6000: train_loss=7.7668, val_loss=9.8904, \n",
            "Epoch 3789/6000: train_loss=7.8825, val_loss=10.9695, \n",
            "Epoch 3790/6000: train_loss=8.0913, val_loss=9.9362, \n",
            "Epoch 3791/6000: train_loss=8.1184, val_loss=10.8466, \n",
            "Epoch 3792/6000: train_loss=7.8099, val_loss=9.5982, \n",
            "Epoch 3793/6000: train_loss=7.7541, val_loss=10.1841, \n",
            "Epoch 3794/6000: train_loss=7.7213, val_loss=9.8314, \n",
            "Epoch 3795/6000: train_loss=7.7127, val_loss=9.8906, \n",
            "Epoch 3796/6000: train_loss=7.7769, val_loss=10.4753, \n",
            "Epoch 3797/6000: train_loss=7.6875, val_loss=10.0221, \n",
            "Epoch 3798/6000: train_loss=7.8957, val_loss=10.7285, \n",
            "Epoch 3799/6000: train_loss=7.7580, val_loss=9.8427, \n",
            "Epoch 3800/6000: train_loss=7.7688, val_loss=10.3487, \n",
            "Epoch 3801/6000: train_loss=7.7794, val_loss=9.7557, \n",
            "Epoch 3802/6000: train_loss=7.8051, val_loss=10.6151, \n",
            "Epoch 3803/6000: train_loss=7.6854, val_loss=10.0918, \n",
            "Epoch 3804/6000: train_loss=7.7029, val_loss=10.0890, \n",
            "Epoch 3805/6000: train_loss=7.7542, val_loss=10.3986, \n",
            "Epoch 3806/6000: train_loss=7.7244, val_loss=9.8231, \n",
            "Epoch 3807/6000: train_loss=7.6804, val_loss=9.9187, \n",
            "Epoch 3808/6000: train_loss=7.7082, val_loss=10.0414, \n",
            "Epoch 3809/6000: train_loss=7.7201, val_loss=10.3939, \n",
            "Epoch 3810/6000: train_loss=7.6874, val_loss=10.2793, \n",
            "Epoch 3811/6000: train_loss=7.6848, val_loss=10.2862, \n",
            "Epoch 3812/6000: train_loss=7.7198, val_loss=9.9503, \n",
            "Epoch 3813/6000: train_loss=7.6993, val_loss=9.5907, \n",
            "Epoch 3814/6000: train_loss=7.7026, val_loss=9.7249, \n",
            "Epoch 3815/6000: train_loss=7.8407, val_loss=10.6160, \n",
            "Epoch 3816/6000: train_loss=7.8512, val_loss=9.6375, \n",
            "Epoch 3817/6000: train_loss=8.2782, val_loss=11.1440, \n",
            "Epoch 3818/6000: train_loss=8.5135, val_loss=9.6125, \n",
            "Epoch 3819/6000: train_loss=8.4713, val_loss=11.8087, \n",
            "Epoch 3820/6000: train_loss=8.1668, val_loss=9.7360, \n",
            "Epoch 3821/6000: train_loss=7.7864, val_loss=10.0488, \n",
            "Epoch 3822/6000: train_loss=7.6894, val_loss=9.7749, \n",
            "Epoch 3823/6000: train_loss=7.7737, val_loss=9.9318, \n",
            "Epoch 3824/6000: train_loss=7.7177, val_loss=10.6032, \n",
            "Epoch 3825/6000: train_loss=7.7785, val_loss=10.5236, \n",
            "Epoch 3826/6000: train_loss=7.6685, val_loss=9.5917, \n",
            "Epoch 3827/6000: train_loss=7.7050, val_loss=9.4574, \n",
            "Epoch 3828/6000: train_loss=7.7487, val_loss=10.1954, \n",
            "Epoch 3829/6000: train_loss=7.9983, val_loss=9.8452, \n",
            "Epoch 3830/6000: train_loss=7.8893, val_loss=10.9786, \n",
            "Epoch 3831/6000: train_loss=8.0531, val_loss=9.4104, \n",
            "Epoch 3832/6000: train_loss=7.6484, val_loss=9.8403, \n",
            "Epoch 3833/6000: train_loss=7.6522, val_loss=10.0940, \n",
            "Epoch 3834/6000: train_loss=7.6541, val_loss=10.2064, \n",
            "Epoch 3835/6000: train_loss=7.8811, val_loss=9.5805, \n",
            "Epoch 3836/6000: train_loss=7.6446, val_loss=9.6711, \n",
            "Epoch 3837/6000: train_loss=7.6657, val_loss=9.9937, \n",
            "Epoch 3838/6000: train_loss=7.7507, val_loss=9.7892, \n",
            "Epoch 3839/6000: train_loss=7.9381, val_loss=10.7072, \n",
            "Epoch 3840/6000: train_loss=7.7133, val_loss=9.5316, \n",
            "Epoch 3841/6000: train_loss=7.6464, val_loss=9.9381, \n",
            "Epoch 3842/6000: train_loss=7.6679, val_loss=10.4844, \n",
            "Epoch 3843/6000: train_loss=7.7987, val_loss=9.8260, \n",
            "Epoch 3844/6000: train_loss=8.0971, val_loss=10.6729, \n",
            "Epoch 3845/6000: train_loss=7.7603, val_loss=9.3065, \n",
            "Epoch 3846/6000: train_loss=7.6433, val_loss=10.1508, \n",
            "Epoch 3847/6000: train_loss=7.6286, val_loss=10.0763, \n",
            "Epoch 3848/6000: train_loss=7.6260, val_loss=10.0291, \n",
            "Epoch 3849/6000: train_loss=7.6654, val_loss=9.9642, \n",
            "Epoch 3850/6000: train_loss=7.7159, val_loss=10.4071, \n",
            "Epoch 3851/6000: train_loss=7.6202, val_loss=9.6581, \n",
            "Epoch 3852/6000: train_loss=7.6879, val_loss=9.3739, \n",
            "Epoch 3853/6000: train_loss=7.6541, val_loss=10.2286, \n",
            "Epoch 3854/6000: train_loss=7.6712, val_loss=10.0792, \n",
            "Epoch 3855/6000: train_loss=7.7254, val_loss=10.4257, \n",
            "Epoch 3856/6000: train_loss=7.7126, val_loss=9.5565, \n",
            "Epoch 3857/6000: train_loss=7.7894, val_loss=10.3891, \n",
            "Epoch 3858/6000: train_loss=7.6309, val_loss=9.9980, \n",
            "Epoch 3859/6000: train_loss=7.6208, val_loss=10.1350, \n",
            "Epoch 3860/6000: train_loss=7.9081, val_loss=9.4138, \n",
            "Epoch 3861/6000: train_loss=7.7965, val_loss=10.3306, \n",
            "Epoch 3862/6000: train_loss=7.6919, val_loss=9.6889, \n",
            "Epoch 3863/6000: train_loss=8.2034, val_loss=11.2730, \n",
            "Epoch 3864/6000: train_loss=7.6244, val_loss=9.9017, \n",
            "Epoch 3865/6000: train_loss=7.6245, val_loss=9.9708, \n",
            "Epoch 3866/6000: train_loss=7.9493, val_loss=10.9780, \n",
            "Epoch 3867/6000: train_loss=7.8742, val_loss=9.6931, \n",
            "Epoch 3868/6000: train_loss=7.7452, val_loss=10.3337, \n",
            "Epoch 3869/6000: train_loss=7.6248, val_loss=9.6023, \n",
            "Epoch 3870/6000: train_loss=7.6264, val_loss=10.1820, \n",
            "Epoch 3871/6000: train_loss=7.5937, val_loss=9.8789, \n",
            "Epoch 3872/6000: train_loss=7.6506, val_loss=10.0295, \n",
            "Epoch 3873/6000: train_loss=8.5328, val_loss=10.0619, \n",
            "Epoch 3874/6000: train_loss=8.0553, val_loss=11.1795, \n",
            "Epoch 3875/6000: train_loss=8.3743, val_loss=9.2625, \n",
            "Epoch 3876/6000: train_loss=7.6435, val_loss=9.3297, \n",
            "Epoch 3877/6000: train_loss=7.6435, val_loss=10.3167, \n",
            "Epoch 3878/6000: train_loss=7.6087, val_loss=10.2229, \n",
            "Epoch 3879/6000: train_loss=7.7841, val_loss=10.2293, \n",
            "Epoch 3880/6000: train_loss=7.8072, val_loss=9.7012, \n",
            "Epoch 3881/6000: train_loss=8.0555, val_loss=11.2326, \n",
            "Epoch 3882/6000: train_loss=8.2505, val_loss=9.5585, \n",
            "Epoch 3883/6000: train_loss=8.0915, val_loss=10.8463, \n",
            "Epoch 3884/6000: train_loss=8.1434, val_loss=9.6265, \n",
            "Epoch 3885/6000: train_loss=7.6946, val_loss=10.4149, \n",
            "Epoch 3886/6000: train_loss=7.6079, val_loss=9.7396, \n",
            "Epoch 3887/6000: train_loss=7.6065, val_loss=9.5355, \n",
            "Epoch 3888/6000: train_loss=7.6370, val_loss=10.0910, \n",
            "Epoch 3889/6000: train_loss=7.6974, val_loss=9.8383, \n",
            "Epoch 3890/6000: train_loss=7.7684, val_loss=10.5912, \n",
            "Epoch 3891/6000: train_loss=7.7918, val_loss=9.4838, \n",
            "Epoch 3892/6000: train_loss=7.5756, val_loss=9.8787, \n",
            "Epoch 3893/6000: train_loss=7.8284, val_loss=10.6444, \n",
            "Epoch 3894/6000: train_loss=7.5706, val_loss=9.7699, \n",
            "Epoch 3895/6000: train_loss=7.5777, val_loss=9.5945, \n",
            "Epoch 3896/6000: train_loss=7.7039, val_loss=9.6926, \n",
            "Epoch 3897/6000: train_loss=7.8677, val_loss=10.6861, \n",
            "Epoch 3898/6000: train_loss=7.6576, val_loss=9.5241, \n",
            "Epoch 3899/6000: train_loss=7.5669, val_loss=9.8632, \n",
            "Epoch 3900/6000: train_loss=7.6449, val_loss=9.9227, \n",
            "Epoch 3901/6000: train_loss=7.9753, val_loss=9.5250, \n",
            "Epoch 3902/6000: train_loss=8.6736, val_loss=12.1509, \n",
            "Epoch 3903/6000: train_loss=8.2331, val_loss=9.5495, \n",
            "Epoch 3904/6000: train_loss=8.3795, val_loss=11.1761, \n",
            "Epoch 3905/6000: train_loss=8.7511, val_loss=9.6656, \n",
            "Epoch 3906/6000: train_loss=8.9620, val_loss=12.6047, \n",
            "Epoch 3907/6000: train_loss=8.4794, val_loss=9.6673, \n",
            "Epoch 3908/6000: train_loss=8.5442, val_loss=11.8439, \n",
            "Epoch 3909/6000: train_loss=7.7040, val_loss=9.5918, \n",
            "Epoch 3910/6000: train_loss=7.5844, val_loss=9.9743, \n",
            "Epoch 3911/6000: train_loss=7.9683, val_loss=11.1649, \n",
            "Epoch 3912/6000: train_loss=8.7728, val_loss=9.7111, \n",
            "Epoch 3913/6000: train_loss=10.3028, val_loss=13.5189, \n",
            "Epoch 3914/6000: train_loss=9.0986, val_loss=9.2667, \n",
            "Epoch 3915/6000: train_loss=10.4908, val_loss=14.4714, \n",
            "Epoch 3916/6000: train_loss=10.5780, val_loss=11.6583, \n",
            "Epoch 3917/6000: train_loss=9.0427, val_loss=13.0340, \n",
            "Epoch 3918/6000: train_loss=8.4058, val_loss=9.5554, \n",
            "Epoch 3919/6000: train_loss=7.9327, val_loss=10.6043, \n",
            "Epoch 3920/6000: train_loss=7.6037, val_loss=9.7129, \n",
            "Epoch 3921/6000: train_loss=7.5818, val_loss=9.9553, \n",
            "Epoch 3922/6000: train_loss=7.5885, val_loss=9.8175, \n",
            "Epoch 3923/6000: train_loss=7.9352, val_loss=9.5277, \n",
            "Epoch 3924/6000: train_loss=7.8679, val_loss=10.9035, \n",
            "Epoch 3925/6000: train_loss=7.5625, val_loss=9.7360, \n",
            "Epoch 3926/6000: train_loss=7.5641, val_loss=9.3262, \n",
            "Epoch 3927/6000: train_loss=7.5893, val_loss=9.6886, \n",
            "Epoch 3928/6000: train_loss=7.5434, val_loss=9.8605, \n",
            "Epoch 3929/6000: train_loss=7.5754, val_loss=10.0089, \n",
            "Epoch 3930/6000: train_loss=7.6294, val_loss=10.1522, \n",
            "Epoch 3931/6000: train_loss=8.8182, val_loss=9.5680, \n",
            "Epoch 3932/6000: train_loss=8.0442, val_loss=11.0427, \n",
            "Epoch 3933/6000: train_loss=7.7480, val_loss=9.5849, \n",
            "Epoch 3934/6000: train_loss=7.5288, val_loss=9.8473, \n",
            "Epoch 3935/6000: train_loss=7.5622, val_loss=9.8556, \n",
            "Epoch 3936/6000: train_loss=7.7199, val_loss=10.3876, \n",
            "Epoch 3937/6000: train_loss=7.6335, val_loss=9.6922, \n",
            "Epoch 3938/6000: train_loss=7.6248, val_loss=9.3322, \n",
            "Epoch 3939/6000: train_loss=7.5991, val_loss=10.2131, \n",
            "Epoch 3940/6000: train_loss=7.7106, val_loss=9.5318, \n",
            "Epoch 3941/6000: train_loss=8.0612, val_loss=11.0308, \n",
            "Epoch 3942/6000: train_loss=8.5396, val_loss=9.3543, \n",
            "Epoch 3943/6000: train_loss=8.5987, val_loss=11.5543, \n",
            "Epoch 3944/6000: train_loss=8.7401, val_loss=9.6785, \n",
            "Epoch 3945/6000: train_loss=8.6536, val_loss=12.2659, \n",
            "Epoch 3946/6000: train_loss=7.9089, val_loss=9.4526, \n",
            "Epoch 3947/6000: train_loss=7.5293, val_loss=9.5861, \n",
            "Epoch 3948/6000: train_loss=7.5817, val_loss=9.6812, \n",
            "Epoch 3949/6000: train_loss=7.5518, val_loss=10.0704, \n",
            "Epoch 3950/6000: train_loss=7.7618, val_loss=10.2761, \n",
            "Epoch 3951/6000: train_loss=7.8330, val_loss=9.0888, \n",
            "Epoch 3952/6000: train_loss=7.6309, val_loss=10.1468, \n",
            "Epoch 3953/6000: train_loss=7.5604, val_loss=9.7765, \n",
            "Epoch 3954/6000: train_loss=7.7299, val_loss=10.3360, \n",
            "Epoch 3955/6000: train_loss=7.8014, val_loss=9.0774, \n",
            "Epoch 3956/6000: train_loss=7.6260, val_loss=9.6700, \n",
            "Epoch 3957/6000: train_loss=8.0738, val_loss=9.6036, \n",
            "Epoch 3958/6000: train_loss=7.6278, val_loss=10.4526, \n",
            "Epoch 3959/6000: train_loss=7.5499, val_loss=9.3536, \n",
            "Epoch 3960/6000: train_loss=7.5187, val_loss=9.5953, \n",
            "Epoch 3961/6000: train_loss=7.5117, val_loss=9.9551, \n",
            "Epoch 3962/6000: train_loss=7.5031, val_loss=10.0204, \n",
            "Epoch 3963/6000: train_loss=7.5684, val_loss=9.8309, \n",
            "Epoch 3964/6000: train_loss=7.7846, val_loss=9.0790, \n",
            "Epoch 3965/6000: train_loss=8.0276, val_loss=10.9110, \n",
            "Epoch 3966/6000: train_loss=7.8980, val_loss=9.3940, \n",
            "Epoch 3967/6000: train_loss=7.8589, val_loss=10.1993, \n",
            "Epoch 3968/6000: train_loss=7.5323, val_loss=9.7672, \n",
            "Epoch 3969/6000: train_loss=7.7209, val_loss=10.6793, \n",
            "Epoch 3970/6000: train_loss=7.5465, val_loss=9.9066, \n",
            "Epoch 3971/6000: train_loss=7.5090, val_loss=10.0337, \n",
            "Epoch 3972/6000: train_loss=7.4941, val_loss=9.6613, \n",
            "Epoch 3973/6000: train_loss=7.5169, val_loss=9.1457, \n",
            "Epoch 3974/6000: train_loss=7.5406, val_loss=9.2488, \n",
            "Epoch 3975/6000: train_loss=7.5211, val_loss=10.0529, \n",
            "Epoch 3976/6000: train_loss=7.5514, val_loss=9.7753, \n",
            "Epoch 3977/6000: train_loss=7.7903, val_loss=10.5097, \n",
            "Epoch 3978/6000: train_loss=7.9352, val_loss=9.5992, \n",
            "Epoch 3979/6000: train_loss=8.4159, val_loss=11.5169, \n",
            "Epoch 3980/6000: train_loss=8.6260, val_loss=9.7520, \n",
            "Epoch 3981/6000: train_loss=8.0651, val_loss=10.8658, \n",
            "Epoch 3982/6000: train_loss=7.8474, val_loss=9.1114, \n",
            "Epoch 3983/6000: train_loss=7.5115, val_loss=9.3290, \n",
            "Epoch 3984/6000: train_loss=7.5852, val_loss=10.2417, \n",
            "Epoch 3985/6000: train_loss=7.4895, val_loss=9.4604, \n",
            "Epoch 3986/6000: train_loss=7.5399, val_loss=9.8635, \n",
            "Epoch 3987/6000: train_loss=7.5554, val_loss=9.5461, \n",
            "Epoch 3988/6000: train_loss=7.5741, val_loss=10.3425, \n",
            "Epoch 3989/6000: train_loss=7.6872, val_loss=9.2799, \n",
            "Epoch 3990/6000: train_loss=7.4871, val_loss=9.4301, \n",
            "Epoch 3991/6000: train_loss=7.5301, val_loss=9.2758, \n",
            "Epoch 3992/6000: train_loss=7.4585, val_loss=9.7518, \n",
            "Epoch 3993/6000: train_loss=7.4931, val_loss=10.0645, \n",
            "Epoch 3994/6000: train_loss=7.4574, val_loss=9.4636, \n",
            "Epoch 3995/6000: train_loss=7.4796, val_loss=9.3584, \n",
            "Epoch 3996/6000: train_loss=7.4744, val_loss=9.6928, \n",
            "Epoch 3997/6000: train_loss=7.6010, val_loss=10.3765, \n",
            "Epoch 3998/6000: train_loss=7.9484, val_loss=9.4122, \n",
            "Epoch 3999/6000: train_loss=7.4820, val_loss=9.5132, \n",
            "Epoch 4000/6000: train_loss=7.4659, val_loss=9.9706, \n",
            "Epoch 4001/6000: train_loss=7.4928, val_loss=9.5619, \n",
            "Epoch 4002/6000: train_loss=7.4745, val_loss=9.2067, \n",
            "Epoch 4003/6000: train_loss=7.5163, val_loss=9.4821, \n",
            "Epoch 4004/6000: train_loss=7.5755, val_loss=9.9139, \n",
            "Epoch 4005/6000: train_loss=7.6219, val_loss=9.3760, \n",
            "Epoch 4006/6000: train_loss=7.9095, val_loss=10.8519, \n",
            "Epoch 4007/6000: train_loss=7.6404, val_loss=9.5367, \n",
            "Epoch 4008/6000: train_loss=7.5593, val_loss=9.9909, \n",
            "Epoch 4009/6000: train_loss=7.4898, val_loss=9.2986, \n",
            "Epoch 4010/6000: train_loss=7.4423, val_loss=9.5480, \n",
            "Epoch 4011/6000: train_loss=7.4810, val_loss=9.9090, \n",
            "Epoch 4012/6000: train_loss=7.6499, val_loss=10.3668, \n",
            "Epoch 4013/6000: train_loss=7.4606, val_loss=9.3627, \n",
            "Epoch 4014/6000: train_loss=7.4684, val_loss=9.6886, \n",
            "Epoch 4015/6000: train_loss=7.6371, val_loss=10.9660, \n",
            "Epoch 4016/6000: train_loss=7.4954, val_loss=9.7075, \n",
            "Epoch 4017/6000: train_loss=7.5854, val_loss=9.1228, \n",
            "Epoch 4018/6000: train_loss=7.4549, val_loss=9.6503, \n",
            "Epoch 4019/6000: train_loss=7.5482, val_loss=10.2588, \n",
            "Epoch 4020/6000: train_loss=7.6245, val_loss=9.4611, \n",
            "Epoch 4021/6000: train_loss=8.3816, val_loss=11.3113, \n",
            "Epoch 4022/6000: train_loss=7.6266, val_loss=9.2391, \n",
            "Epoch 4023/6000: train_loss=7.5879, val_loss=10.1429, \n",
            "Epoch 4024/6000: train_loss=7.4430, val_loss=9.7838, \n",
            "Epoch 4025/6000: train_loss=7.4326, val_loss=10.0164, \n",
            "Epoch 4026/6000: train_loss=7.6110, val_loss=10.3059, \n",
            "Epoch 4027/6000: train_loss=7.5040, val_loss=9.1776, \n",
            "Epoch 4028/6000: train_loss=7.4793, val_loss=9.4461, \n",
            "Epoch 4029/6000: train_loss=7.6579, val_loss=10.6410, \n",
            "Epoch 4030/6000: train_loss=7.6623, val_loss=9.2012, \n",
            "Epoch 4031/6000: train_loss=7.5969, val_loss=9.7988, \n",
            "Epoch 4032/6000: train_loss=7.5731, val_loss=9.3282, \n",
            "Epoch 4033/6000: train_loss=7.5359, val_loss=10.2776, \n",
            "Epoch 4034/6000: train_loss=7.4072, val_loss=9.4616, \n",
            "Epoch 4035/6000: train_loss=7.4697, val_loss=9.6159, \n",
            "Epoch 4036/6000: train_loss=7.5766, val_loss=9.4637, \n",
            "Epoch 4037/6000: train_loss=7.5140, val_loss=10.1471, \n",
            "Epoch 4038/6000: train_loss=7.4441, val_loss=9.2056, \n",
            "Epoch 4039/6000: train_loss=7.5628, val_loss=9.8360, \n",
            "Epoch 4040/6000: train_loss=8.1106, val_loss=9.6972, \n",
            "Epoch 4041/6000: train_loss=7.6077, val_loss=10.5189, \n",
            "Epoch 4042/6000: train_loss=7.5603, val_loss=9.2637, \n",
            "Epoch 4043/6000: train_loss=7.4727, val_loss=9.0873, \n",
            "Epoch 4044/6000: train_loss=7.7657, val_loss=10.3664, \n",
            "Epoch 4045/6000: train_loss=8.8402, val_loss=9.7591, \n",
            "Epoch 4046/6000: train_loss=9.2463, val_loss=12.8798, \n",
            "Epoch 4047/6000: train_loss=7.6483, val_loss=9.2627, \n",
            "Epoch 4048/6000: train_loss=7.4065, val_loss=9.3773, \n",
            "Epoch 4049/6000: train_loss=7.5483, val_loss=10.2019, \n",
            "Epoch 4050/6000: train_loss=7.4621, val_loss=9.3503, \n",
            "Epoch 4051/6000: train_loss=7.4007, val_loss=9.5118, \n",
            "Epoch 4052/6000: train_loss=7.3867, val_loss=9.5060, \n",
            "Epoch 4053/6000: train_loss=7.3916, val_loss=9.6608, \n",
            "Epoch 4054/6000: train_loss=7.4021, val_loss=9.9213, \n",
            "Epoch 4055/6000: train_loss=7.6385, val_loss=10.2458, \n",
            "Epoch 4056/6000: train_loss=7.4531, val_loss=9.1597, \n",
            "Epoch 4057/6000: train_loss=7.4087, val_loss=9.3467, \n",
            "Epoch 4058/6000: train_loss=7.3788, val_loss=9.7736, \n",
            "Epoch 4059/6000: train_loss=7.3786, val_loss=9.5767, \n",
            "Epoch 4060/6000: train_loss=7.5056, val_loss=9.3920, \n",
            "Epoch 4061/6000: train_loss=7.7167, val_loss=10.4736, \n",
            "Epoch 4062/6000: train_loss=7.5786, val_loss=9.2799, \n",
            "Epoch 4063/6000: train_loss=7.4220, val_loss=9.7457, \n",
            "Epoch 4064/6000: train_loss=7.3753, val_loss=9.5826, \n",
            "Epoch 4065/6000: train_loss=7.8163, val_loss=9.4091, \n",
            "Epoch 4066/6000: train_loss=7.5041, val_loss=10.1041, \n",
            "Epoch 4067/6000: train_loss=7.3836, val_loss=9.2710, \n",
            "Epoch 4068/6000: train_loss=7.4820, val_loss=9.7383, \n",
            "Epoch 4069/6000: train_loss=7.3714, val_loss=9.4082, \n",
            "Epoch 4070/6000: train_loss=7.3792, val_loss=9.7680, \n",
            "Epoch 4071/6000: train_loss=7.3744, val_loss=9.7754, \n",
            "Epoch 4072/6000: train_loss=7.5223, val_loss=9.1649, \n",
            "Epoch 4073/6000: train_loss=7.5033, val_loss=9.9995, \n",
            "Epoch 4074/6000: train_loss=7.3734, val_loss=9.1719, \n",
            "Epoch 4075/6000: train_loss=7.4551, val_loss=9.5753, \n",
            "Epoch 4076/6000: train_loss=7.8223, val_loss=9.4433, \n",
            "Epoch 4077/6000: train_loss=7.6790, val_loss=10.7416, \n",
            "Epoch 4078/6000: train_loss=7.3986, val_loss=9.5502, \n",
            "Epoch 4079/6000: train_loss=7.3925, val_loss=9.3629, \n",
            "Epoch 4080/6000: train_loss=7.4745, val_loss=9.3708, \n",
            "Epoch 4081/6000: train_loss=7.5918, val_loss=10.5183, \n",
            "Epoch 4082/6000: train_loss=7.4513, val_loss=9.1738, \n",
            "Epoch 4083/6000: train_loss=7.4972, val_loss=9.6672, \n",
            "Epoch 4084/6000: train_loss=7.3979, val_loss=9.1896, \n",
            "Epoch 4085/6000: train_loss=7.3881, val_loss=9.2986, \n",
            "Epoch 4086/6000: train_loss=7.3849, val_loss=9.9913, \n",
            "Epoch 4087/6000: train_loss=7.4665, val_loss=9.4745, \n",
            "Epoch 4088/6000: train_loss=7.3548, val_loss=9.3754, \n",
            "Epoch 4089/6000: train_loss=7.3517, val_loss=9.4781, \n",
            "Epoch 4090/6000: train_loss=7.4025, val_loss=10.0170, \n",
            "Epoch 4091/6000: train_loss=7.3611, val_loss=9.2994, \n",
            "Epoch 4092/6000: train_loss=7.3714, val_loss=9.5092, \n",
            "Epoch 4093/6000: train_loss=7.4509, val_loss=9.4245, \n",
            "Epoch 4094/6000: train_loss=7.3626, val_loss=9.7974, \n",
            "Epoch 4095/6000: train_loss=7.3650, val_loss=9.1419, \n",
            "Epoch 4096/6000: train_loss=7.5758, val_loss=9.8659, \n",
            "Epoch 4097/6000: train_loss=7.6744, val_loss=9.3045, \n",
            "Epoch 4098/6000: train_loss=7.7968, val_loss=10.8853, \n",
            "Epoch 4099/6000: train_loss=7.3541, val_loss=9.5784, \n",
            "Epoch 4100/6000: train_loss=7.3599, val_loss=9.5198, \n",
            "Epoch 4101/6000: train_loss=7.4945, val_loss=9.8537, \n",
            "Epoch 4102/6000: train_loss=7.7020, val_loss=9.4326, \n",
            "Epoch 4103/6000: train_loss=7.3459, val_loss=9.7766, \n",
            "Epoch 4104/6000: train_loss=7.3242, val_loss=9.4861, \n",
            "Epoch 4105/6000: train_loss=7.3450, val_loss=9.3594, \n",
            "Epoch 4106/6000: train_loss=7.4433, val_loss=9.6110, \n",
            "Epoch 4107/6000: train_loss=7.3664, val_loss=9.6885, \n",
            "Epoch 4108/6000: train_loss=7.6709, val_loss=9.4593, \n",
            "Epoch 4109/6000: train_loss=7.3592, val_loss=9.9029, \n",
            "Epoch 4110/6000: train_loss=7.3359, val_loss=9.5404, \n",
            "Epoch 4111/6000: train_loss=7.3419, val_loss=9.2331, \n",
            "Epoch 4112/6000: train_loss=7.3226, val_loss=9.5406, \n",
            "Epoch 4113/6000: train_loss=7.3339, val_loss=9.6387, \n",
            "Epoch 4114/6000: train_loss=7.4243, val_loss=9.7768, \n",
            "Epoch 4115/6000: train_loss=8.1794, val_loss=9.3465, \n",
            "Epoch 4116/6000: train_loss=8.0317, val_loss=11.0076, \n",
            "Epoch 4117/6000: train_loss=7.3726, val_loss=9.5690, \n",
            "Epoch 4118/6000: train_loss=7.4328, val_loss=9.7408, \n",
            "Epoch 4119/6000: train_loss=7.7054, val_loss=9.9357, \n",
            "Epoch 4120/6000: train_loss=7.7795, val_loss=9.1507, \n",
            "Epoch 4121/6000: train_loss=7.8634, val_loss=11.2349, \n",
            "Epoch 4122/6000: train_loss=7.7934, val_loss=9.2976, \n",
            "Epoch 4123/6000: train_loss=7.7257, val_loss=9.9591, \n",
            "Epoch 4124/6000: train_loss=7.4214, val_loss=9.1047, \n",
            "Epoch 4125/6000: train_loss=7.6301, val_loss=9.3386, \n",
            "Epoch 4126/6000: train_loss=7.6578, val_loss=10.3991, \n",
            "Epoch 4127/6000: train_loss=7.8728, val_loss=9.0408, \n",
            "Epoch 4128/6000: train_loss=7.5642, val_loss=10.2976, \n",
            "Epoch 4129/6000: train_loss=7.3915, val_loss=9.4840, \n",
            "Epoch 4130/6000: train_loss=7.2943, val_loss=9.4291, \n",
            "Epoch 4131/6000: train_loss=7.5381, val_loss=9.9441, \n",
            "Epoch 4132/6000: train_loss=8.7782, val_loss=9.8453, \n",
            "Epoch 4133/6000: train_loss=7.9690, val_loss=11.2497, \n",
            "Epoch 4134/6000: train_loss=8.0562, val_loss=9.2176, \n",
            "Epoch 4135/6000: train_loss=7.3501, val_loss=9.3695, \n",
            "Epoch 4136/6000: train_loss=7.3154, val_loss=9.2840, \n",
            "Epoch 4137/6000: train_loss=7.3910, val_loss=9.1377, \n",
            "Epoch 4138/6000: train_loss=7.4945, val_loss=9.8462, \n",
            "Epoch 4139/6000: train_loss=7.7654, val_loss=9.1371, \n",
            "Epoch 4140/6000: train_loss=7.7789, val_loss=11.0433, \n",
            "Epoch 4141/6000: train_loss=7.4248, val_loss=9.5178, \n",
            "Epoch 4142/6000: train_loss=7.2843, val_loss=9.3228, \n",
            "Epoch 4143/6000: train_loss=7.4541, val_loss=9.6666, \n",
            "Epoch 4144/6000: train_loss=7.6315, val_loss=9.2056, \n",
            "Epoch 4145/6000: train_loss=7.3575, val_loss=10.0041, \n",
            "Epoch 4146/6000: train_loss=7.3125, val_loss=9.2657, \n",
            "Epoch 4147/6000: train_loss=7.4185, val_loss=9.0646, \n",
            "Epoch 4148/6000: train_loss=7.3866, val_loss=9.6569, \n",
            "Epoch 4149/6000: train_loss=7.4986, val_loss=8.9120, \n",
            "Epoch 4150/6000: train_loss=7.3118, val_loss=9.1843, \n",
            "Epoch 4151/6000: train_loss=7.2744, val_loss=9.5081, \n",
            "Epoch 4152/6000: train_loss=7.3205, val_loss=9.1987, \n",
            "Epoch 4153/6000: train_loss=7.2990, val_loss=9.6601, \n",
            "Epoch 4154/6000: train_loss=7.3513, val_loss=9.6718, \n",
            "Epoch 4155/6000: train_loss=7.2973, val_loss=9.3413, \n",
            "Epoch 4156/6000: train_loss=7.3056, val_loss=9.2801, \n",
            "Epoch 4157/6000: train_loss=7.5034, val_loss=10.2334, \n",
            "Epoch 4158/6000: train_loss=7.8377, val_loss=9.0831, \n",
            "Epoch 4159/6000: train_loss=7.5033, val_loss=9.7463, \n",
            "Epoch 4160/6000: train_loss=7.3883, val_loss=8.7686, \n",
            "Epoch 4161/6000: train_loss=7.3318, val_loss=9.6217, \n",
            "Epoch 4162/6000: train_loss=7.7082, val_loss=10.8683, \n",
            "Epoch 4163/6000: train_loss=7.3447, val_loss=9.5109, \n",
            "Epoch 4164/6000: train_loss=7.4591, val_loss=9.8063, \n",
            "Epoch 4165/6000: train_loss=7.4855, val_loss=8.9357, \n",
            "Epoch 4166/6000: train_loss=7.9557, val_loss=11.1110, \n",
            "Epoch 4167/6000: train_loss=8.4529, val_loss=9.4840, \n",
            "Epoch 4168/6000: train_loss=7.9751, val_loss=10.3766, \n",
            "Epoch 4169/6000: train_loss=7.6413, val_loss=9.1219, \n",
            "Epoch 4170/6000: train_loss=8.1560, val_loss=11.2743, \n",
            "Epoch 4171/6000: train_loss=8.0463, val_loss=8.8728, \n",
            "Epoch 4172/6000: train_loss=7.7738, val_loss=10.1321, \n",
            "Epoch 4173/6000: train_loss=7.3621, val_loss=9.4702, \n",
            "Epoch 4174/6000: train_loss=7.3491, val_loss=10.0624, \n",
            "Epoch 4175/6000: train_loss=7.3057, val_loss=9.4008, \n",
            "Epoch 4176/6000: train_loss=7.4462, val_loss=8.9143, \n",
            "Epoch 4177/6000: train_loss=7.5788, val_loss=10.6572, \n",
            "Epoch 4178/6000: train_loss=7.7372, val_loss=9.3634, \n",
            "Epoch 4179/6000: train_loss=7.7938, val_loss=10.2962, \n",
            "Epoch 4180/6000: train_loss=7.8962, val_loss=8.7952, \n",
            "Epoch 4181/6000: train_loss=8.2490, val_loss=11.1679, \n",
            "Epoch 4182/6000: train_loss=7.8193, val_loss=9.4158, \n",
            "Epoch 4183/6000: train_loss=7.2883, val_loss=9.8594, \n",
            "Epoch 4184/6000: train_loss=7.3755, val_loss=9.7346, \n",
            "Epoch 4185/6000: train_loss=7.2836, val_loss=8.9147, \n",
            "Epoch 4186/6000: train_loss=7.2754, val_loss=9.0309, \n",
            "Epoch 4187/6000: train_loss=7.4428, val_loss=10.2836, \n",
            "Epoch 4188/6000: train_loss=7.3886, val_loss=9.0420, \n",
            "Epoch 4189/6000: train_loss=7.2583, val_loss=9.1369, \n",
            "Epoch 4190/6000: train_loss=7.2415, val_loss=8.9717, \n",
            "Epoch 4191/6000: train_loss=7.2458, val_loss=9.1412, \n",
            "Epoch 4192/6000: train_loss=7.4004, val_loss=10.0587, \n",
            "Epoch 4193/6000: train_loss=7.3615, val_loss=9.1599, \n",
            "Epoch 4194/6000: train_loss=7.2376, val_loss=9.4575, \n",
            "Epoch 4195/6000: train_loss=7.3120, val_loss=9.7351, \n",
            "Epoch 4196/6000: train_loss=7.2375, val_loss=9.2148, \n",
            "Epoch 4197/6000: train_loss=7.2476, val_loss=9.4044, \n",
            "Epoch 4198/6000: train_loss=7.2422, val_loss=9.1373, \n",
            "Epoch 4199/6000: train_loss=7.3143, val_loss=9.5000, \n",
            "Epoch 4200/6000: train_loss=7.2198, val_loss=9.4309, \n",
            "Epoch 4201/6000: train_loss=7.2998, val_loss=9.3430, \n",
            "Epoch 4202/6000: train_loss=7.2923, val_loss=9.6412, \n",
            "Epoch 4203/6000: train_loss=7.2448, val_loss=9.0771, \n",
            "Epoch 4204/6000: train_loss=7.2465, val_loss=9.1489, \n",
            "Epoch 4205/6000: train_loss=7.2632, val_loss=9.0802, \n",
            "Epoch 4206/6000: train_loss=7.3025, val_loss=9.5347, \n",
            "Epoch 4207/6000: train_loss=7.2321, val_loss=9.1862, \n",
            "Epoch 4208/6000: train_loss=7.2168, val_loss=9.3734, \n",
            "Epoch 4209/6000: train_loss=7.2695, val_loss=9.2184, \n",
            "Epoch 4210/6000: train_loss=7.3454, val_loss=9.6668, \n",
            "Epoch 4211/6000: train_loss=7.7063, val_loss=9.0012, \n",
            "Epoch 4212/6000: train_loss=7.4770, val_loss=10.3516, \n",
            "Epoch 4213/6000: train_loss=7.7942, val_loss=8.9992, \n",
            "Epoch 4214/6000: train_loss=7.2132, val_loss=9.2473, \n",
            "Epoch 4215/6000: train_loss=7.2319, val_loss=9.2682, \n",
            "Epoch 4216/6000: train_loss=7.2203, val_loss=9.2826, \n",
            "Epoch 4217/6000: train_loss=7.2688, val_loss=9.4420, \n",
            "Epoch 4218/6000: train_loss=7.6881, val_loss=10.3175, \n",
            "Epoch 4219/6000: train_loss=7.2357, val_loss=8.8613, \n",
            "Epoch 4220/6000: train_loss=7.3465, val_loss=9.2510, \n",
            "Epoch 4221/6000: train_loss=7.3942, val_loss=10.1948, \n",
            "Epoch 4222/6000: train_loss=7.3849, val_loss=8.9163, \n",
            "Epoch 4223/6000: train_loss=7.3779, val_loss=9.5052, \n",
            "Epoch 4224/6000: train_loss=8.0130, val_loss=9.0747, \n",
            "Epoch 4225/6000: train_loss=8.6365, val_loss=11.9101, \n",
            "Epoch 4226/6000: train_loss=8.5138, val_loss=9.2815, \n",
            "Epoch 4227/6000: train_loss=8.0387, val_loss=10.7574, \n",
            "Epoch 4228/6000: train_loss=7.8904, val_loss=9.0537, \n",
            "Epoch 4229/6000: train_loss=7.8677, val_loss=11.0079, \n",
            "Epoch 4230/6000: train_loss=7.4161, val_loss=9.2611, \n",
            "Epoch 4231/6000: train_loss=7.3570, val_loss=9.7051, \n",
            "Epoch 4232/6000: train_loss=7.2144, val_loss=9.2637, \n",
            "Epoch 4233/6000: train_loss=7.3683, val_loss=8.9562, \n",
            "Epoch 4234/6000: train_loss=7.4607, val_loss=10.1392, \n",
            "Epoch 4235/6000: train_loss=7.5160, val_loss=8.8776, \n",
            "Epoch 4236/6000: train_loss=7.7220, val_loss=10.4444, \n",
            "Epoch 4237/6000: train_loss=7.5494, val_loss=8.8987, \n",
            "Epoch 4238/6000: train_loss=7.9146, val_loss=10.8048, \n",
            "Epoch 4239/6000: train_loss=7.7662, val_loss=8.9729, \n",
            "Epoch 4240/6000: train_loss=8.5767, val_loss=11.8151, \n",
            "Epoch 4241/6000: train_loss=9.3999, val_loss=9.9688, \n",
            "Epoch 4242/6000: train_loss=8.5518, val_loss=11.8166, \n",
            "Epoch 4243/6000: train_loss=7.7079, val_loss=8.7856, \n",
            "Epoch 4244/6000: train_loss=7.3063, val_loss=8.9634, \n",
            "Epoch 4245/6000: train_loss=7.9061, val_loss=10.2816, \n",
            "Epoch 4246/6000: train_loss=7.9650, val_loss=9.1077, \n",
            "Epoch 4247/6000: train_loss=8.9044, val_loss=12.6926, \n",
            "Epoch 4248/6000: train_loss=9.0169, val_loss=9.9069, \n",
            "Epoch 4249/6000: train_loss=10.0410, val_loss=13.1260, \n",
            "Epoch 4250/6000: train_loss=9.9456, val_loss=9.9965, \n",
            "Epoch 4251/6000: train_loss=8.1515, val_loss=11.2888, \n",
            "Epoch 4252/6000: train_loss=7.6523, val_loss=9.3054, \n",
            "Epoch 4253/6000: train_loss=7.2356, val_loss=9.0446, \n",
            "Epoch 4254/6000: train_loss=7.3365, val_loss=9.2555, \n",
            "Epoch 4255/6000: train_loss=7.6879, val_loss=8.7135, \n",
            "Epoch 4256/6000: train_loss=7.7151, val_loss=10.8914, \n",
            "Epoch 4257/6000: train_loss=7.5224, val_loss=9.0960, \n",
            "Epoch 4258/6000: train_loss=7.4173, val_loss=9.7070, \n",
            "Epoch 4259/6000: train_loss=7.7295, val_loss=9.0352, \n",
            "Epoch 4260/6000: train_loss=7.3401, val_loss=10.0264, \n",
            "Epoch 4261/6000: train_loss=7.2245, val_loss=8.9780, \n",
            "Epoch 4262/6000: train_loss=7.2008, val_loss=8.7840, \n",
            "Epoch 4263/6000: train_loss=7.1518, val_loss=9.1784, \n",
            "Epoch 4264/6000: train_loss=7.6401, val_loss=9.4126, \n",
            "Epoch 4265/6000: train_loss=7.6847, val_loss=10.4460, \n",
            "Epoch 4266/6000: train_loss=7.6918, val_loss=8.7816, \n",
            "Epoch 4267/6000: train_loss=7.2056, val_loss=9.4441, \n",
            "Epoch 4268/6000: train_loss=7.1618, val_loss=9.3767, \n",
            "Epoch 4269/6000: train_loss=7.2070, val_loss=8.9696, \n",
            "Epoch 4270/6000: train_loss=7.4625, val_loss=9.9890, \n",
            "Epoch 4271/6000: train_loss=7.4332, val_loss=9.0410, \n",
            "Epoch 4272/6000: train_loss=7.1574, val_loss=9.1582, \n",
            "Epoch 4273/6000: train_loss=7.2819, val_loss=9.5817, \n",
            "Epoch 4274/6000: train_loss=7.5360, val_loss=8.8581, \n",
            "Epoch 4275/6000: train_loss=7.1642, val_loss=9.2617, \n",
            "Epoch 4276/6000: train_loss=7.1467, val_loss=9.1384, \n",
            "Epoch 4277/6000: train_loss=7.2379, val_loss=9.0116, \n",
            "Epoch 4278/6000: train_loss=7.1928, val_loss=9.6355, \n",
            "Epoch 4279/6000: train_loss=7.1855, val_loss=9.6928, \n",
            "Epoch 4280/6000: train_loss=7.1807, val_loss=8.9512, \n",
            "Epoch 4281/6000: train_loss=7.1753, val_loss=9.2337, \n",
            "Epoch 4282/6000: train_loss=7.3470, val_loss=9.0863, \n",
            "Epoch 4283/6000: train_loss=7.1501, val_loss=9.4781, \n",
            "Epoch 4284/6000: train_loss=7.1521, val_loss=8.9882, \n",
            "Epoch 4285/6000: train_loss=7.1479, val_loss=9.0832, \n",
            "Epoch 4286/6000: train_loss=7.1773, val_loss=9.2647, \n",
            "Epoch 4287/6000: train_loss=7.2175, val_loss=9.6520, \n",
            "Epoch 4288/6000: train_loss=7.1599, val_loss=9.0081, \n",
            "Epoch 4289/6000: train_loss=7.4883, val_loss=8.7643, \n",
            "Epoch 4290/6000: train_loss=7.8341, val_loss=11.1496, \n",
            "Epoch 4291/6000: train_loss=7.1896, val_loss=9.2959, \n",
            "Epoch 4292/6000: train_loss=7.2369, val_loss=9.2296, \n",
            "Epoch 4293/6000: train_loss=7.1527, val_loss=9.2495, \n",
            "Epoch 4294/6000: train_loss=7.9389, val_loss=9.5198, \n",
            "Epoch 4295/6000: train_loss=7.6601, val_loss=10.6111, \n",
            "Epoch 4296/6000: train_loss=8.3770, val_loss=8.8114, \n",
            "Epoch 4297/6000: train_loss=8.1277, val_loss=10.4016, \n",
            "Epoch 4298/6000: train_loss=7.8667, val_loss=9.0944, \n",
            "Epoch 4299/6000: train_loss=7.7635, val_loss=11.0178, \n",
            "Epoch 4300/6000: train_loss=7.4735, val_loss=8.8837, \n",
            "Epoch 4301/6000: train_loss=7.1773, val_loss=8.7281, \n",
            "Epoch 4302/6000: train_loss=7.1837, val_loss=9.4580, \n",
            "Epoch 4303/6000: train_loss=7.4082, val_loss=8.9809, \n",
            "Epoch 4304/6000: train_loss=7.2668, val_loss=9.0680, \n",
            "Epoch 4305/6000: train_loss=7.8626, val_loss=8.8758, \n",
            "Epoch 4306/6000: train_loss=8.4391, val_loss=11.9223, \n",
            "Epoch 4307/6000: train_loss=9.5883, val_loss=10.3389, \n",
            "Epoch 4308/6000: train_loss=10.1694, val_loss=13.3905, \n",
            "Epoch 4309/6000: train_loss=8.6886, val_loss=9.4622, \n",
            "Epoch 4310/6000: train_loss=7.8576, val_loss=10.8234, \n",
            "Epoch 4311/6000: train_loss=7.1622, val_loss=8.6260, \n",
            "Epoch 4312/6000: train_loss=7.1632, val_loss=8.7072, \n",
            "Epoch 4313/6000: train_loss=7.1228, val_loss=8.9812, \n",
            "Epoch 4314/6000: train_loss=7.9776, val_loss=9.4530, \n",
            "Epoch 4315/6000: train_loss=7.9536, val_loss=11.2107, \n",
            "Epoch 4316/6000: train_loss=7.7295, val_loss=8.6560, \n",
            "Epoch 4317/6000: train_loss=7.4515, val_loss=9.5069, \n",
            "Epoch 4318/6000: train_loss=7.9099, val_loss=9.1801, \n",
            "Epoch 4319/6000: train_loss=8.3931, val_loss=11.7541, \n",
            "Epoch 4320/6000: train_loss=8.0964, val_loss=8.9798, \n",
            "Epoch 4321/6000: train_loss=7.3785, val_loss=9.6915, \n",
            "Epoch 4322/6000: train_loss=7.1125, val_loss=9.4436, \n",
            "Epoch 4323/6000: train_loss=7.3516, val_loss=9.3520, \n",
            "Epoch 4324/6000: train_loss=7.4091, val_loss=10.0450, \n",
            "Epoch 4325/6000: train_loss=7.6810, val_loss=8.5965, \n",
            "Epoch 4326/6000: train_loss=7.4776, val_loss=9.8880, \n",
            "Epoch 4327/6000: train_loss=7.6137, val_loss=9.4045, \n",
            "Epoch 4328/6000: train_loss=7.4187, val_loss=10.0816, \n",
            "Epoch 4329/6000: train_loss=7.6553, val_loss=8.4283, \n",
            "Epoch 4330/6000: train_loss=7.1157, val_loss=8.9394, \n",
            "Epoch 4331/6000: train_loss=7.2158, val_loss=9.7372, \n",
            "Epoch 4332/6000: train_loss=7.3013, val_loss=8.8042, \n",
            "Epoch 4333/6000: train_loss=7.1454, val_loss=8.6137, \n",
            "Epoch 4334/6000: train_loss=7.0925, val_loss=8.9488, \n",
            "Epoch 4335/6000: train_loss=7.1120, val_loss=9.4687, \n",
            "Epoch 4336/6000: train_loss=7.1010, val_loss=9.1738, \n",
            "Epoch 4337/6000: train_loss=7.2591, val_loss=8.6825, \n",
            "Epoch 4338/6000: train_loss=7.5023, val_loss=9.9375, \n",
            "Epoch 4339/6000: train_loss=7.2211, val_loss=8.9972, \n",
            "Epoch 4340/6000: train_loss=7.2812, val_loss=9.1704, \n",
            "Epoch 4341/6000: train_loss=7.0830, val_loss=9.2596, \n",
            "Epoch 4342/6000: train_loss=7.0841, val_loss=8.8105, \n",
            "Epoch 4343/6000: train_loss=7.0828, val_loss=8.8851, \n",
            "Epoch 4344/6000: train_loss=7.1278, val_loss=9.1523, \n",
            "Epoch 4345/6000: train_loss=7.3315, val_loss=9.1889, \n",
            "Epoch 4346/6000: train_loss=7.1037, val_loss=9.5840, \n",
            "Epoch 4347/6000: train_loss=7.0727, val_loss=8.9608, \n",
            "Epoch 4348/6000: train_loss=7.2725, val_loss=9.1032, \n",
            "Epoch 4349/6000: train_loss=7.5807, val_loss=8.6804, \n",
            "Epoch 4350/6000: train_loss=7.5105, val_loss=10.4868, \n",
            "Epoch 4351/6000: train_loss=7.8044, val_loss=9.0464, \n",
            "Epoch 4352/6000: train_loss=7.4096, val_loss=9.5987, \n",
            "Epoch 4353/6000: train_loss=7.1442, val_loss=8.8307, \n",
            "Epoch 4354/6000: train_loss=7.1546, val_loss=9.7245, \n",
            "Epoch 4355/6000: train_loss=7.4308, val_loss=10.0569, \n",
            "Epoch 4356/6000: train_loss=7.3334, val_loss=8.5464, \n",
            "Epoch 4357/6000: train_loss=7.3666, val_loss=9.7957, \n",
            "Epoch 4358/6000: train_loss=7.1535, val_loss=9.2218, \n",
            "Epoch 4359/6000: train_loss=7.0861, val_loss=9.1791, \n",
            "Epoch 4360/6000: train_loss=7.0741, val_loss=8.8137, \n",
            "Epoch 4361/6000: train_loss=7.0927, val_loss=9.5193, \n",
            "Epoch 4362/6000: train_loss=7.0707, val_loss=9.1435, \n",
            "Epoch 4363/6000: train_loss=7.2024, val_loss=9.2822, \n",
            "Epoch 4364/6000: train_loss=7.1781, val_loss=9.2657, \n",
            "Epoch 4365/6000: train_loss=7.0850, val_loss=9.1816, \n",
            "Epoch 4366/6000: train_loss=7.1047, val_loss=9.4342, \n",
            "Epoch 4367/6000: train_loss=7.1142, val_loss=9.1915, \n",
            "Epoch 4368/6000: train_loss=7.2457, val_loss=8.6726, \n",
            "Epoch 4369/6000: train_loss=7.1804, val_loss=9.8620, \n",
            "Epoch 4370/6000: train_loss=7.1391, val_loss=9.4973, \n",
            "Epoch 4371/6000: train_loss=7.1053, val_loss=8.5690, \n",
            "Epoch 4372/6000: train_loss=7.1241, val_loss=8.2928, \n",
            "Epoch 4373/6000: train_loss=7.1079, val_loss=8.8262, \n",
            "Epoch 4374/6000: train_loss=7.2436, val_loss=9.4062, \n",
            "Epoch 4375/6000: train_loss=7.8519, val_loss=10.7967, \n",
            "Epoch 4376/6000: train_loss=7.2783, val_loss=8.4464, \n",
            "Epoch 4377/6000: train_loss=7.4026, val_loss=9.7919, \n",
            "Epoch 4378/6000: train_loss=7.1622, val_loss=9.2455, \n",
            "Epoch 4379/6000: train_loss=7.2954, val_loss=8.9920, \n",
            "Epoch 4380/6000: train_loss=7.3130, val_loss=9.5086, \n",
            "Epoch 4381/6000: train_loss=7.0459, val_loss=8.6994, \n",
            "Epoch 4382/6000: train_loss=7.0578, val_loss=8.6563, \n",
            "Epoch 4383/6000: train_loss=7.2019, val_loss=9.4085, \n",
            "Epoch 4384/6000: train_loss=7.2395, val_loss=8.8971, \n",
            "Epoch 4385/6000: train_loss=7.2992, val_loss=9.7774, \n",
            "Epoch 4386/6000: train_loss=7.1417, val_loss=8.5896, \n",
            "Epoch 4387/6000: train_loss=7.2791, val_loss=9.7295, \n",
            "Epoch 4388/6000: train_loss=7.3416, val_loss=8.9079, \n",
            "Epoch 4389/6000: train_loss=7.0599, val_loss=8.7864, \n",
            "Epoch 4390/6000: train_loss=7.3065, val_loss=9.5650, \n",
            "Epoch 4391/6000: train_loss=7.3990, val_loss=8.6996, \n",
            "Epoch 4392/6000: train_loss=7.3073, val_loss=9.8986, \n",
            "Epoch 4393/6000: train_loss=7.2706, val_loss=8.8183, \n",
            "Epoch 4394/6000: train_loss=7.0169, val_loss=8.9581, \n",
            "Epoch 4395/6000: train_loss=7.1773, val_loss=9.6628, \n",
            "Epoch 4396/6000: train_loss=7.0810, val_loss=8.6821, \n",
            "Epoch 4397/6000: train_loss=7.2948, val_loss=9.3152, \n",
            "Epoch 4398/6000: train_loss=7.2959, val_loss=8.6794, \n",
            "Epoch 4399/6000: train_loss=7.3659, val_loss=10.2785, \n",
            "Epoch 4400/6000: train_loss=7.0135, val_loss=9.1435, \n",
            "Epoch 4401/6000: train_loss=7.2519, val_loss=8.5432, \n",
            "Epoch 4402/6000: train_loss=7.5287, val_loss=9.8299, \n",
            "Epoch 4403/6000: train_loss=7.7739, val_loss=9.2248, \n",
            "Epoch 4404/6000: train_loss=7.1944, val_loss=9.6809, \n",
            "Epoch 4405/6000: train_loss=7.0584, val_loss=8.5822, \n",
            "Epoch 4406/6000: train_loss=7.0143, val_loss=8.9900, \n",
            "Epoch 4407/6000: train_loss=7.0345, val_loss=9.1965, \n",
            "Epoch 4408/6000: train_loss=7.1535, val_loss=8.7486, \n",
            "Epoch 4409/6000: train_loss=7.4780, val_loss=9.7452, \n",
            "Epoch 4410/6000: train_loss=7.0033, val_loss=8.7866, \n",
            "Epoch 4411/6000: train_loss=7.0009, val_loss=8.9970, \n",
            "Epoch 4412/6000: train_loss=7.0047, val_loss=9.0975, \n",
            "Epoch 4413/6000: train_loss=7.0455, val_loss=9.2225, \n",
            "Epoch 4414/6000: train_loss=7.0086, val_loss=8.7993, \n",
            "Epoch 4415/6000: train_loss=7.0005, val_loss=8.8717, \n",
            "Epoch 4416/6000: train_loss=6.9914, val_loss=9.1109, \n",
            "Epoch 4417/6000: train_loss=7.0094, val_loss=8.9722, \n",
            "Epoch 4418/6000: train_loss=7.1733, val_loss=9.5143, \n",
            "Epoch 4419/6000: train_loss=6.9974, val_loss=9.0721, \n",
            "Epoch 4420/6000: train_loss=7.0000, val_loss=9.0408, \n",
            "Epoch 4421/6000: train_loss=7.0853, val_loss=8.5932, \n",
            "Epoch 4422/6000: train_loss=7.1129, val_loss=9.4575, \n",
            "Epoch 4423/6000: train_loss=7.4146, val_loss=8.9191, \n",
            "Epoch 4424/6000: train_loss=7.0433, val_loss=9.1676, \n",
            "Epoch 4425/6000: train_loss=6.9820, val_loss=8.9213, \n",
            "Epoch 4426/6000: train_loss=6.9988, val_loss=9.1601, \n",
            "Epoch 4427/6000: train_loss=7.0021, val_loss=9.0354, \n",
            "Epoch 4428/6000: train_loss=7.0657, val_loss=8.6114, \n",
            "Epoch 4429/6000: train_loss=7.4711, val_loss=10.2412, \n",
            "Epoch 4430/6000: train_loss=7.7785, val_loss=8.9921, \n",
            "Epoch 4431/6000: train_loss=7.8462, val_loss=10.7120, \n",
            "Epoch 4432/6000: train_loss=7.2635, val_loss=8.8087, \n",
            "Epoch 4433/6000: train_loss=7.1427, val_loss=9.4980, \n",
            "Epoch 4434/6000: train_loss=7.0543, val_loss=8.6006, \n",
            "Epoch 4435/6000: train_loss=7.2983, val_loss=9.7697, \n",
            "Epoch 4436/6000: train_loss=6.9825, val_loss=9.2094, \n",
            "Epoch 4437/6000: train_loss=6.9801, val_loss=9.0614, \n",
            "Epoch 4438/6000: train_loss=7.1501, val_loss=9.1929, \n",
            "Epoch 4439/6000: train_loss=7.3476, val_loss=8.3559, \n",
            "Epoch 4440/6000: train_loss=8.2344, val_loss=11.2104, \n",
            "Epoch 4441/6000: train_loss=7.9059, val_loss=8.6224, \n",
            "Epoch 4442/6000: train_loss=8.7358, val_loss=11.3886, \n",
            "Epoch 4443/6000: train_loss=7.6734, val_loss=8.7770, \n",
            "Epoch 4444/6000: train_loss=8.5874, val_loss=11.6998, \n",
            "Epoch 4445/6000: train_loss=7.5224, val_loss=8.7037, \n",
            "Epoch 4446/6000: train_loss=7.6161, val_loss=10.0132, \n",
            "Epoch 4447/6000: train_loss=7.2512, val_loss=8.5234, \n",
            "Epoch 4448/6000: train_loss=7.0077, val_loss=9.2139, \n",
            "Epoch 4449/6000: train_loss=7.1902, val_loss=9.7521, \n",
            "Epoch 4450/6000: train_loss=7.1063, val_loss=8.5253, \n",
            "Epoch 4451/6000: train_loss=7.2362, val_loss=9.6654, \n",
            "Epoch 4452/6000: train_loss=7.7427, val_loss=9.0746, \n",
            "Epoch 4453/6000: train_loss=7.3537, val_loss=9.8188, \n",
            "Epoch 4454/6000: train_loss=7.8557, val_loss=8.7136, \n",
            "Epoch 4455/6000: train_loss=7.5542, val_loss=10.2279, \n",
            "Epoch 4456/6000: train_loss=7.2299, val_loss=8.8329, \n",
            "Epoch 4457/6000: train_loss=7.4428, val_loss=9.8874, \n",
            "Epoch 4458/6000: train_loss=7.9415, val_loss=9.0431, \n",
            "Epoch 4459/6000: train_loss=7.5695, val_loss=10.2135, \n",
            "Epoch 4460/6000: train_loss=7.2200, val_loss=8.7449, \n",
            "Epoch 4461/6000: train_loss=7.0766, val_loss=8.5820, \n",
            "Epoch 4462/6000: train_loss=7.0493, val_loss=9.2412, \n",
            "Epoch 4463/6000: train_loss=8.1313, val_loss=8.9820, \n",
            "Epoch 4464/6000: train_loss=7.4445, val_loss=9.9797, \n",
            "Epoch 4465/6000: train_loss=7.3828, val_loss=8.5259, \n",
            "Epoch 4466/6000: train_loss=7.1221, val_loss=9.5283, \n",
            "Epoch 4467/6000: train_loss=7.5543, val_loss=8.7770, \n",
            "Epoch 4468/6000: train_loss=7.0865, val_loss=9.3528, \n",
            "Epoch 4469/6000: train_loss=7.2127, val_loss=8.5240, \n",
            "Epoch 4470/6000: train_loss=6.9715, val_loss=9.1742, \n",
            "Epoch 4471/6000: train_loss=7.0265, val_loss=8.9678, \n",
            "Epoch 4472/6000: train_loss=6.9471, val_loss=9.0509, \n",
            "Epoch 4473/6000: train_loss=7.0574, val_loss=9.2960, \n",
            "Epoch 4474/6000: train_loss=7.2967, val_loss=8.4767, \n",
            "Epoch 4475/6000: train_loss=7.9130, val_loss=10.3936, \n",
            "Epoch 4476/6000: train_loss=7.3943, val_loss=8.7843, \n",
            "Epoch 4477/6000: train_loss=7.2205, val_loss=9.9714, \n",
            "Epoch 4478/6000: train_loss=6.9515, val_loss=8.8678, \n",
            "Epoch 4479/6000: train_loss=6.9271, val_loss=8.8741, \n",
            "Epoch 4480/6000: train_loss=6.9338, val_loss=8.9388, \n",
            "Epoch 4481/6000: train_loss=6.9573, val_loss=8.9435, \n",
            "Epoch 4482/6000: train_loss=6.9496, val_loss=8.6060, \n",
            "Epoch 4483/6000: train_loss=6.9581, val_loss=8.6640, \n",
            "Epoch 4484/6000: train_loss=6.9471, val_loss=9.2940, \n",
            "Epoch 4485/6000: train_loss=6.9341, val_loss=9.1190, \n",
            "Epoch 4486/6000: train_loss=6.9369, val_loss=8.7776, \n",
            "Epoch 4487/6000: train_loss=6.9658, val_loss=8.4963, \n",
            "Epoch 4488/6000: train_loss=7.0739, val_loss=9.4852, \n",
            "Epoch 4489/6000: train_loss=7.2678, val_loss=8.8651, \n",
            "Epoch 4490/6000: train_loss=7.0012, val_loss=9.1766, \n",
            "Epoch 4491/6000: train_loss=7.1277, val_loss=8.3119, \n",
            "Epoch 4492/6000: train_loss=6.9302, val_loss=8.6947, \n",
            "Epoch 4493/6000: train_loss=7.0508, val_loss=9.5358, \n",
            "Epoch 4494/6000: train_loss=6.9577, val_loss=8.6196, \n",
            "Epoch 4495/6000: train_loss=6.9849, val_loss=8.9112, \n",
            "Epoch 4496/6000: train_loss=6.9934, val_loss=8.6991, \n",
            "Epoch 4497/6000: train_loss=6.9272, val_loss=9.1178, \n",
            "Epoch 4498/6000: train_loss=6.9028, val_loss=8.7639, \n",
            "Epoch 4499/6000: train_loss=6.9448, val_loss=8.7010, \n",
            "Epoch 4500/6000: train_loss=6.9233, val_loss=8.7160, \n",
            "Epoch 4501/6000: train_loss=6.9994, val_loss=8.9801, \n",
            "Epoch 4502/6000: train_loss=7.0451, val_loss=9.4146, \n",
            "Epoch 4503/6000: train_loss=7.0760, val_loss=8.4409, \n",
            "Epoch 4504/6000: train_loss=6.9657, val_loss=9.0555, \n",
            "Epoch 4505/6000: train_loss=6.9367, val_loss=8.7485, \n",
            "Epoch 4506/6000: train_loss=7.0922, val_loss=9.3398, \n",
            "Epoch 4507/6000: train_loss=7.1029, val_loss=8.4581, \n",
            "Epoch 4508/6000: train_loss=6.9023, val_loss=8.8651, \n",
            "Epoch 4509/6000: train_loss=6.9431, val_loss=9.2006, \n",
            "Epoch 4510/6000: train_loss=6.9984, val_loss=8.6056, \n",
            "Epoch 4511/6000: train_loss=7.0000, val_loss=9.1091, \n",
            "Epoch 4512/6000: train_loss=7.4528, val_loss=8.5840, \n",
            "Epoch 4513/6000: train_loss=7.2217, val_loss=9.8935, \n",
            "Epoch 4514/6000: train_loss=7.1623, val_loss=8.5877, \n",
            "Epoch 4515/6000: train_loss=6.9749, val_loss=9.0354, \n",
            "Epoch 4516/6000: train_loss=6.9133, val_loss=9.0486, \n",
            "Epoch 4517/6000: train_loss=6.9871, val_loss=8.9760, \n",
            "Epoch 4518/6000: train_loss=7.1490, val_loss=9.6185, \n",
            "Epoch 4519/6000: train_loss=7.1973, val_loss=8.3083, \n",
            "Epoch 4520/6000: train_loss=7.1030, val_loss=9.1234, \n",
            "Epoch 4521/6000: train_loss=6.8966, val_loss=9.0909, \n",
            "Epoch 4522/6000: train_loss=6.9661, val_loss=9.0817, \n",
            "Epoch 4523/6000: train_loss=6.9533, val_loss=8.5888, \n",
            "Epoch 4524/6000: train_loss=6.9634, val_loss=8.2942, \n",
            "Epoch 4525/6000: train_loss=6.9470, val_loss=9.3946, \n",
            "Epoch 4526/6000: train_loss=6.9857, val_loss=9.4752, \n",
            "Epoch 4527/6000: train_loss=7.0289, val_loss=8.3126, \n",
            "Epoch 4528/6000: train_loss=7.1284, val_loss=9.3096, \n",
            "Epoch 4529/6000: train_loss=6.9207, val_loss=8.9094, \n",
            "Epoch 4530/6000: train_loss=6.8829, val_loss=8.7410, \n",
            "Epoch 4531/6000: train_loss=6.8968, val_loss=8.5773, \n",
            "Epoch 4532/6000: train_loss=6.8739, val_loss=8.7013, \n",
            "Epoch 4533/6000: train_loss=6.8864, val_loss=8.6022, \n",
            "Epoch 4534/6000: train_loss=7.0523, val_loss=9.3085, \n",
            "Epoch 4535/6000: train_loss=6.9098, val_loss=8.4044, \n",
            "Epoch 4536/6000: train_loss=6.8813, val_loss=8.5106, \n",
            "Epoch 4537/6000: train_loss=6.8847, val_loss=8.8000, \n",
            "Epoch 4538/6000: train_loss=6.9026, val_loss=9.1942, \n",
            "Epoch 4539/6000: train_loss=6.8733, val_loss=8.9649, \n",
            "Epoch 4540/6000: train_loss=7.0164, val_loss=8.3820, \n",
            "Epoch 4541/6000: train_loss=6.9527, val_loss=8.8006, \n",
            "Epoch 4542/6000: train_loss=6.9703, val_loss=8.3653, \n",
            "Epoch 4543/6000: train_loss=7.0486, val_loss=9.3418, \n",
            "Epoch 4544/6000: train_loss=6.9075, val_loss=8.5019, \n",
            "Epoch 4545/6000: train_loss=7.1882, val_loss=9.4221, \n",
            "Epoch 4546/6000: train_loss=7.1867, val_loss=8.9724, \n",
            "Epoch 4547/6000: train_loss=7.0301, val_loss=9.5061, \n",
            "Epoch 4548/6000: train_loss=7.1198, val_loss=8.2488, \n",
            "Epoch 4549/6000: train_loss=6.8837, val_loss=8.3840, \n",
            "Epoch 4550/6000: train_loss=6.9485, val_loss=9.2322, \n",
            "Epoch 4551/6000: train_loss=6.8552, val_loss=8.7825, \n",
            "Epoch 4552/6000: train_loss=6.8603, val_loss=8.5387, \n",
            "Epoch 4553/6000: train_loss=6.8491, val_loss=8.7747, \n",
            "Epoch 4554/6000: train_loss=6.8675, val_loss=8.5661, \n",
            "Epoch 4555/6000: train_loss=6.8691, val_loss=8.7131, \n",
            "Epoch 4556/6000: train_loss=6.8468, val_loss=8.7645, \n",
            "Epoch 4557/6000: train_loss=6.8573, val_loss=8.9984, \n",
            "Epoch 4558/6000: train_loss=6.8453, val_loss=8.6179, \n",
            "Epoch 4559/6000: train_loss=6.9876, val_loss=8.8989, \n",
            "Epoch 4560/6000: train_loss=6.8620, val_loss=8.3980, \n",
            "Epoch 4561/6000: train_loss=6.9722, val_loss=9.2569, \n",
            "Epoch 4562/6000: train_loss=6.9613, val_loss=8.6460, \n",
            "Epoch 4563/6000: train_loss=7.3049, val_loss=9.7634, \n",
            "Epoch 4564/6000: train_loss=7.0878, val_loss=8.3932, \n",
            "Epoch 4565/6000: train_loss=7.4674, val_loss=9.9549, \n",
            "Epoch 4566/6000: train_loss=8.3328, val_loss=9.1304, \n",
            "Epoch 4567/6000: train_loss=7.2235, val_loss=10.0111, \n",
            "Epoch 4568/6000: train_loss=7.1873, val_loss=8.4164, \n",
            "Epoch 4569/6000: train_loss=6.9214, val_loss=8.1955, \n",
            "Epoch 4570/6000: train_loss=7.9209, val_loss=10.6117, \n",
            "Epoch 4571/6000: train_loss=8.5164, val_loss=8.8980, \n",
            "Epoch 4572/6000: train_loss=9.1663, val_loss=12.1438, \n",
            "Epoch 4573/6000: train_loss=8.9941, val_loss=9.5691, \n",
            "Epoch 4574/6000: train_loss=7.6970, val_loss=10.6768, \n",
            "Epoch 4575/6000: train_loss=7.5217, val_loss=8.7771, \n",
            "Epoch 4576/6000: train_loss=7.1040, val_loss=9.1278, \n",
            "Epoch 4577/6000: train_loss=6.8620, val_loss=8.2080, \n",
            "Epoch 4578/6000: train_loss=6.8329, val_loss=8.9195, \n",
            "Epoch 4579/6000: train_loss=7.2585, val_loss=10.0965, \n",
            "Epoch 4580/6000: train_loss=6.9870, val_loss=8.4055, \n",
            "Epoch 4581/6000: train_loss=6.9013, val_loss=8.8121, \n",
            "Epoch 4582/6000: train_loss=6.9359, val_loss=8.8721, \n",
            "Epoch 4583/6000: train_loss=6.9797, val_loss=9.0486, \n",
            "Epoch 4584/6000: train_loss=6.9122, val_loss=8.1198, \n",
            "Epoch 4585/6000: train_loss=6.9856, val_loss=9.2156, \n",
            "Epoch 4586/6000: train_loss=7.2212, val_loss=8.9716, \n",
            "Epoch 4587/6000: train_loss=6.8170, val_loss=8.9291, \n",
            "Epoch 4588/6000: train_loss=6.8513, val_loss=8.2870, \n",
            "Epoch 4589/6000: train_loss=6.8993, val_loss=8.2547, \n",
            "Epoch 4590/6000: train_loss=7.1052, val_loss=9.1167, \n",
            "Epoch 4591/6000: train_loss=6.8718, val_loss=9.0113, \n",
            "Epoch 4592/6000: train_loss=6.9556, val_loss=8.4515, \n",
            "Epoch 4593/6000: train_loss=6.8858, val_loss=8.3607, \n",
            "Epoch 4594/6000: train_loss=6.8971, val_loss=9.3880, \n",
            "Epoch 4595/6000: train_loss=6.8630, val_loss=9.1133, \n",
            "Epoch 4596/6000: train_loss=6.8190, val_loss=8.4293, \n",
            "Epoch 4597/6000: train_loss=6.8410, val_loss=8.1980, \n",
            "Epoch 4598/6000: train_loss=6.8286, val_loss=8.7268, \n",
            "Epoch 4599/6000: train_loss=6.8140, val_loss=8.6885, \n",
            "Epoch 4600/6000: train_loss=6.8086, val_loss=8.7162, \n",
            "Epoch 4601/6000: train_loss=6.8218, val_loss=8.6094, \n",
            "Epoch 4602/6000: train_loss=6.9022, val_loss=9.3183, \n",
            "Epoch 4603/6000: train_loss=6.9716, val_loss=8.5646, \n",
            "Epoch 4604/6000: train_loss=6.8522, val_loss=8.7316, \n",
            "Epoch 4605/6000: train_loss=6.7997, val_loss=8.9032, \n",
            "Epoch 4606/6000: train_loss=6.8911, val_loss=9.2887, \n",
            "Epoch 4607/6000: train_loss=6.8150, val_loss=8.5799, \n",
            "Epoch 4608/6000: train_loss=6.7878, val_loss=8.7813, \n",
            "Epoch 4609/6000: train_loss=6.7883, val_loss=8.7481, \n",
            "Epoch 4610/6000: train_loss=6.8283, val_loss=8.5411, \n",
            "Epoch 4611/6000: train_loss=6.9209, val_loss=9.0342, \n",
            "Epoch 4612/6000: train_loss=7.3017, val_loss=8.4786, \n",
            "Epoch 4613/6000: train_loss=7.2851, val_loss=10.0218, \n",
            "Epoch 4614/6000: train_loss=6.8538, val_loss=9.2013, \n",
            "Epoch 4615/6000: train_loss=6.8048, val_loss=8.3686, \n",
            "Epoch 4616/6000: train_loss=6.9670, val_loss=8.8185, \n",
            "Epoch 4617/6000: train_loss=6.8823, val_loss=8.8714, \n",
            "Epoch 4618/6000: train_loss=6.9027, val_loss=9.0468, \n",
            "Epoch 4619/6000: train_loss=6.8169, val_loss=8.5407, \n",
            "Epoch 4620/6000: train_loss=6.9391, val_loss=8.5027, \n",
            "Epoch 4621/6000: train_loss=7.1513, val_loss=8.2911, \n",
            "Epoch 4622/6000: train_loss=6.8772, val_loss=9.4605, \n",
            "Epoch 4623/6000: train_loss=6.7759, val_loss=8.9810, \n",
            "Epoch 4624/6000: train_loss=6.9800, val_loss=8.1476, \n",
            "Epoch 4625/6000: train_loss=6.8855, val_loss=8.7580, \n",
            "Epoch 4626/6000: train_loss=6.8115, val_loss=8.9073, \n",
            "Epoch 4627/6000: train_loss=6.7964, val_loss=9.0976, \n",
            "Epoch 4628/6000: train_loss=6.8055, val_loss=8.4244, \n",
            "Epoch 4629/6000: train_loss=6.7883, val_loss=8.4532, \n",
            "Epoch 4630/6000: train_loss=6.8050, val_loss=9.0807, \n",
            "Epoch 4631/6000: train_loss=6.7695, val_loss=8.6772, \n",
            "Epoch 4632/6000: train_loss=6.7621, val_loss=8.5255, \n",
            "Epoch 4633/6000: train_loss=6.7888, val_loss=8.8076, \n",
            "Epoch 4634/6000: train_loss=7.5097, val_loss=8.9789, \n",
            "Epoch 4635/6000: train_loss=7.1700, val_loss=9.6637, \n",
            "Epoch 4636/6000: train_loss=7.6465, val_loss=8.4181, \n",
            "Epoch 4637/6000: train_loss=7.9808, val_loss=10.8357, \n",
            "Epoch 4638/6000: train_loss=7.2782, val_loss=8.4655, \n",
            "Epoch 4639/6000: train_loss=6.7949, val_loss=8.8280, \n",
            "Epoch 4640/6000: train_loss=6.8032, val_loss=8.9544, \n",
            "Epoch 4641/6000: train_loss=6.9372, val_loss=8.3335, \n",
            "Epoch 4642/6000: train_loss=6.9186, val_loss=9.1715, \n",
            "Epoch 4643/6000: train_loss=6.9184, val_loss=8.9028, \n",
            "Epoch 4644/6000: train_loss=7.0912, val_loss=9.7262, \n",
            "Epoch 4645/6000: train_loss=6.8527, val_loss=8.3057, \n",
            "Epoch 4646/6000: train_loss=7.1432, val_loss=9.4084, \n",
            "Epoch 4647/6000: train_loss=7.9947, val_loss=8.7288, \n",
            "Epoch 4648/6000: train_loss=8.2894, val_loss=11.4603, \n",
            "Epoch 4649/6000: train_loss=7.4578, val_loss=8.6862, \n",
            "Epoch 4650/6000: train_loss=7.6470, val_loss=10.2121, \n",
            "Epoch 4651/6000: train_loss=6.8076, val_loss=8.4793, \n",
            "Epoch 4652/6000: train_loss=6.7463, val_loss=8.6642, \n",
            "Epoch 4653/6000: train_loss=6.7939, val_loss=8.6339, \n",
            "Epoch 4654/6000: train_loss=6.7381, val_loss=8.6302, \n",
            "Epoch 4655/6000: train_loss=6.7558, val_loss=8.9807, \n",
            "Epoch 4656/6000: train_loss=6.8042, val_loss=8.6442, \n",
            "Epoch 4657/6000: train_loss=6.8442, val_loss=8.6697, \n",
            "Epoch 4658/6000: train_loss=6.9510, val_loss=8.7095, \n",
            "Epoch 4659/6000: train_loss=6.7823, val_loss=8.8216, \n",
            "Epoch 4660/6000: train_loss=6.7988, val_loss=8.3734, \n",
            "Epoch 4661/6000: train_loss=6.7899, val_loss=8.3793, \n",
            "Epoch 4662/6000: train_loss=6.9947, val_loss=8.8749, \n",
            "Epoch 4663/6000: train_loss=6.8053, val_loss=9.1614, \n",
            "Epoch 4664/6000: train_loss=6.7703, val_loss=8.5251, \n",
            "Epoch 4665/6000: train_loss=6.9044, val_loss=9.1181, \n",
            "Epoch 4666/6000: train_loss=6.8824, val_loss=8.2259, \n",
            "Epoch 4667/6000: train_loss=6.9311, val_loss=8.9996, \n",
            "Epoch 4668/6000: train_loss=6.8041, val_loss=8.6069, \n",
            "Epoch 4669/6000: train_loss=6.8400, val_loss=9.3288, \n",
            "Epoch 4670/6000: train_loss=6.7614, val_loss=8.7280, \n",
            "Epoch 4671/6000: train_loss=6.7233, val_loss=8.6949, \n",
            "Epoch 4672/6000: train_loss=6.7390, val_loss=8.4476, \n",
            "Epoch 4673/6000: train_loss=6.8314, val_loss=9.0311, \n",
            "Epoch 4674/6000: train_loss=6.7254, val_loss=8.5334, \n",
            "Epoch 4675/6000: train_loss=6.7543, val_loss=8.3151, \n",
            "Epoch 4676/6000: train_loss=6.7343, val_loss=8.5713, \n",
            "Epoch 4677/6000: train_loss=6.7545, val_loss=9.2209, \n",
            "Epoch 4678/6000: train_loss=6.9782, val_loss=8.7493, \n",
            "Epoch 4679/6000: train_loss=6.8005, val_loss=8.6191, \n",
            "Epoch 4680/6000: train_loss=6.8373, val_loss=8.0588, \n",
            "Epoch 4681/6000: train_loss=6.7682, val_loss=8.6467, \n",
            "Epoch 4682/6000: train_loss=6.7575, val_loss=9.0720, \n",
            "Epoch 4683/6000: train_loss=6.7561, val_loss=8.4857, \n",
            "Epoch 4684/6000: train_loss=6.7309, val_loss=8.5682, \n",
            "Epoch 4685/6000: train_loss=6.7569, val_loss=9.1113, \n",
            "Epoch 4686/6000: train_loss=6.7489, val_loss=8.4388, \n",
            "Epoch 4687/6000: train_loss=6.8481, val_loss=8.7745, \n",
            "Epoch 4688/6000: train_loss=6.7531, val_loss=8.2072, \n",
            "Epoch 4689/6000: train_loss=6.7758, val_loss=9.1809, \n",
            "Epoch 4690/6000: train_loss=6.9642, val_loss=8.8147, \n",
            "Epoch 4691/6000: train_loss=6.7325, val_loss=9.0852, \n",
            "Epoch 4692/6000: train_loss=6.7863, val_loss=8.1252, \n",
            "Epoch 4693/6000: train_loss=6.7732, val_loss=8.5697, \n",
            "Epoch 4694/6000: train_loss=6.8846, val_loss=8.4807, \n",
            "Epoch 4695/6000: train_loss=6.6946, val_loss=8.9226, \n",
            "Epoch 4696/6000: train_loss=6.6889, val_loss=8.6026, \n",
            "Epoch 4697/6000: train_loss=6.7302, val_loss=8.5903, \n",
            "Epoch 4698/6000: train_loss=6.9047, val_loss=8.3759, \n",
            "Epoch 4699/6000: train_loss=6.8206, val_loss=9.4498, \n",
            "Epoch 4700/6000: train_loss=6.7918, val_loss=8.5836, \n",
            "Epoch 4701/6000: train_loss=6.8786, val_loss=8.8218, \n",
            "Epoch 4702/6000: train_loss=7.4279, val_loss=8.3177, \n",
            "Epoch 4703/6000: train_loss=6.9606, val_loss=9.7214, \n",
            "Epoch 4704/6000: train_loss=6.7459, val_loss=8.9435, \n",
            "Epoch 4705/6000: train_loss=6.6824, val_loss=8.4712, \n",
            "Epoch 4706/6000: train_loss=6.7362, val_loss=8.4271, \n",
            "Epoch 4707/6000: train_loss=6.6743, val_loss=8.6664, \n",
            "Epoch 4708/6000: train_loss=6.7048, val_loss=9.0449, \n",
            "Epoch 4709/6000: train_loss=6.6780, val_loss=8.9715, \n",
            "Epoch 4710/6000: train_loss=6.8018, val_loss=8.4745, \n",
            "Epoch 4711/6000: train_loss=6.8117, val_loss=9.1502, \n",
            "Epoch 4712/6000: train_loss=6.7403, val_loss=8.3924, \n",
            "Epoch 4713/6000: train_loss=6.6975, val_loss=8.3591, \n",
            "Epoch 4714/6000: train_loss=6.7221, val_loss=8.9133, \n",
            "Epoch 4715/6000: train_loss=6.6995, val_loss=9.0686, \n",
            "Epoch 4716/6000: train_loss=7.1691, val_loss=9.9812, \n",
            "Epoch 4717/6000: train_loss=7.4609, val_loss=8.5139, \n",
            "Epoch 4718/6000: train_loss=6.7676, val_loss=8.9260, \n",
            "Epoch 4719/6000: train_loss=6.7390, val_loss=8.2792, \n",
            "Epoch 4720/6000: train_loss=6.7717, val_loss=8.7199, \n",
            "Epoch 4721/6000: train_loss=6.9222, val_loss=8.2470, \n",
            "Epoch 4722/6000: train_loss=6.7404, val_loss=9.2200, \n",
            "Epoch 4723/6000: train_loss=6.7812, val_loss=8.8609, \n",
            "Epoch 4724/6000: train_loss=6.9495, val_loss=9.2681, \n",
            "Epoch 4725/6000: train_loss=6.8253, val_loss=8.1915, \n",
            "Epoch 4726/6000: train_loss=6.6648, val_loss=8.7096, \n",
            "Epoch 4727/6000: train_loss=6.6649, val_loss=8.8913, \n",
            "Epoch 4728/6000: train_loss=6.6863, val_loss=8.4323, \n",
            "Epoch 4729/6000: train_loss=6.6755, val_loss=8.6395, \n",
            "Epoch 4730/6000: train_loss=6.7047, val_loss=8.8082, \n",
            "Epoch 4731/6000: train_loss=6.7152, val_loss=8.6662, \n",
            "Epoch 4732/6000: train_loss=6.6347, val_loss=8.6450, \n",
            "Epoch 4733/6000: train_loss=6.9054, val_loss=8.0986, \n",
            "Epoch 4734/6000: train_loss=6.9297, val_loss=9.0962, \n",
            "Epoch 4735/6000: train_loss=6.6583, val_loss=8.9241, \n",
            "Epoch 4736/6000: train_loss=6.9853, val_loss=8.6686, \n",
            "Epoch 4737/6000: train_loss=6.6512, val_loss=8.4752, \n",
            "Epoch 4738/6000: train_loss=6.6423, val_loss=8.7131, \n",
            "Epoch 4739/6000: train_loss=6.7654, val_loss=9.0849, \n",
            "Epoch 4740/6000: train_loss=6.7065, val_loss=8.5882, \n",
            "Epoch 4741/6000: train_loss=6.6700, val_loss=8.4705, \n",
            "Epoch 4742/6000: train_loss=6.7078, val_loss=8.7426, \n",
            "Epoch 4743/6000: train_loss=6.7779, val_loss=9.2499, \n",
            "Epoch 4744/6000: train_loss=7.0930, val_loss=8.2039, \n",
            "Epoch 4745/6000: train_loss=6.7634, val_loss=8.7678, \n",
            "Epoch 4746/6000: train_loss=6.6915, val_loss=8.8217, \n",
            "Epoch 4747/6000: train_loss=6.7626, val_loss=9.2364, \n",
            "Epoch 4748/6000: train_loss=6.7911, val_loss=8.0000, \n",
            "Epoch 4749/6000: train_loss=6.8093, val_loss=8.9435, \n",
            "Epoch 4750/6000: train_loss=6.7262, val_loss=9.1739, \n",
            "Epoch 4751/6000: train_loss=7.1600, val_loss=9.9984, \n",
            "Epoch 4752/6000: train_loss=6.7435, val_loss=8.0594, \n",
            "Epoch 4753/6000: train_loss=6.7854, val_loss=8.7669, \n",
            "Epoch 4754/6000: train_loss=6.6485, val_loss=8.8766, \n",
            "Epoch 4755/6000: train_loss=6.6753, val_loss=8.6081, \n",
            "Epoch 4756/6000: train_loss=6.7426, val_loss=8.8930, \n",
            "Epoch 4757/6000: train_loss=6.6533, val_loss=8.2641, \n",
            "Epoch 4758/6000: train_loss=6.8293, val_loss=8.2854, \n",
            "Epoch 4759/6000: train_loss=7.0714, val_loss=9.7097, \n",
            "Epoch 4760/6000: train_loss=6.9458, val_loss=8.2323, \n",
            "Epoch 4761/6000: train_loss=6.6195, val_loss=8.6847, \n",
            "Epoch 4762/6000: train_loss=6.7208, val_loss=8.3682, \n",
            "Epoch 4763/6000: train_loss=6.6547, val_loss=8.7961, \n",
            "Epoch 4764/6000: train_loss=6.6837, val_loss=8.9616, \n",
            "Epoch 4765/6000: train_loss=7.3830, val_loss=8.6818, \n",
            "Epoch 4766/6000: train_loss=7.4454, val_loss=10.2771, \n",
            "Epoch 4767/6000: train_loss=7.2637, val_loss=8.3483, \n",
            "Epoch 4768/6000: train_loss=6.7362, val_loss=8.9787, \n",
            "Epoch 4769/6000: train_loss=6.7148, val_loss=8.5400, \n",
            "Epoch 4770/6000: train_loss=6.6969, val_loss=9.0503, \n",
            "Epoch 4771/6000: train_loss=6.6324, val_loss=8.2439, \n",
            "Epoch 4772/6000: train_loss=6.8345, val_loss=9.2303, \n",
            "Epoch 4773/6000: train_loss=6.9778, val_loss=8.5853, \n",
            "Epoch 4774/6000: train_loss=7.5491, val_loss=10.4948, \n",
            "Epoch 4775/6000: train_loss=7.2583, val_loss=8.3391, \n",
            "Epoch 4776/6000: train_loss=6.8731, val_loss=8.9959, \n",
            "Epoch 4777/6000: train_loss=6.9494, val_loss=8.4770, \n",
            "Epoch 4778/6000: train_loss=6.6087, val_loss=8.8270, \n",
            "Epoch 4779/6000: train_loss=6.6044, val_loss=8.4013, \n",
            "Epoch 4780/6000: train_loss=6.6232, val_loss=8.4487, \n",
            "Epoch 4781/6000: train_loss=6.6516, val_loss=8.6853, \n",
            "Epoch 4782/6000: train_loss=6.6010, val_loss=8.9496, \n",
            "Epoch 4783/6000: train_loss=6.5988, val_loss=8.6595, \n",
            "Epoch 4784/6000: train_loss=6.6957, val_loss=8.3323, \n",
            "Epoch 4785/6000: train_loss=6.9040, val_loss=9.2190, \n",
            "Epoch 4786/6000: train_loss=7.3158, val_loss=8.1673, \n",
            "Epoch 4787/6000: train_loss=7.1786, val_loss=9.7081, \n",
            "Epoch 4788/6000: train_loss=6.9126, val_loss=8.5747, \n",
            "Epoch 4789/6000: train_loss=7.5813, val_loss=10.3998, \n",
            "Epoch 4790/6000: train_loss=6.8985, val_loss=8.3504, \n",
            "Epoch 4791/6000: train_loss=6.5619, val_loss=8.5571, \n",
            "Epoch 4792/6000: train_loss=6.5847, val_loss=8.6930, \n",
            "Epoch 4793/6000: train_loss=6.5694, val_loss=8.3504, \n",
            "Epoch 4794/6000: train_loss=6.6826, val_loss=8.8990, \n",
            "Epoch 4795/6000: train_loss=6.8268, val_loss=8.5543, \n",
            "Epoch 4796/6000: train_loss=6.5644, val_loss=8.4987, \n",
            "Epoch 4797/6000: train_loss=6.5966, val_loss=8.2260, \n",
            "Epoch 4798/6000: train_loss=6.5524, val_loss=8.3909, \n",
            "Epoch 4799/6000: train_loss=6.6293, val_loss=8.9871, \n",
            "Epoch 4800/6000: train_loss=6.8836, val_loss=8.2114, \n",
            "Epoch 4801/6000: train_loss=6.6963, val_loss=8.6497, \n",
            "Epoch 4802/6000: train_loss=6.5531, val_loss=8.4222, \n",
            "Epoch 4803/6000: train_loss=6.5973, val_loss=8.4906, \n",
            "Epoch 4804/6000: train_loss=6.6660, val_loss=9.1829, \n",
            "Epoch 4805/6000: train_loss=6.6870, val_loss=8.3157, \n",
            "Epoch 4806/6000: train_loss=6.5751, val_loss=8.4758, \n",
            "Epoch 4807/6000: train_loss=6.5369, val_loss=8.3296, \n",
            "Epoch 4808/6000: train_loss=6.6136, val_loss=9.0017, \n",
            "Epoch 4809/6000: train_loss=6.9480, val_loss=8.4135, \n",
            "Epoch 4810/6000: train_loss=6.9379, val_loss=8.9615, \n",
            "Epoch 4811/6000: train_loss=6.9439, val_loss=8.0854, \n",
            "Epoch 4812/6000: train_loss=6.6724, val_loss=9.3855, \n",
            "Epoch 4813/6000: train_loss=6.6380, val_loss=9.1827, \n",
            "Epoch 4814/6000: train_loss=6.7955, val_loss=7.7693, \n",
            "Epoch 4815/6000: train_loss=6.6344, val_loss=8.4731, \n",
            "Epoch 4816/6000: train_loss=6.8682, val_loss=8.5973, \n",
            "Epoch 4817/6000: train_loss=6.6352, val_loss=8.9394, \n",
            "Epoch 4818/6000: train_loss=6.9114, val_loss=8.1006, \n",
            "Epoch 4819/6000: train_loss=6.7673, val_loss=9.1514, \n",
            "Epoch 4820/6000: train_loss=6.8714, val_loss=8.3583, \n",
            "Epoch 4821/6000: train_loss=6.6751, val_loss=8.9190, \n",
            "Epoch 4822/6000: train_loss=6.7540, val_loss=8.0480, \n",
            "Epoch 4823/6000: train_loss=6.7846, val_loss=8.8730, \n",
            "Epoch 4824/6000: train_loss=6.8424, val_loss=8.3266, \n",
            "Epoch 4825/6000: train_loss=7.1005, val_loss=9.9210, \n",
            "Epoch 4826/6000: train_loss=7.0943, val_loss=8.3892, \n",
            "Epoch 4827/6000: train_loss=7.0681, val_loss=9.5511, \n",
            "Epoch 4828/6000: train_loss=7.0992, val_loss=8.2536, \n",
            "Epoch 4829/6000: train_loss=6.5538, val_loss=8.2346, \n",
            "Epoch 4830/6000: train_loss=6.6604, val_loss=8.4403, \n",
            "Epoch 4831/6000: train_loss=6.5308, val_loss=8.7010, \n",
            "Epoch 4832/6000: train_loss=6.5555, val_loss=8.6565, \n",
            "Epoch 4833/6000: train_loss=6.5589, val_loss=8.3848, \n",
            "Epoch 4834/6000: train_loss=6.5216, val_loss=8.3476, \n",
            "Epoch 4835/6000: train_loss=6.5648, val_loss=8.3128, \n",
            "Epoch 4836/6000: train_loss=6.5306, val_loss=8.6550, \n",
            "Epoch 4837/6000: train_loss=6.6339, val_loss=8.8495, \n",
            "Epoch 4838/6000: train_loss=6.5171, val_loss=8.1844, \n",
            "Epoch 4839/6000: train_loss=6.5608, val_loss=8.0163, \n",
            "Epoch 4840/6000: train_loss=6.5670, val_loss=8.7164, \n",
            "Epoch 4841/6000: train_loss=6.5451, val_loss=8.5126, \n",
            "Epoch 4842/6000: train_loss=6.6216, val_loss=8.3936, \n",
            "Epoch 4843/6000: train_loss=6.5195, val_loss=8.2635, \n",
            "Epoch 4844/6000: train_loss=6.5479, val_loss=8.8510, \n",
            "Epoch 4845/6000: train_loss=6.5901, val_loss=8.5000, \n",
            "Epoch 4846/6000: train_loss=6.7236, val_loss=8.0213, \n",
            "Epoch 4847/6000: train_loss=6.8068, val_loss=8.9368, \n",
            "Epoch 4848/6000: train_loss=6.7569, val_loss=8.2186, \n",
            "Epoch 4849/6000: train_loss=6.5735, val_loss=8.6532, \n",
            "Epoch 4850/6000: train_loss=6.5059, val_loss=8.3257, \n",
            "Epoch 4851/6000: train_loss=6.4951, val_loss=8.4712, \n",
            "Epoch 4852/6000: train_loss=6.7607, val_loss=9.2781, \n",
            "Epoch 4853/6000: train_loss=7.3267, val_loss=8.4198, \n",
            "Epoch 4854/6000: train_loss=7.1741, val_loss=9.6782, \n",
            "Epoch 4855/6000: train_loss=6.8696, val_loss=8.3333, \n",
            "Epoch 4856/6000: train_loss=6.6591, val_loss=9.0016, \n",
            "Epoch 4857/6000: train_loss=6.8371, val_loss=8.2026, \n",
            "Epoch 4858/6000: train_loss=6.7939, val_loss=9.4132, \n",
            "Epoch 4859/6000: train_loss=7.0857, val_loss=8.1971, \n",
            "Epoch 4860/6000: train_loss=6.8387, val_loss=9.1021, \n",
            "Epoch 4861/6000: train_loss=6.6073, val_loss=8.2735, \n",
            "Epoch 4862/6000: train_loss=6.7935, val_loss=9.1204, \n",
            "Epoch 4863/6000: train_loss=6.7887, val_loss=8.0250, \n",
            "Epoch 4864/6000: train_loss=6.5329, val_loss=8.5513, \n",
            "Epoch 4865/6000: train_loss=6.5937, val_loss=9.1713, \n",
            "Epoch 4866/6000: train_loss=6.5084, val_loss=8.6236, \n",
            "Epoch 4867/6000: train_loss=6.5885, val_loss=8.3911, \n",
            "Epoch 4868/6000: train_loss=6.7858, val_loss=7.9662, \n",
            "Epoch 4869/6000: train_loss=6.7366, val_loss=9.3821, \n",
            "Epoch 4870/6000: train_loss=6.7748, val_loss=8.3885, \n",
            "Epoch 4871/6000: train_loss=6.7742, val_loss=8.8137, \n",
            "Epoch 4872/6000: train_loss=6.6264, val_loss=7.9742, \n",
            "Epoch 4873/6000: train_loss=6.5746, val_loss=8.6785, \n",
            "Epoch 4874/6000: train_loss=6.4854, val_loss=8.5476, \n",
            "Epoch 4875/6000: train_loss=6.4997, val_loss=8.2175, \n",
            "Epoch 4876/6000: train_loss=6.4769, val_loss=8.1580, \n",
            "Epoch 4877/6000: train_loss=6.5460, val_loss=8.0181, \n",
            "Epoch 4878/6000: train_loss=6.5691, val_loss=8.6941, \n",
            "Epoch 4879/6000: train_loss=6.5132, val_loss=8.3240, \n",
            "Epoch 4880/6000: train_loss=6.4821, val_loss=8.2483, \n",
            "Epoch 4881/6000: train_loss=6.4762, val_loss=8.4374, \n",
            "Epoch 4882/6000: train_loss=6.5445, val_loss=8.9014, \n",
            "Epoch 4883/6000: train_loss=6.6530, val_loss=8.2266, \n",
            "Epoch 4884/6000: train_loss=7.4228, val_loss=9.8710, \n",
            "Epoch 4885/6000: train_loss=8.6307, val_loss=9.0874, \n",
            "Epoch 4886/6000: train_loss=8.6405, val_loss=11.8263, \n",
            "Epoch 4887/6000: train_loss=7.5983, val_loss=8.5857, \n",
            "Epoch 4888/6000: train_loss=6.5170, val_loss=8.4169, \n",
            "Epoch 4889/6000: train_loss=6.4899, val_loss=8.2151, \n",
            "Epoch 4890/6000: train_loss=6.5467, val_loss=8.3090, \n",
            "Epoch 4891/6000: train_loss=6.5127, val_loss=8.6579, \n",
            "Epoch 4892/6000: train_loss=6.6080, val_loss=7.7994, \n",
            "Epoch 4893/6000: train_loss=6.8043, val_loss=9.0881, \n",
            "Epoch 4894/6000: train_loss=7.2643, val_loss=8.6060, \n",
            "Epoch 4895/6000: train_loss=6.9681, val_loss=9.4389, \n",
            "Epoch 4896/6000: train_loss=6.4721, val_loss=8.0287, \n",
            "Epoch 4897/6000: train_loss=6.4958, val_loss=8.4571, \n",
            "Epoch 4898/6000: train_loss=6.4710, val_loss=8.1192, \n",
            "Epoch 4899/6000: train_loss=6.4859, val_loss=8.4903, \n",
            "Epoch 4900/6000: train_loss=6.5311, val_loss=8.3512, \n",
            "Epoch 4901/6000: train_loss=6.4897, val_loss=8.2153, \n",
            "Epoch 4902/6000: train_loss=6.5937, val_loss=8.5717, \n",
            "Epoch 4903/6000: train_loss=7.3933, val_loss=8.1392, \n",
            "Epoch 4904/6000: train_loss=7.2092, val_loss=9.8642, \n",
            "Epoch 4905/6000: train_loss=7.8901, val_loss=8.5581, \n",
            "Epoch 4906/6000: train_loss=7.3994, val_loss=10.0631, \n",
            "Epoch 4907/6000: train_loss=7.3343, val_loss=8.3951, \n",
            "Epoch 4908/6000: train_loss=6.7135, val_loss=9.0420, \n",
            "Epoch 4909/6000: train_loss=6.4484, val_loss=8.0503, \n",
            "Epoch 4910/6000: train_loss=7.0967, val_loss=8.1551, \n",
            "Epoch 4911/6000: train_loss=7.9332, val_loss=11.0004, \n",
            "Epoch 4912/6000: train_loss=7.8582, val_loss=8.7165, \n",
            "Epoch 4913/6000: train_loss=7.6949, val_loss=10.2006, \n",
            "Epoch 4914/6000: train_loss=6.7169, val_loss=7.8952, \n",
            "Epoch 4915/6000: train_loss=6.5501, val_loss=8.6643, \n",
            "Epoch 4916/6000: train_loss=6.7325, val_loss=8.1460, \n",
            "Epoch 4917/6000: train_loss=7.3610, val_loss=9.8185, \n",
            "Epoch 4918/6000: train_loss=6.6521, val_loss=7.9276, \n",
            "Epoch 4919/6000: train_loss=6.6002, val_loss=8.7765, \n",
            "Epoch 4920/6000: train_loss=6.8530, val_loss=8.1722, \n",
            "Epoch 4921/6000: train_loss=6.9244, val_loss=9.2547, \n",
            "Epoch 4922/6000: train_loss=6.4803, val_loss=8.0283, \n",
            "Epoch 4923/6000: train_loss=6.4488, val_loss=8.3908, \n",
            "Epoch 4924/6000: train_loss=6.5796, val_loss=8.1952, \n",
            "Epoch 4925/6000: train_loss=6.6620, val_loss=9.1490, \n",
            "Epoch 4926/6000: train_loss=6.8976, val_loss=7.8548, \n",
            "Epoch 4927/6000: train_loss=6.5625, val_loss=8.4954, \n",
            "Epoch 4928/6000: train_loss=6.4561, val_loss=8.6766, \n",
            "Epoch 4929/6000: train_loss=6.4278, val_loss=8.4030, \n",
            "Epoch 4930/6000: train_loss=6.4950, val_loss=7.9011, \n",
            "Epoch 4931/6000: train_loss=6.6273, val_loss=8.8652, \n",
            "Epoch 4932/6000: train_loss=6.4826, val_loss=8.5931, \n",
            "Epoch 4933/6000: train_loss=6.4304, val_loss=8.1150, \n",
            "Epoch 4934/6000: train_loss=6.5377, val_loss=7.7078, \n",
            "Epoch 4935/6000: train_loss=6.4825, val_loss=8.3098, \n",
            "Epoch 4936/6000: train_loss=6.8577, val_loss=8.7246, \n",
            "Epoch 4937/6000: train_loss=6.6937, val_loss=9.2512, \n",
            "Epoch 4938/6000: train_loss=6.7024, val_loss=7.5969, \n",
            "Epoch 4939/6000: train_loss=6.5201, val_loss=8.1886, \n",
            "Epoch 4940/6000: train_loss=6.8091, val_loss=8.4460, \n",
            "Epoch 4941/6000: train_loss=7.0177, val_loss=9.5584, \n",
            "Epoch 4942/6000: train_loss=7.9461, val_loss=8.2026, \n",
            "Epoch 4943/6000: train_loss=7.1650, val_loss=9.7289, \n",
            "Epoch 4944/6000: train_loss=6.6478, val_loss=8.1359, \n",
            "Epoch 4945/6000: train_loss=6.5150, val_loss=8.1790, \n",
            "Epoch 4946/6000: train_loss=6.4119, val_loss=8.1513, \n",
            "Epoch 4947/6000: train_loss=6.4178, val_loss=8.3648, \n",
            "Epoch 4948/6000: train_loss=6.5013, val_loss=8.2870, \n",
            "Epoch 4949/6000: train_loss=6.4412, val_loss=8.0742, \n",
            "Epoch 4950/6000: train_loss=6.4285, val_loss=8.0085, \n",
            "Epoch 4951/6000: train_loss=6.4242, val_loss=8.0366, \n",
            "Epoch 4952/6000: train_loss=6.4469, val_loss=8.1023, \n",
            "Epoch 4953/6000: train_loss=6.4323, val_loss=8.0517, \n",
            "Epoch 4954/6000: train_loss=6.4490, val_loss=8.4561, \n",
            "Epoch 4955/6000: train_loss=6.4220, val_loss=8.1466, \n",
            "Epoch 4956/6000: train_loss=6.5291, val_loss=7.6499, \n",
            "Epoch 4957/6000: train_loss=6.4418, val_loss=8.3036, \n",
            "Epoch 4958/6000: train_loss=6.4697, val_loss=8.5443, \n",
            "Epoch 4959/6000: train_loss=6.4497, val_loss=8.1461, \n",
            "Epoch 4960/6000: train_loss=6.4256, val_loss=7.8564, \n",
            "Epoch 4961/6000: train_loss=6.5051, val_loss=7.7069, \n",
            "Epoch 4962/6000: train_loss=6.4831, val_loss=8.5631, \n",
            "Epoch 4963/6000: train_loss=6.7796, val_loss=8.3705, \n",
            "Epoch 4964/6000: train_loss=6.5269, val_loss=8.6208, \n",
            "Epoch 4965/6000: train_loss=6.5339, val_loss=7.7446, \n",
            "Epoch 4966/6000: train_loss=6.5168, val_loss=8.6146, \n",
            "Epoch 4967/6000: train_loss=6.4123, val_loss=8.0400, \n",
            "Epoch 4968/6000: train_loss=6.4201, val_loss=8.1567, \n",
            "Epoch 4969/6000: train_loss=6.8936, val_loss=7.8293, \n",
            "Epoch 4970/6000: train_loss=7.7964, val_loss=10.6216, \n",
            "Epoch 4971/6000: train_loss=7.5052, val_loss=8.4007, \n",
            "Epoch 4972/6000: train_loss=7.0597, val_loss=9.3445, \n",
            "Epoch 4973/6000: train_loss=6.7839, val_loss=7.9328, \n",
            "Epoch 4974/6000: train_loss=6.7304, val_loss=8.9663, \n",
            "Epoch 4975/6000: train_loss=7.0496, val_loss=7.8569, \n",
            "Epoch 4976/6000: train_loss=6.5727, val_loss=8.6531, \n",
            "Epoch 4977/6000: train_loss=6.4132, val_loss=8.1156, \n",
            "Epoch 4978/6000: train_loss=6.7282, val_loss=8.7350, \n",
            "Epoch 4979/6000: train_loss=6.4058, val_loss=7.8838, \n",
            "Epoch 4980/6000: train_loss=6.3978, val_loss=8.3415, \n",
            "Epoch 4981/6000: train_loss=6.4116, val_loss=8.5199, \n",
            "Epoch 4982/6000: train_loss=6.4417, val_loss=7.8941, \n",
            "Epoch 4983/6000: train_loss=6.3864, val_loss=8.0231, \n",
            "Epoch 4984/6000: train_loss=6.4279, val_loss=8.1782, \n",
            "Epoch 4985/6000: train_loss=6.4203, val_loss=7.8184, \n",
            "Epoch 4986/6000: train_loss=6.4404, val_loss=8.0133, \n",
            "Epoch 4987/6000: train_loss=6.3788, val_loss=8.2817, \n",
            "Epoch 4988/6000: train_loss=6.3798, val_loss=8.1281, \n",
            "Epoch 4989/6000: train_loss=6.3748, val_loss=8.0685, \n",
            "Epoch 4990/6000: train_loss=6.3846, val_loss=7.9807, \n",
            "Epoch 4991/6000: train_loss=6.4274, val_loss=7.8965, \n",
            "Epoch 4992/6000: train_loss=6.3688, val_loss=7.8859, \n",
            "Epoch 4993/6000: train_loss=6.6170, val_loss=7.8148, \n",
            "Epoch 4994/6000: train_loss=6.5162, val_loss=8.6634, \n",
            "Epoch 4995/6000: train_loss=6.7265, val_loss=7.6719, \n",
            "Epoch 4996/6000: train_loss=6.8589, val_loss=8.7940, \n",
            "Epoch 4997/6000: train_loss=6.9252, val_loss=8.1445, \n",
            "Epoch 4998/6000: train_loss=6.6873, val_loss=9.2690, \n",
            "Epoch 4999/6000: train_loss=6.6785, val_loss=7.8843, \n",
            "Epoch 5000/6000: train_loss=6.4574, val_loss=7.6998, \n",
            "Epoch 5001/6000: train_loss=6.3989, val_loss=7.8186, \n",
            "Epoch 5002/6000: train_loss=6.4789, val_loss=8.3432, \n",
            "Epoch 5003/6000: train_loss=6.3825, val_loss=8.2042, \n",
            "Epoch 5004/6000: train_loss=6.6444, val_loss=7.7588, \n",
            "Epoch 5005/6000: train_loss=6.7661, val_loss=9.1712, \n",
            "Epoch 5006/6000: train_loss=6.6794, val_loss=7.7724, \n",
            "Epoch 5007/6000: train_loss=7.1641, val_loss=9.2714, \n",
            "Epoch 5008/6000: train_loss=6.9241, val_loss=7.9498, \n",
            "Epoch 5009/6000: train_loss=7.5372, val_loss=10.1357, \n",
            "Epoch 5010/6000: train_loss=7.8706, val_loss=8.7203, \n",
            "Epoch 5011/6000: train_loss=7.2086, val_loss=9.6629, \n",
            "Epoch 5012/6000: train_loss=7.1353, val_loss=8.0493, \n",
            "Epoch 5013/6000: train_loss=7.3853, val_loss=10.1310, \n",
            "Epoch 5014/6000: train_loss=7.0236, val_loss=7.9239, \n",
            "Epoch 5015/6000: train_loss=6.4001, val_loss=8.3369, \n",
            "Epoch 5016/6000: train_loss=6.3911, val_loss=8.0867, \n",
            "Epoch 5017/6000: train_loss=6.3592, val_loss=7.9521, \n",
            "Epoch 5018/6000: train_loss=6.4097, val_loss=7.6221, \n",
            "Epoch 5019/6000: train_loss=6.3871, val_loss=7.8873, \n",
            "Epoch 5020/6000: train_loss=6.5386, val_loss=8.7002, \n",
            "Epoch 5021/6000: train_loss=6.7702, val_loss=7.7136, \n",
            "Epoch 5022/6000: train_loss=6.4621, val_loss=7.9482, \n",
            "Epoch 5023/6000: train_loss=6.8978, val_loss=8.0778, \n",
            "Epoch 5024/6000: train_loss=7.0197, val_loss=9.6459, \n",
            "Epoch 5025/6000: train_loss=6.9375, val_loss=7.6797, \n",
            "Epoch 5026/6000: train_loss=6.7308, val_loss=8.3511, \n",
            "Epoch 5027/6000: train_loss=6.8316, val_loss=7.9649, \n",
            "Epoch 5028/6000: train_loss=6.9017, val_loss=9.6365, \n",
            "Epoch 5029/6000: train_loss=6.5106, val_loss=7.9319, \n",
            "Epoch 5030/6000: train_loss=6.4728, val_loss=7.7994, \n",
            "Epoch 5031/6000: train_loss=6.4463, val_loss=7.8532, \n",
            "Epoch 5032/6000: train_loss=6.4669, val_loss=8.3494, \n",
            "Epoch 5033/6000: train_loss=6.3441, val_loss=8.1801, \n",
            "Epoch 5034/6000: train_loss=6.5364, val_loss=7.5600, \n",
            "Epoch 5035/6000: train_loss=6.4015, val_loss=8.2451, \n",
            "Epoch 5036/6000: train_loss=6.6642, val_loss=8.0482, \n",
            "Epoch 5037/6000: train_loss=6.4145, val_loss=8.4179, \n",
            "Epoch 5038/6000: train_loss=6.5182, val_loss=7.6696, \n",
            "Epoch 5039/6000: train_loss=6.3299, val_loss=7.8466, \n",
            "Epoch 5040/6000: train_loss=6.4055, val_loss=7.7632, \n",
            "Epoch 5041/6000: train_loss=6.8665, val_loss=9.0859, \n",
            "Epoch 5042/6000: train_loss=7.1056, val_loss=7.8856, \n",
            "Epoch 5043/6000: train_loss=7.3141, val_loss=9.6858, \n",
            "Epoch 5044/6000: train_loss=6.7752, val_loss=7.8264, \n",
            "Epoch 5045/6000: train_loss=6.7333, val_loss=8.8982, \n",
            "Epoch 5046/6000: train_loss=6.3573, val_loss=7.7071, \n",
            "Epoch 5047/6000: train_loss=6.5830, val_loss=7.7753, \n",
            "Epoch 5048/6000: train_loss=6.4841, val_loss=8.5886, \n",
            "Epoch 5049/6000: train_loss=6.3432, val_loss=7.9195, \n",
            "Epoch 5050/6000: train_loss=6.3257, val_loss=7.9958, \n",
            "Epoch 5051/6000: train_loss=6.3241, val_loss=7.9222, \n",
            "Epoch 5052/6000: train_loss=6.3203, val_loss=7.9565, \n",
            "Epoch 5053/6000: train_loss=6.3232, val_loss=8.0728, \n",
            "Epoch 5054/6000: train_loss=6.3287, val_loss=7.8430, \n",
            "Epoch 5055/6000: train_loss=6.4315, val_loss=8.4818, \n",
            "Epoch 5056/6000: train_loss=6.4957, val_loss=7.8999, \n",
            "Epoch 5057/6000: train_loss=6.3153, val_loss=7.9891, \n",
            "Epoch 5058/6000: train_loss=6.3360, val_loss=7.8890, \n",
            "Epoch 5059/6000: train_loss=6.3876, val_loss=8.3833, \n",
            "Epoch 5060/6000: train_loss=6.5351, val_loss=7.7937, \n",
            "Epoch 5061/6000: train_loss=6.5218, val_loss=8.5426, \n",
            "Epoch 5062/6000: train_loss=7.0839, val_loss=8.0365, \n",
            "Epoch 5063/6000: train_loss=7.0248, val_loss=9.2526, \n",
            "Epoch 5064/6000: train_loss=6.9413, val_loss=7.6524, \n",
            "Epoch 5065/6000: train_loss=6.3221, val_loss=7.9386, \n",
            "Epoch 5066/6000: train_loss=6.3649, val_loss=8.0723, \n",
            "Epoch 5067/6000: train_loss=6.4736, val_loss=7.6379, \n",
            "Epoch 5068/6000: train_loss=6.5935, val_loss=8.7106, \n",
            "Epoch 5069/6000: train_loss=6.3096, val_loss=8.1170, \n",
            "Epoch 5070/6000: train_loss=6.3047, val_loss=8.1168, \n",
            "Epoch 5071/6000: train_loss=6.3296, val_loss=8.0399, \n",
            "Epoch 5072/6000: train_loss=6.3142, val_loss=7.8462, \n",
            "Epoch 5073/6000: train_loss=6.3578, val_loss=7.9954, \n",
            "Epoch 5074/6000: train_loss=6.3117, val_loss=8.0966, \n",
            "Epoch 5075/6000: train_loss=6.4189, val_loss=7.5040, \n",
            "Epoch 5076/6000: train_loss=6.3451, val_loss=7.6594, \n",
            "Epoch 5077/6000: train_loss=6.3107, val_loss=8.0921, \n",
            "Epoch 5078/6000: train_loss=6.3187, val_loss=8.1736, \n",
            "Epoch 5079/6000: train_loss=6.3803, val_loss=8.2410, \n",
            "Epoch 5080/6000: train_loss=6.3016, val_loss=7.9653, \n",
            "Epoch 5081/6000: train_loss=6.4755, val_loss=8.2106, \n",
            "Epoch 5082/6000: train_loss=6.3064, val_loss=7.8002, \n",
            "Epoch 5083/6000: train_loss=6.3504, val_loss=8.0373, \n",
            "Epoch 5084/6000: train_loss=6.5742, val_loss=8.7316, \n",
            "Epoch 5085/6000: train_loss=6.4381, val_loss=7.4519, \n",
            "Epoch 5086/6000: train_loss=6.3362, val_loss=7.9694, \n",
            "Epoch 5087/6000: train_loss=6.3304, val_loss=8.2586, \n",
            "Epoch 5088/6000: train_loss=6.2893, val_loss=7.9101, \n",
            "Epoch 5089/6000: train_loss=6.3179, val_loss=7.6256, \n",
            "Epoch 5090/6000: train_loss=6.2922, val_loss=7.8295, \n",
            "Epoch 5091/6000: train_loss=6.4183, val_loss=8.5369, \n",
            "Epoch 5092/6000: train_loss=6.4729, val_loss=7.6407, \n",
            "Epoch 5093/6000: train_loss=6.4578, val_loss=8.1961, \n",
            "Epoch 5094/6000: train_loss=6.4508, val_loss=7.7230, \n",
            "Epoch 5095/6000: train_loss=6.5041, val_loss=8.8329, \n",
            "Epoch 5096/6000: train_loss=6.7826, val_loss=7.9292, \n",
            "Epoch 5097/6000: train_loss=6.8256, val_loss=8.8131, \n",
            "Epoch 5098/6000: train_loss=6.4206, val_loss=7.9355, \n",
            "Epoch 5099/6000: train_loss=6.3250, val_loss=8.0929, \n",
            "Epoch 5100/6000: train_loss=6.3266, val_loss=7.6928, \n",
            "Epoch 5101/6000: train_loss=6.3306, val_loss=8.3185, \n",
            "Epoch 5102/6000: train_loss=6.3206, val_loss=8.1234, \n",
            "Epoch 5103/6000: train_loss=6.4564, val_loss=7.7818, \n",
            "Epoch 5104/6000: train_loss=6.4512, val_loss=7.4070, \n",
            "Epoch 5105/6000: train_loss=6.7179, val_loss=9.0894, \n",
            "Epoch 5106/6000: train_loss=6.4327, val_loss=7.9741, \n",
            "Epoch 5107/6000: train_loss=6.2858, val_loss=7.7310, \n",
            "Epoch 5108/6000: train_loss=6.2887, val_loss=7.6989, \n",
            "Epoch 5109/6000: train_loss=6.3311, val_loss=7.6403, \n",
            "Epoch 5110/6000: train_loss=6.6754, val_loss=8.8751, \n",
            "Epoch 5111/6000: train_loss=6.9593, val_loss=7.8571, \n",
            "Epoch 5112/6000: train_loss=6.7934, val_loss=8.8072, \n",
            "Epoch 5113/6000: train_loss=6.4305, val_loss=7.6672, \n",
            "Epoch 5114/6000: train_loss=6.3044, val_loss=8.0334, \n",
            "Epoch 5115/6000: train_loss=6.4122, val_loss=7.6428, \n",
            "Epoch 5116/6000: train_loss=6.9620, val_loss=9.0110, \n",
            "Epoch 5117/6000: train_loss=6.3840, val_loss=7.5308, \n",
            "Epoch 5118/6000: train_loss=6.2859, val_loss=8.2017, \n",
            "Epoch 5119/6000: train_loss=6.3982, val_loss=7.9842, \n",
            "Epoch 5120/6000: train_loss=6.3666, val_loss=8.0610, \n",
            "Epoch 5121/6000: train_loss=6.2773, val_loss=7.6398, \n",
            "Epoch 5122/6000: train_loss=6.3457, val_loss=8.2656, \n",
            "Epoch 5123/6000: train_loss=6.2736, val_loss=7.9157, \n",
            "Epoch 5124/6000: train_loss=6.3886, val_loss=7.5416, \n",
            "Epoch 5125/6000: train_loss=6.2985, val_loss=8.1255, \n",
            "Epoch 5126/6000: train_loss=6.2866, val_loss=7.8398, \n",
            "Epoch 5127/6000: train_loss=6.2814, val_loss=7.7805, \n",
            "Epoch 5128/6000: train_loss=6.2816, val_loss=7.9700, \n",
            "Epoch 5129/6000: train_loss=6.2759, val_loss=8.0325, \n",
            "Epoch 5130/6000: train_loss=6.2690, val_loss=7.6012, \n",
            "Epoch 5131/6000: train_loss=6.5027, val_loss=7.4763, \n",
            "Epoch 5132/6000: train_loss=6.3368, val_loss=8.3185, \n",
            "Epoch 5133/6000: train_loss=6.3317, val_loss=7.9108, \n",
            "Epoch 5134/6000: train_loss=6.4024, val_loss=7.9734, \n",
            "Epoch 5135/6000: train_loss=6.5206, val_loss=7.4376, \n",
            "Epoch 5136/6000: train_loss=7.1893, val_loss=9.6920, \n",
            "Epoch 5137/6000: train_loss=6.3967, val_loss=7.6013, \n",
            "Epoch 5138/6000: train_loss=6.5338, val_loss=8.3044, \n",
            "Epoch 5139/6000: train_loss=6.2898, val_loss=7.6217, \n",
            "Epoch 5140/6000: train_loss=6.3048, val_loss=7.9181, \n",
            "Epoch 5141/6000: train_loss=6.4678, val_loss=8.6007, \n",
            "Epoch 5142/6000: train_loss=6.9213, val_loss=7.7766, \n",
            "Epoch 5143/6000: train_loss=6.4111, val_loss=8.2484, \n",
            "Epoch 5144/6000: train_loss=6.2677, val_loss=7.7796, \n",
            "Epoch 5145/6000: train_loss=6.5641, val_loss=7.3640, \n",
            "Epoch 5146/6000: train_loss=6.9780, val_loss=8.9305, \n",
            "Epoch 5147/6000: train_loss=6.9620, val_loss=8.0301, \n",
            "Epoch 5148/6000: train_loss=6.7163, val_loss=9.1602, \n",
            "Epoch 5149/6000: train_loss=6.2503, val_loss=7.8778, \n",
            "Epoch 5150/6000: train_loss=6.3453, val_loss=7.8598, \n",
            "Epoch 5151/6000: train_loss=6.2467, val_loss=7.6731, \n",
            "Epoch 5152/6000: train_loss=6.3529, val_loss=8.3568, \n",
            "Epoch 5153/6000: train_loss=6.4984, val_loss=7.8332, \n",
            "Epoch 5154/6000: train_loss=6.2541, val_loss=7.7156, \n",
            "Epoch 5155/6000: train_loss=6.4022, val_loss=7.5430, \n",
            "Epoch 5156/6000: train_loss=6.3074, val_loss=7.8392, \n",
            "Epoch 5157/6000: train_loss=6.3920, val_loss=7.9671, \n",
            "Epoch 5158/6000: train_loss=7.0785, val_loss=7.9965, \n",
            "Epoch 5159/6000: train_loss=7.1810, val_loss=9.8467, \n",
            "Epoch 5160/6000: train_loss=6.5715, val_loss=7.7315, \n",
            "Epoch 5161/6000: train_loss=6.4512, val_loss=7.8820, \n",
            "Epoch 5162/6000: train_loss=6.3311, val_loss=7.3403, \n",
            "Epoch 5163/6000: train_loss=6.7416, val_loss=9.2076, \n",
            "Epoch 5164/6000: train_loss=6.3853, val_loss=7.9487, \n",
            "Epoch 5165/6000: train_loss=6.5613, val_loss=8.4912, \n",
            "Epoch 5166/6000: train_loss=6.2793, val_loss=7.5320, \n",
            "Epoch 5167/6000: train_loss=6.2625, val_loss=7.8905, \n",
            "Epoch 5168/6000: train_loss=6.2966, val_loss=8.2468, \n",
            "Epoch 5169/6000: train_loss=6.5019, val_loss=7.2354, \n",
            "Epoch 5170/6000: train_loss=6.3036, val_loss=7.7067, \n",
            "Epoch 5171/6000: train_loss=6.5184, val_loss=8.1337, \n",
            "Epoch 5172/6000: train_loss=6.8393, val_loss=9.2473, \n",
            "Epoch 5173/6000: train_loss=6.8133, val_loss=7.3028, \n",
            "Epoch 5174/6000: train_loss=6.7966, val_loss=8.6214, \n",
            "Epoch 5175/6000: train_loss=7.0716, val_loss=8.2184, \n",
            "Epoch 5176/6000: train_loss=6.2470, val_loss=8.2451, \n",
            "Epoch 5177/6000: train_loss=6.2598, val_loss=7.7750, \n",
            "Epoch 5178/6000: train_loss=6.4147, val_loss=7.4752, \n",
            "Epoch 5179/6000: train_loss=6.4541, val_loss=8.6879, \n",
            "Epoch 5180/6000: train_loss=6.3219, val_loss=7.6854, \n",
            "Epoch 5181/6000: train_loss=6.5633, val_loss=8.1975, \n",
            "Epoch 5182/6000: train_loss=6.8471, val_loss=7.7043, \n",
            "Epoch 5183/6000: train_loss=6.5038, val_loss=8.9309, \n",
            "Epoch 5184/6000: train_loss=6.5304, val_loss=7.7479, \n",
            "Epoch 5185/6000: train_loss=6.2595, val_loss=7.5575, \n",
            "Epoch 5186/6000: train_loss=6.2323, val_loss=7.9026, \n",
            "Epoch 5187/6000: train_loss=6.5341, val_loss=7.8639, \n",
            "Epoch 5188/6000: train_loss=6.4652, val_loss=8.5039, \n",
            "Epoch 5189/6000: train_loss=6.2545, val_loss=7.4236, \n",
            "Epoch 5190/6000: train_loss=6.2108, val_loss=7.5808, \n",
            "Epoch 5191/6000: train_loss=6.2031, val_loss=8.0302, \n",
            "Epoch 5192/6000: train_loss=6.1910, val_loss=7.8415, \n",
            "Epoch 5193/6000: train_loss=6.2376, val_loss=7.7940, \n",
            "Epoch 5194/6000: train_loss=6.1913, val_loss=7.8271, \n",
            "Epoch 5195/6000: train_loss=6.1953, val_loss=7.9877, \n",
            "Epoch 5196/6000: train_loss=6.3565, val_loss=8.4304, \n",
            "Epoch 5197/6000: train_loss=6.3747, val_loss=7.5819, \n",
            "Epoch 5198/6000: train_loss=6.1843, val_loss=7.7836, \n",
            "Epoch 5199/6000: train_loss=6.2544, val_loss=7.7095, \n",
            "Epoch 5200/6000: train_loss=6.2536, val_loss=7.9444, \n",
            "Epoch 5201/6000: train_loss=6.1938, val_loss=7.8469, \n",
            "Epoch 5202/6000: train_loss=6.2719, val_loss=7.5123, \n",
            "Epoch 5203/6000: train_loss=6.1858, val_loss=7.7787, \n",
            "Epoch 5204/6000: train_loss=6.2307, val_loss=7.9993, \n",
            "Epoch 5205/6000: train_loss=6.3928, val_loss=7.2200, \n",
            "Epoch 5206/6000: train_loss=6.3120, val_loss=7.9062, \n",
            "Epoch 5207/6000: train_loss=6.3243, val_loss=7.9433, \n",
            "Epoch 5208/6000: train_loss=6.2818, val_loss=8.3053, \n",
            "Epoch 5209/6000: train_loss=6.1909, val_loss=7.5206, \n",
            "Epoch 5210/6000: train_loss=6.8058, val_loss=8.7962, \n",
            "Epoch 5211/6000: train_loss=6.5945, val_loss=7.5981, \n",
            "Epoch 5212/6000: train_loss=6.9370, val_loss=9.3851, \n",
            "Epoch 5213/6000: train_loss=7.2058, val_loss=7.9041, \n",
            "Epoch 5214/6000: train_loss=7.1409, val_loss=9.1750, \n",
            "Epoch 5215/6000: train_loss=7.2063, val_loss=7.8550, \n",
            "Epoch 5216/6000: train_loss=6.7479, val_loss=9.2169, \n",
            "Epoch 5217/6000: train_loss=6.7533, val_loss=7.8511, \n",
            "Epoch 5218/6000: train_loss=6.2306, val_loss=7.4946, \n",
            "Epoch 5219/6000: train_loss=6.1838, val_loss=7.4477, \n",
            "Epoch 5220/6000: train_loss=6.2672, val_loss=8.2673, \n",
            "Epoch 5221/6000: train_loss=6.5474, val_loss=7.5868, \n",
            "Epoch 5222/6000: train_loss=6.2190, val_loss=7.3993, \n",
            "Epoch 5223/6000: train_loss=6.1817, val_loss=7.6782, \n",
            "Epoch 5224/6000: train_loss=6.4044, val_loss=7.6362, \n",
            "Epoch 5225/6000: train_loss=6.2156, val_loss=8.0565, \n",
            "Epoch 5226/6000: train_loss=6.3143, val_loss=7.9633, \n",
            "Epoch 5227/6000: train_loss=6.1988, val_loss=7.5852, \n",
            "Epoch 5228/6000: train_loss=6.1716, val_loss=7.7787, \n",
            "Epoch 5229/6000: train_loss=6.2824, val_loss=8.2278, \n",
            "Epoch 5230/6000: train_loss=6.2969, val_loss=7.7706, \n",
            "Epoch 5231/6000: train_loss=6.2753, val_loss=7.6179, \n",
            "Epoch 5232/6000: train_loss=6.2418, val_loss=7.9124, \n",
            "Epoch 5233/6000: train_loss=6.9223, val_loss=7.4377, \n",
            "Epoch 5234/6000: train_loss=6.6423, val_loss=8.8333, \n",
            "Epoch 5235/6000: train_loss=6.2258, val_loss=7.9575, \n",
            "Epoch 5236/6000: train_loss=6.4332, val_loss=8.5084, \n",
            "Epoch 5237/6000: train_loss=6.6160, val_loss=7.7173, \n",
            "Epoch 5238/6000: train_loss=7.1381, val_loss=9.4491, \n",
            "Epoch 5239/6000: train_loss=8.0630, val_loss=8.2915, \n",
            "Epoch 5240/6000: train_loss=8.9070, val_loss=11.8420, \n",
            "Epoch 5241/6000: train_loss=10.3697, val_loss=10.0651, \n",
            "Epoch 5242/6000: train_loss=10.7959, val_loss=14.0464, \n",
            "Epoch 5243/6000: train_loss=9.1355, val_loss=9.3109, \n",
            "Epoch 5244/6000: train_loss=7.8422, val_loss=10.6628, \n",
            "Epoch 5245/6000: train_loss=8.1220, val_loss=8.1849, \n",
            "Epoch 5246/6000: train_loss=7.2739, val_loss=9.2343, \n",
            "Epoch 5247/6000: train_loss=6.7512, val_loss=7.5218, \n",
            "Epoch 5248/6000: train_loss=6.2312, val_loss=8.2276, \n",
            "Epoch 5249/6000: train_loss=6.2016, val_loss=7.9022, \n",
            "Epoch 5250/6000: train_loss=6.5404, val_loss=7.3801, \n",
            "Epoch 5251/6000: train_loss=7.5043, val_loss=9.6984, \n",
            "Epoch 5252/6000: train_loss=8.3400, val_loss=8.5713, \n",
            "Epoch 5253/6000: train_loss=8.1602, val_loss=10.5957, \n",
            "Epoch 5254/6000: train_loss=7.2214, val_loss=7.8219, \n",
            "Epoch 5255/6000: train_loss=8.3477, val_loss=10.8064, \n",
            "Epoch 5256/6000: train_loss=7.3274, val_loss=7.9663, \n",
            "Epoch 5257/6000: train_loss=7.0514, val_loss=9.3961, \n",
            "Epoch 5258/6000: train_loss=6.6934, val_loss=7.4732, \n",
            "Epoch 5259/6000: train_loss=6.9527, val_loss=8.9826, \n",
            "Epoch 5260/6000: train_loss=6.2332, val_loss=7.7199, \n",
            "Epoch 5261/6000: train_loss=6.1502, val_loss=7.9540, \n",
            "Epoch 5262/6000: train_loss=6.1448, val_loss=7.6482, \n",
            "Epoch 5263/6000: train_loss=6.4028, val_loss=7.3222, \n",
            "Epoch 5264/6000: train_loss=6.2137, val_loss=8.0512, \n",
            "Epoch 5265/6000: train_loss=6.3671, val_loss=7.5682, \n",
            "Epoch 5266/6000: train_loss=6.7256, val_loss=8.7382, \n",
            "Epoch 5267/6000: train_loss=6.3754, val_loss=7.5061, \n",
            "Epoch 5268/6000: train_loss=6.4113, val_loss=8.4047, \n",
            "Epoch 5269/6000: train_loss=6.3056, val_loss=7.6324, \n",
            "Epoch 5270/6000: train_loss=6.3015, val_loss=8.1722, \n",
            "Epoch 5271/6000: train_loss=6.2536, val_loss=7.5137, \n",
            "Epoch 5272/6000: train_loss=6.3373, val_loss=7.6533, \n",
            "Epoch 5273/6000: train_loss=6.6240, val_loss=8.5892, \n",
            "Epoch 5274/6000: train_loss=6.3359, val_loss=7.2960, \n",
            "Epoch 5275/6000: train_loss=6.8160, val_loss=9.1325, \n",
            "Epoch 5276/6000: train_loss=7.0024, val_loss=8.1001, \n",
            "Epoch 5277/6000: train_loss=6.6396, val_loss=8.7587, \n",
            "Epoch 5278/6000: train_loss=6.1700, val_loss=7.4948, \n",
            "Epoch 5279/6000: train_loss=6.1402, val_loss=7.4428, \n",
            "Epoch 5280/6000: train_loss=6.2910, val_loss=8.3260, \n",
            "Epoch 5281/6000: train_loss=6.5806, val_loss=7.6925, \n",
            "Epoch 5282/6000: train_loss=6.4753, val_loss=8.1463, \n",
            "Epoch 5283/6000: train_loss=6.2154, val_loss=7.3994, \n",
            "Epoch 5284/6000: train_loss=6.1990, val_loss=8.1427, \n",
            "Epoch 5285/6000: train_loss=6.1347, val_loss=7.8005, \n",
            "Epoch 5286/6000: train_loss=6.1561, val_loss=7.3133, \n",
            "Epoch 5287/6000: train_loss=6.1428, val_loss=7.8430, \n",
            "Epoch 5288/6000: train_loss=6.2106, val_loss=7.9042, \n",
            "Epoch 5289/6000: train_loss=6.2893, val_loss=7.9948, \n",
            "Epoch 5290/6000: train_loss=6.6298, val_loss=7.2150, \n",
            "Epoch 5291/6000: train_loss=6.2849, val_loss=8.1939, \n",
            "Epoch 5292/6000: train_loss=6.6943, val_loss=8.0799, \n",
            "Epoch 5293/6000: train_loss=6.2111, val_loss=7.8747, \n",
            "Epoch 5294/6000: train_loss=6.2586, val_loss=7.5825, \n",
            "Epoch 5295/6000: train_loss=6.1784, val_loss=7.3286, \n",
            "Epoch 5296/6000: train_loss=6.3536, val_loss=8.5042, \n",
            "Epoch 5297/6000: train_loss=6.2325, val_loss=7.5210, \n",
            "Epoch 5298/6000: train_loss=6.1934, val_loss=7.8032, \n",
            "Epoch 5299/6000: train_loss=6.1904, val_loss=7.4445, \n",
            "Epoch 5300/6000: train_loss=6.1142, val_loss=7.6543, \n",
            "Epoch 5301/6000: train_loss=6.2482, val_loss=7.5587, \n",
            "Epoch 5302/6000: train_loss=6.2531, val_loss=8.0256, \n",
            "Epoch 5303/6000: train_loss=6.3780, val_loss=7.3040, \n",
            "Epoch 5304/6000: train_loss=6.2310, val_loss=7.8221, \n",
            "Epoch 5305/6000: train_loss=6.1480, val_loss=7.5971, \n",
            "Epoch 5306/6000: train_loss=6.1157, val_loss=7.6469, \n",
            "Epoch 5307/6000: train_loss=6.2159, val_loss=7.7677, \n",
            "Epoch 5308/6000: train_loss=6.4244, val_loss=7.4042, \n",
            "Epoch 5309/6000: train_loss=6.4665, val_loss=8.6606, \n",
            "Epoch 5310/6000: train_loss=6.4562, val_loss=7.5785, \n",
            "Epoch 5311/6000: train_loss=6.4466, val_loss=8.0692, \n",
            "Epoch 5312/6000: train_loss=6.1422, val_loss=7.5165, \n",
            "Epoch 5313/6000: train_loss=6.2017, val_loss=8.2720, \n",
            "Epoch 5314/6000: train_loss=6.2160, val_loss=7.3248, \n",
            "Epoch 5315/6000: train_loss=6.1816, val_loss=7.6570, \n",
            "Epoch 5316/6000: train_loss=6.2130, val_loss=8.1751, \n",
            "Epoch 5317/6000: train_loss=6.4936, val_loss=7.6325, \n",
            "Epoch 5318/6000: train_loss=6.1188, val_loss=7.5478, \n",
            "Epoch 5319/6000: train_loss=6.0963, val_loss=7.4425, \n",
            "Epoch 5320/6000: train_loss=6.1179, val_loss=7.6741, \n",
            "Epoch 5321/6000: train_loss=6.1374, val_loss=7.6588, \n",
            "Epoch 5322/6000: train_loss=6.1503, val_loss=7.1809, \n",
            "Epoch 5323/6000: train_loss=6.1371, val_loss=7.5298, \n",
            "Epoch 5324/6000: train_loss=6.1106, val_loss=7.7876, \n",
            "Epoch 5325/6000: train_loss=6.1046, val_loss=7.8498, \n",
            "Epoch 5326/6000: train_loss=6.1507, val_loss=7.5535, \n",
            "Epoch 5327/6000: train_loss=6.1072, val_loss=7.7963, \n",
            "Epoch 5328/6000: train_loss=6.0987, val_loss=7.2930, \n",
            "Epoch 5329/6000: train_loss=6.1252, val_loss=7.2779, \n",
            "Epoch 5330/6000: train_loss=6.4865, val_loss=8.5401, \n",
            "Epoch 5331/6000: train_loss=6.2163, val_loss=7.4109, \n",
            "Epoch 5332/6000: train_loss=6.2089, val_loss=7.5186, \n",
            "Epoch 5333/6000: train_loss=6.1948, val_loss=7.7028, \n",
            "Epoch 5334/6000: train_loss=6.1545, val_loss=7.9771, \n",
            "Epoch 5335/6000: train_loss=6.1033, val_loss=7.3457, \n",
            "Epoch 5336/6000: train_loss=6.2733, val_loss=7.6162, \n",
            "Epoch 5337/6000: train_loss=6.1210, val_loss=7.5188, \n",
            "Epoch 5338/6000: train_loss=6.3774, val_loss=8.7313, \n",
            "Epoch 5339/6000: train_loss=6.2788, val_loss=7.2712, \n",
            "Epoch 5340/6000: train_loss=6.1719, val_loss=7.1764, \n",
            "Epoch 5341/6000: train_loss=6.1648, val_loss=7.9835, \n",
            "Epoch 5342/6000: train_loss=6.0906, val_loss=7.6204, \n",
            "Epoch 5343/6000: train_loss=6.4398, val_loss=8.1029, \n",
            "Epoch 5344/6000: train_loss=6.1614, val_loss=7.2552, \n",
            "Epoch 5345/6000: train_loss=6.5914, val_loss=8.8412, \n",
            "Epoch 5346/6000: train_loss=6.8075, val_loss=7.7385, \n",
            "Epoch 5347/6000: train_loss=6.5470, val_loss=8.3055, \n",
            "Epoch 5348/6000: train_loss=6.1179, val_loss=7.3599, \n",
            "Epoch 5349/6000: train_loss=6.1075, val_loss=7.9319, \n",
            "Epoch 5350/6000: train_loss=6.1946, val_loss=8.1728, \n",
            "Epoch 5351/6000: train_loss=6.1785, val_loss=7.1295, \n",
            "Epoch 5352/6000: train_loss=6.2923, val_loss=7.9044, \n",
            "Epoch 5353/6000: train_loss=6.3467, val_loss=7.8253, \n",
            "Epoch 5354/6000: train_loss=6.2681, val_loss=8.2852, \n",
            "Epoch 5355/6000: train_loss=7.5807, val_loss=7.7875, \n",
            "Epoch 5356/6000: train_loss=7.0108, val_loss=9.0374, \n",
            "Epoch 5357/6000: train_loss=6.7320, val_loss=7.5709, \n",
            "Epoch 5358/6000: train_loss=6.6245, val_loss=8.6474, \n",
            "Epoch 5359/6000: train_loss=6.3272, val_loss=7.3246, \n",
            "Epoch 5360/6000: train_loss=7.0586, val_loss=9.2636, \n",
            "Epoch 5361/6000: train_loss=7.2103, val_loss=7.9916, \n",
            "Epoch 5362/6000: train_loss=6.5936, val_loss=8.6197, \n",
            "Epoch 5363/6000: train_loss=6.3045, val_loss=7.2835, \n",
            "Epoch 5364/6000: train_loss=6.1116, val_loss=7.7152, \n",
            "Epoch 5365/6000: train_loss=6.1003, val_loss=7.3788, \n",
            "Epoch 5366/6000: train_loss=6.1183, val_loss=7.3603, \n",
            "Epoch 5367/6000: train_loss=6.2609, val_loss=7.8880, \n",
            "Epoch 5368/6000: train_loss=6.7396, val_loss=7.2646, \n",
            "Epoch 5369/6000: train_loss=6.5477, val_loss=8.6273, \n",
            "Epoch 5370/6000: train_loss=6.8282, val_loss=7.9494, \n",
            "Epoch 5371/6000: train_loss=7.2262, val_loss=9.0926, \n",
            "Epoch 5372/6000: train_loss=6.6502, val_loss=7.3233, \n",
            "Epoch 5373/6000: train_loss=7.4704, val_loss=10.0480, \n",
            "Epoch 5374/6000: train_loss=6.8494, val_loss=7.3641, \n",
            "Epoch 5375/6000: train_loss=6.7082, val_loss=8.6041, \n",
            "Epoch 5376/6000: train_loss=6.6825, val_loss=7.7916, \n",
            "Epoch 5377/6000: train_loss=6.0804, val_loss=7.9039, \n",
            "Epoch 5378/6000: train_loss=6.0688, val_loss=7.3121, \n",
            "Epoch 5379/6000: train_loss=6.0811, val_loss=7.2503, \n",
            "Epoch 5380/6000: train_loss=6.0711, val_loss=7.4566, \n",
            "Epoch 5381/6000: train_loss=6.0677, val_loss=7.8004, \n",
            "Epoch 5382/6000: train_loss=6.0886, val_loss=7.8731, \n",
            "Epoch 5383/6000: train_loss=6.1486, val_loss=7.6361, \n",
            "Epoch 5384/6000: train_loss=6.2428, val_loss=7.6787, \n",
            "Epoch 5385/6000: train_loss=6.2570, val_loss=7.3860, \n",
            "Epoch 5386/6000: train_loss=6.6241, val_loss=8.7030, \n",
            "Epoch 5387/6000: train_loss=6.4324, val_loss=7.4242, \n",
            "Epoch 5388/6000: train_loss=6.3557, val_loss=8.1560, \n",
            "Epoch 5389/6000: train_loss=6.4107, val_loss=7.4631, \n",
            "Epoch 5390/6000: train_loss=6.5916, val_loss=8.7744, \n",
            "Epoch 5391/6000: train_loss=6.2404, val_loss=7.2792, \n",
            "Epoch 5392/6000: train_loss=6.0643, val_loss=7.6147, \n",
            "Epoch 5393/6000: train_loss=6.0587, val_loss=7.6629, \n",
            "Epoch 5394/6000: train_loss=6.0756, val_loss=7.2515, \n",
            "Epoch 5395/6000: train_loss=6.0724, val_loss=7.5033, \n",
            "Epoch 5396/6000: train_loss=6.1945, val_loss=7.6739, \n",
            "Epoch 5397/6000: train_loss=6.0828, val_loss=8.0517, \n",
            "Epoch 5398/6000: train_loss=6.0719, val_loss=7.3578, \n",
            "Epoch 5399/6000: train_loss=6.0673, val_loss=7.4367, \n",
            "Epoch 5400/6000: train_loss=6.0444, val_loss=7.4237, \n",
            "Epoch 5401/6000: train_loss=6.1464, val_loss=7.6169, \n",
            "Epoch 5402/6000: train_loss=6.0397, val_loss=7.4454, \n",
            "Epoch 5403/6000: train_loss=6.2092, val_loss=7.1146, \n",
            "Epoch 5404/6000: train_loss=6.0618, val_loss=7.7509, \n",
            "Epoch 5405/6000: train_loss=6.0539, val_loss=7.8335, \n",
            "Epoch 5406/6000: train_loss=6.0891, val_loss=7.6133, \n",
            "Epoch 5407/6000: train_loss=6.0624, val_loss=7.2323, \n",
            "Epoch 5408/6000: train_loss=6.0452, val_loss=7.5282, \n",
            "Epoch 5409/6000: train_loss=6.0810, val_loss=7.9133, \n",
            "Epoch 5410/6000: train_loss=6.0326, val_loss=7.3883, \n",
            "Epoch 5411/6000: train_loss=6.1502, val_loss=7.6619, \n",
            "Epoch 5412/6000: train_loss=6.1430, val_loss=7.2778, \n",
            "Epoch 5413/6000: train_loss=6.1032, val_loss=7.7825, \n",
            "Epoch 5414/6000: train_loss=6.0481, val_loss=7.6486, \n",
            "Epoch 5415/6000: train_loss=6.1272, val_loss=7.5204, \n",
            "Epoch 5416/6000: train_loss=6.2225, val_loss=8.0899, \n",
            "Epoch 5417/6000: train_loss=6.1407, val_loss=7.1530, \n",
            "Epoch 5418/6000: train_loss=6.0545, val_loss=7.7156, \n",
            "Epoch 5419/6000: train_loss=6.0596, val_loss=7.8229, \n",
            "Epoch 5420/6000: train_loss=6.0341, val_loss=7.2926, \n",
            "Epoch 5421/6000: train_loss=6.2676, val_loss=7.1444, \n",
            "Epoch 5422/6000: train_loss=6.0722, val_loss=7.7079, \n",
            "Epoch 5423/6000: train_loss=6.1002, val_loss=7.4188, \n",
            "Epoch 5424/6000: train_loss=6.0661, val_loss=7.5572, \n",
            "Epoch 5425/6000: train_loss=6.0486, val_loss=7.5423, \n",
            "Epoch 5426/6000: train_loss=6.0441, val_loss=7.7618, \n",
            "Epoch 5427/6000: train_loss=6.0322, val_loss=7.7001, \n",
            "Epoch 5428/6000: train_loss=6.0484, val_loss=7.3427, \n",
            "Epoch 5429/6000: train_loss=6.0199, val_loss=7.3732, \n",
            "Epoch 5430/6000: train_loss=6.0329, val_loss=7.4321, \n",
            "Epoch 5431/6000: train_loss=6.0596, val_loss=7.5032, \n",
            "Epoch 5432/6000: train_loss=6.2216, val_loss=7.3773, \n",
            "Epoch 5433/6000: train_loss=6.6202, val_loss=9.0652, \n",
            "Epoch 5434/6000: train_loss=6.0413, val_loss=7.4122, \n",
            "Epoch 5435/6000: train_loss=6.0532, val_loss=7.3038, \n",
            "Epoch 5436/6000: train_loss=6.2527, val_loss=8.0915, \n",
            "Epoch 5437/6000: train_loss=6.2618, val_loss=7.2717, \n",
            "Epoch 5438/6000: train_loss=6.3498, val_loss=8.1518, \n",
            "Epoch 5439/6000: train_loss=6.3509, val_loss=7.4818, \n",
            "Epoch 5440/6000: train_loss=6.2342, val_loss=8.0997, \n",
            "Epoch 5441/6000: train_loss=6.0119, val_loss=7.4064, \n",
            "Epoch 5442/6000: train_loss=6.1724, val_loss=7.2637, \n",
            "Epoch 5443/6000: train_loss=6.4037, val_loss=8.4220, \n",
            "Epoch 5444/6000: train_loss=6.1111, val_loss=7.1830, \n",
            "Epoch 5445/6000: train_loss=6.3298, val_loss=8.1341, \n",
            "Epoch 5446/6000: train_loss=6.1231, val_loss=7.4237, \n",
            "Epoch 5447/6000: train_loss=6.6882, val_loss=8.7993, \n",
            "Epoch 5448/6000: train_loss=6.7790, val_loss=7.6724, \n",
            "Epoch 5449/6000: train_loss=6.3018, val_loss=7.9284, \n",
            "Epoch 5450/6000: train_loss=6.4562, val_loss=7.3390, \n",
            "Epoch 5451/6000: train_loss=6.0407, val_loss=7.6758, \n",
            "Epoch 5452/6000: train_loss=6.0672, val_loss=7.2779, \n",
            "Epoch 5453/6000: train_loss=6.2019, val_loss=7.9335, \n",
            "Epoch 5454/6000: train_loss=6.1104, val_loss=7.6858, \n",
            "Epoch 5455/6000: train_loss=6.2163, val_loss=7.3598, \n",
            "Epoch 5456/6000: train_loss=6.0622, val_loss=7.5936, \n",
            "Epoch 5457/6000: train_loss=6.1815, val_loss=7.3268, \n",
            "Epoch 5458/6000: train_loss=6.1133, val_loss=8.0097, \n",
            "Epoch 5459/6000: train_loss=6.0853, val_loss=7.2681, \n",
            "Epoch 5460/6000: train_loss=6.5405, val_loss=8.2175, \n",
            "Epoch 5461/6000: train_loss=6.1861, val_loss=7.3711, \n",
            "Epoch 5462/6000: train_loss=6.6441, val_loss=8.8544, \n",
            "Epoch 5463/6000: train_loss=6.1447, val_loss=7.3592, \n",
            "Epoch 5464/6000: train_loss=6.0025, val_loss=7.5793, \n",
            "Epoch 5465/6000: train_loss=6.0870, val_loss=7.5655, \n",
            "Epoch 5466/6000: train_loss=6.0072, val_loss=7.3662, \n",
            "Epoch 5467/6000: train_loss=6.0993, val_loss=7.1353, \n",
            "Epoch 5468/6000: train_loss=6.1655, val_loss=7.9991, \n",
            "Epoch 5469/6000: train_loss=5.9986, val_loss=7.4631, \n",
            "Epoch 5470/6000: train_loss=6.0313, val_loss=7.5384, \n",
            "Epoch 5471/6000: train_loss=6.4809, val_loss=7.5676, \n",
            "Epoch 5472/6000: train_loss=6.9680, val_loss=9.2707, \n",
            "Epoch 5473/6000: train_loss=6.1713, val_loss=6.9112, \n",
            "Epoch 5474/6000: train_loss=6.0256, val_loss=7.4065, \n",
            "Epoch 5475/6000: train_loss=6.0232, val_loss=7.6754, \n",
            "Epoch 5476/6000: train_loss=6.0698, val_loss=7.5425, \n",
            "Epoch 5477/6000: train_loss=6.0333, val_loss=7.1046, \n",
            "Epoch 5478/6000: train_loss=6.0737, val_loss=7.1840, \n",
            "Epoch 5479/6000: train_loss=6.2822, val_loss=7.1970, \n",
            "Epoch 5480/6000: train_loss=6.0568, val_loss=7.8195, \n",
            "Epoch 5481/6000: train_loss=6.1635, val_loss=7.9439, \n",
            "Epoch 5482/6000: train_loss=6.0506, val_loss=6.9676, \n",
            "Epoch 5483/6000: train_loss=6.2624, val_loss=8.0536, \n",
            "Epoch 5484/6000: train_loss=7.2334, val_loss=8.0994, \n",
            "Epoch 5485/6000: train_loss=6.8794, val_loss=8.7627, \n",
            "Epoch 5486/6000: train_loss=7.1903, val_loss=7.4782, \n",
            "Epoch 5487/6000: train_loss=6.6968, val_loss=8.9911, \n",
            "Epoch 5488/6000: train_loss=6.4047, val_loss=7.5674, \n",
            "Epoch 5489/6000: train_loss=6.3283, val_loss=7.9559, \n",
            "Epoch 5490/6000: train_loss=6.0560, val_loss=7.0799, \n",
            "Epoch 5491/6000: train_loss=6.2818, val_loss=8.5684, \n",
            "Epoch 5492/6000: train_loss=6.0139, val_loss=7.4246, \n",
            "Epoch 5493/6000: train_loss=6.1935, val_loss=7.0785, \n",
            "Epoch 5494/6000: train_loss=6.2587, val_loss=7.3005, \n",
            "Epoch 5495/6000: train_loss=6.2456, val_loss=8.6447, \n",
            "Epoch 5496/6000: train_loss=5.9758, val_loss=7.3243, \n",
            "Epoch 5497/6000: train_loss=6.1959, val_loss=6.6889, \n",
            "Epoch 5498/6000: train_loss=6.0634, val_loss=7.4835, \n",
            "Epoch 5499/6000: train_loss=6.3442, val_loss=7.9104, \n",
            "Epoch 5500/6000: train_loss=5.9969, val_loss=7.3355, \n",
            "Epoch 5501/6000: train_loss=6.0497, val_loss=7.0406, \n",
            "Epoch 5502/6000: train_loss=5.9830, val_loss=7.3735, \n",
            "Epoch 5503/6000: train_loss=6.0955, val_loss=7.7334, \n",
            "Epoch 5504/6000: train_loss=6.1527, val_loss=7.8640, \n",
            "Epoch 5505/6000: train_loss=6.4613, val_loss=6.9162, \n",
            "Epoch 5506/6000: train_loss=6.3117, val_loss=8.1761, \n",
            "Epoch 5507/6000: train_loss=6.0854, val_loss=7.6673, \n",
            "Epoch 5508/6000: train_loss=5.9908, val_loss=7.4248, \n",
            "Epoch 5509/6000: train_loss=5.9727, val_loss=7.1312, \n",
            "Epoch 5510/6000: train_loss=5.9985, val_loss=7.6031, \n",
            "Epoch 5511/6000: train_loss=6.0827, val_loss=7.3144, \n",
            "Epoch 5512/6000: train_loss=5.9804, val_loss=7.5768, \n",
            "Epoch 5513/6000: train_loss=5.9605, val_loss=7.3420, \n",
            "Epoch 5514/6000: train_loss=5.9889, val_loss=7.3273, \n",
            "Epoch 5515/6000: train_loss=5.9743, val_loss=7.6417, \n",
            "Epoch 5516/6000: train_loss=6.0429, val_loss=7.1110, \n",
            "Epoch 5517/6000: train_loss=5.9548, val_loss=7.2650, \n",
            "Epoch 5518/6000: train_loss=6.1304, val_loss=8.2077, \n",
            "Epoch 5519/6000: train_loss=6.7046, val_loss=7.4921, \n",
            "Epoch 5520/6000: train_loss=6.8253, val_loss=8.5278, \n",
            "Epoch 5521/6000: train_loss=6.5131, val_loss=7.3182, \n",
            "Epoch 5522/6000: train_loss=6.2070, val_loss=8.5090, \n",
            "Epoch 5523/6000: train_loss=5.9706, val_loss=7.6633, \n",
            "Epoch 5524/6000: train_loss=6.0510, val_loss=7.0056, \n",
            "Epoch 5525/6000: train_loss=6.0126, val_loss=6.9394, \n",
            "Epoch 5526/6000: train_loss=6.0178, val_loss=7.6308, \n",
            "Epoch 5527/6000: train_loss=5.9781, val_loss=7.6434, \n",
            "Epoch 5528/6000: train_loss=6.0498, val_loss=6.9570, \n",
            "Epoch 5529/6000: train_loss=6.0817, val_loss=7.6142, \n",
            "Epoch 5530/6000: train_loss=6.0860, val_loss=7.4741, \n",
            "Epoch 5531/6000: train_loss=5.9542, val_loss=7.5872, \n",
            "Epoch 5532/6000: train_loss=6.0098, val_loss=7.0469, \n",
            "Epoch 5533/6000: train_loss=6.0184, val_loss=7.1349, \n",
            "Epoch 5534/6000: train_loss=5.9782, val_loss=7.5315, \n",
            "Epoch 5535/6000: train_loss=6.2962, val_loss=8.2063, \n",
            "Epoch 5536/6000: train_loss=6.1505, val_loss=7.0786, \n",
            "Epoch 5537/6000: train_loss=6.3075, val_loss=8.1195, \n",
            "Epoch 5538/6000: train_loss=6.1474, val_loss=7.4184, \n",
            "Epoch 5539/6000: train_loss=6.1625, val_loss=8.0719, \n",
            "Epoch 5540/6000: train_loss=6.1357, val_loss=7.1800, \n",
            "Epoch 5541/6000: train_loss=6.2538, val_loss=8.1698, \n",
            "Epoch 5542/6000: train_loss=5.9813, val_loss=7.3271, \n",
            "Epoch 5543/6000: train_loss=6.0115, val_loss=7.7465, \n",
            "Epoch 5544/6000: train_loss=5.9380, val_loss=7.3754, \n",
            "Epoch 5545/6000: train_loss=6.1796, val_loss=7.1860, \n",
            "Epoch 5546/6000: train_loss=6.6313, val_loss=8.3663, \n",
            "Epoch 5547/6000: train_loss=6.4519, val_loss=7.3209, \n",
            "Epoch 5548/6000: train_loss=6.9311, val_loss=9.4053, \n",
            "Epoch 5549/6000: train_loss=6.5967, val_loss=7.4396, \n",
            "Epoch 5550/6000: train_loss=6.5503, val_loss=8.5054, \n",
            "Epoch 5551/6000: train_loss=6.1273, val_loss=7.3216, \n",
            "Epoch 5552/6000: train_loss=6.6802, val_loss=8.8239, \n",
            "Epoch 5553/6000: train_loss=6.1239, val_loss=7.2486, \n",
            "Epoch 5554/6000: train_loss=5.9857, val_loss=7.4147, \n",
            "Epoch 5555/6000: train_loss=5.9312, val_loss=7.2126, \n",
            "Epoch 5556/6000: train_loss=6.2002, val_loss=7.2806, \n",
            "Epoch 5557/6000: train_loss=6.3885, val_loss=8.3385, \n",
            "Epoch 5558/6000: train_loss=6.4198, val_loss=7.1318, \n",
            "Epoch 5559/6000: train_loss=6.5324, val_loss=8.1982, \n",
            "Epoch 5560/6000: train_loss=6.0548, val_loss=7.2257, \n",
            "Epoch 5561/6000: train_loss=5.9329, val_loss=7.5231, \n",
            "Epoch 5562/6000: train_loss=6.0074, val_loss=7.3598, \n",
            "Epoch 5563/6000: train_loss=6.0857, val_loss=7.0002, \n",
            "Epoch 5564/6000: train_loss=5.9654, val_loss=7.6616, \n",
            "Epoch 5565/6000: train_loss=5.9198, val_loss=7.4100, \n",
            "Epoch 5566/6000: train_loss=5.9947, val_loss=7.5287, \n",
            "Epoch 5567/6000: train_loss=5.9959, val_loss=7.2003, \n",
            "Epoch 5568/6000: train_loss=6.3691, val_loss=8.3452, \n",
            "Epoch 5569/6000: train_loss=6.2317, val_loss=7.2174, \n",
            "Epoch 5570/6000: train_loss=6.1369, val_loss=8.1198, \n",
            "Epoch 5571/6000: train_loss=6.0630, val_loss=7.1537, \n",
            "Epoch 5572/6000: train_loss=5.9211, val_loss=7.1656, \n",
            "Epoch 5573/6000: train_loss=6.1173, val_loss=7.2137, \n",
            "Epoch 5574/6000: train_loss=5.9388, val_loss=7.5954, \n",
            "Epoch 5575/6000: train_loss=5.9274, val_loss=7.1520, \n",
            "Epoch 5576/6000: train_loss=5.9563, val_loss=7.0446, \n",
            "Epoch 5577/6000: train_loss=5.9200, val_loss=7.3724, \n",
            "Epoch 5578/6000: train_loss=6.0210, val_loss=7.7496, \n",
            "Epoch 5579/6000: train_loss=6.1262, val_loss=7.0733, \n",
            "Epoch 5580/6000: train_loss=6.0241, val_loss=7.6249, \n",
            "Epoch 5581/6000: train_loss=5.9044, val_loss=7.2322, \n",
            "Epoch 5582/6000: train_loss=5.9171, val_loss=7.3974, \n",
            "Epoch 5583/6000: train_loss=5.9621, val_loss=7.6427, \n",
            "Epoch 5584/6000: train_loss=5.9128, val_loss=7.2702, \n",
            "Epoch 5585/6000: train_loss=5.9058, val_loss=7.2827, \n",
            "Epoch 5586/6000: train_loss=5.9231, val_loss=7.2393, \n",
            "Epoch 5587/6000: train_loss=5.9679, val_loss=7.6070, \n",
            "Epoch 5588/6000: train_loss=5.9073, val_loss=7.2670, \n",
            "Epoch 5589/6000: train_loss=5.9313, val_loss=7.3081, \n",
            "Epoch 5590/6000: train_loss=5.9788, val_loss=7.0893, \n",
            "Epoch 5591/6000: train_loss=6.1200, val_loss=7.7921, \n",
            "Epoch 5592/6000: train_loss=6.2113, val_loss=7.3471, \n",
            "Epoch 5593/6000: train_loss=6.1111, val_loss=7.8865, \n",
            "Epoch 5594/6000: train_loss=5.9172, val_loss=7.1838, \n",
            "Epoch 5595/6000: train_loss=5.9341, val_loss=7.3034, \n",
            "Epoch 5596/6000: train_loss=5.9598, val_loss=7.6432, \n",
            "Epoch 5597/6000: train_loss=6.1345, val_loss=7.1363, \n",
            "Epoch 5598/6000: train_loss=6.7724, val_loss=8.7963, \n",
            "Epoch 5599/6000: train_loss=6.3024, val_loss=7.2871, \n",
            "Epoch 5600/6000: train_loss=6.1362, val_loss=7.9841, \n",
            "Epoch 5601/6000: train_loss=5.9930, val_loss=6.9477, \n",
            "Epoch 5602/6000: train_loss=5.9314, val_loss=7.1548, \n",
            "Epoch 5603/6000: train_loss=6.0195, val_loss=7.8749, \n",
            "Epoch 5604/6000: train_loss=6.0653, val_loss=7.3089, \n",
            "Epoch 5605/6000: train_loss=5.9294, val_loss=7.0772, \n",
            "Epoch 5606/6000: train_loss=6.0544, val_loss=7.1706, \n",
            "Epoch 5607/6000: train_loss=6.3083, val_loss=8.4304, \n",
            "Epoch 5608/6000: train_loss=6.0728, val_loss=7.0140, \n",
            "Epoch 5609/6000: train_loss=6.0738, val_loss=7.3656, \n",
            "Epoch 5610/6000: train_loss=5.9843, val_loss=7.7319, \n",
            "Epoch 5611/6000: train_loss=5.9664, val_loss=7.5966, \n",
            "Epoch 5612/6000: train_loss=5.9296, val_loss=7.5348, \n",
            "Epoch 5613/6000: train_loss=5.8944, val_loss=7.1656, \n",
            "Epoch 5614/6000: train_loss=5.9814, val_loss=7.3455, \n",
            "Epoch 5615/6000: train_loss=5.9461, val_loss=7.2346, \n",
            "Epoch 5616/6000: train_loss=5.9093, val_loss=7.6132, \n",
            "Epoch 5617/6000: train_loss=5.8868, val_loss=7.2100, \n",
            "Epoch 5618/6000: train_loss=5.9325, val_loss=7.2426, \n",
            "Epoch 5619/6000: train_loss=5.9207, val_loss=7.0414, \n",
            "Epoch 5620/6000: train_loss=5.9772, val_loss=7.2076, \n",
            "Epoch 5621/6000: train_loss=6.2424, val_loss=8.1377, \n",
            "Epoch 5622/6000: train_loss=6.4374, val_loss=7.2257, \n",
            "Epoch 5623/6000: train_loss=5.9609, val_loss=7.6729, \n",
            "Epoch 5624/6000: train_loss=5.9633, val_loss=7.8184, \n",
            "Epoch 5625/6000: train_loss=6.0227, val_loss=7.0258, \n",
            "Epoch 5626/6000: train_loss=5.9648, val_loss=6.9948, \n",
            "Epoch 5627/6000: train_loss=6.0724, val_loss=7.2628, \n",
            "Epoch 5628/6000: train_loss=5.9868, val_loss=7.7459, \n",
            "Epoch 5629/6000: train_loss=5.9087, val_loss=7.0057, \n",
            "Epoch 5630/6000: train_loss=5.9060, val_loss=7.1671, \n",
            "Epoch 5631/6000: train_loss=5.8964, val_loss=7.5313, \n",
            "Epoch 5632/6000: train_loss=5.8987, val_loss=7.5981, \n",
            "Epoch 5633/6000: train_loss=6.0549, val_loss=7.0246, \n",
            "Epoch 5634/6000: train_loss=5.9058, val_loss=7.1752, \n",
            "Epoch 5635/6000: train_loss=6.0366, val_loss=7.1200, \n",
            "Epoch 5636/6000: train_loss=5.8816, val_loss=7.4318, \n",
            "Epoch 5637/6000: train_loss=5.8827, val_loss=7.5076, \n",
            "Epoch 5638/6000: train_loss=5.9090, val_loss=7.3676, \n",
            "Epoch 5639/6000: train_loss=6.2654, val_loss=7.0923, \n",
            "Epoch 5640/6000: train_loss=6.5869, val_loss=8.6847, \n",
            "Epoch 5641/6000: train_loss=6.5406, val_loss=7.2532, \n",
            "Epoch 5642/6000: train_loss=6.0896, val_loss=7.6877, \n",
            "Epoch 5643/6000: train_loss=5.9147, val_loss=7.2645, \n",
            "Epoch 5644/6000: train_loss=6.0122, val_loss=7.2707, \n",
            "Epoch 5645/6000: train_loss=6.2967, val_loss=7.2783, \n",
            "Epoch 5646/6000: train_loss=5.9943, val_loss=7.3368, \n",
            "Epoch 5647/6000: train_loss=5.9039, val_loss=7.0341, \n",
            "Epoch 5648/6000: train_loss=5.9700, val_loss=7.8130, \n",
            "Epoch 5649/6000: train_loss=6.0460, val_loss=7.9555, \n",
            "Epoch 5650/6000: train_loss=5.9690, val_loss=6.8073, \n",
            "Epoch 5651/6000: train_loss=5.9001, val_loss=7.0570, \n",
            "Epoch 5652/6000: train_loss=5.9799, val_loss=7.5247, \n",
            "Epoch 5653/6000: train_loss=6.3810, val_loss=8.4208, \n",
            "Epoch 5654/6000: train_loss=6.0006, val_loss=6.8900, \n",
            "Epoch 5655/6000: train_loss=6.0752, val_loss=7.9050, \n",
            "Epoch 5656/6000: train_loss=6.4544, val_loss=7.4767, \n",
            "Epoch 5657/6000: train_loss=7.4344, val_loss=9.4582, \n",
            "Epoch 5658/6000: train_loss=7.2042, val_loss=7.5395, \n",
            "Epoch 5659/6000: train_loss=7.9244, val_loss=10.5911, \n",
            "Epoch 5660/6000: train_loss=7.7312, val_loss=7.9751, \n",
            "Epoch 5661/6000: train_loss=8.2165, val_loss=10.4711, \n",
            "Epoch 5662/6000: train_loss=7.5403, val_loss=7.9777, \n",
            "Epoch 5663/6000: train_loss=8.1058, val_loss=10.6098, \n",
            "Epoch 5664/6000: train_loss=6.9189, val_loss=7.3366, \n",
            "Epoch 5665/6000: train_loss=6.0892, val_loss=7.7011, \n",
            "Epoch 5666/6000: train_loss=5.9666, val_loss=7.5959, \n",
            "Epoch 5667/6000: train_loss=5.8813, val_loss=7.2210, \n",
            "Epoch 5668/6000: train_loss=5.8757, val_loss=7.2182, \n",
            "Epoch 5669/6000: train_loss=5.8869, val_loss=7.2749, \n",
            "Epoch 5670/6000: train_loss=6.0043, val_loss=7.2731, \n",
            "Epoch 5671/6000: train_loss=6.0379, val_loss=7.8460, \n",
            "Epoch 5672/6000: train_loss=5.8938, val_loss=6.9123, \n",
            "Epoch 5673/6000: train_loss=6.1715, val_loss=7.7399, \n",
            "Epoch 5674/6000: train_loss=5.9951, val_loss=7.1823, \n",
            "Epoch 5675/6000: train_loss=5.8742, val_loss=7.4932, \n",
            "Epoch 5676/6000: train_loss=5.8821, val_loss=7.3880, \n",
            "Epoch 5677/6000: train_loss=6.1140, val_loss=6.9272, \n",
            "Epoch 5678/6000: train_loss=6.2690, val_loss=8.0199, \n",
            "Epoch 5679/6000: train_loss=6.2243, val_loss=7.2280, \n",
            "Epoch 5680/6000: train_loss=6.5105, val_loss=8.5043, \n",
            "Epoch 5681/6000: train_loss=6.7308, val_loss=7.4800, \n",
            "Epoch 5682/6000: train_loss=8.0041, val_loss=10.3949, \n",
            "Epoch 5683/6000: train_loss=8.0382, val_loss=8.3025, \n",
            "Epoch 5684/6000: train_loss=6.5097, val_loss=8.5207, \n",
            "Epoch 5685/6000: train_loss=7.1628, val_loss=7.7373, \n",
            "Epoch 5686/6000: train_loss=7.5184, val_loss=9.9001, \n",
            "Epoch 5687/6000: train_loss=6.8909, val_loss=7.1482, \n",
            "Epoch 5688/6000: train_loss=6.8892, val_loss=8.8825, \n",
            "Epoch 5689/6000: train_loss=6.3982, val_loss=7.6361, \n",
            "Epoch 5690/6000: train_loss=6.0197, val_loss=7.8457, \n",
            "Epoch 5691/6000: train_loss=5.8716, val_loss=6.9792, \n",
            "Epoch 5692/6000: train_loss=5.8376, val_loss=7.1975, \n",
            "Epoch 5693/6000: train_loss=5.9817, val_loss=7.8124, \n",
            "Epoch 5694/6000: train_loss=5.8539, val_loss=7.3326, \n",
            "Epoch 5695/6000: train_loss=5.9571, val_loss=7.6365, \n",
            "Epoch 5696/6000: train_loss=5.9674, val_loss=6.8948, \n",
            "Epoch 5697/6000: train_loss=5.8446, val_loss=7.2463, \n",
            "Epoch 5698/6000: train_loss=5.9027, val_loss=7.6516, \n",
            "Epoch 5699/6000: train_loss=5.9615, val_loss=6.9388, \n",
            "Epoch 5700/6000: train_loss=5.9577, val_loss=7.3026, \n",
            "Epoch 5701/6000: train_loss=5.9389, val_loss=7.3371, \n",
            "Epoch 5702/6000: train_loss=5.9172, val_loss=7.8586, \n",
            "Epoch 5703/6000: train_loss=5.9394, val_loss=6.8298, \n",
            "Epoch 5704/6000: train_loss=5.9078, val_loss=6.8635, \n",
            "Epoch 5705/6000: train_loss=5.9178, val_loss=7.5917, \n",
            "Epoch 5706/6000: train_loss=6.2749, val_loss=7.5193, \n",
            "Epoch 5707/6000: train_loss=5.8777, val_loss=7.4670, \n",
            "Epoch 5708/6000: train_loss=5.9096, val_loss=6.9432, \n",
            "Epoch 5709/6000: train_loss=5.8572, val_loss=7.2023, \n",
            "Epoch 5710/6000: train_loss=5.9149, val_loss=7.5810, \n",
            "Epoch 5711/6000: train_loss=5.8589, val_loss=7.2381, \n",
            "Epoch 5712/6000: train_loss=5.9451, val_loss=6.7914, \n",
            "Epoch 5713/6000: train_loss=5.8500, val_loss=7.3482, \n",
            "Epoch 5714/6000: train_loss=5.8995, val_loss=7.8075, \n",
            "Epoch 5715/6000: train_loss=5.9141, val_loss=7.1071, \n",
            "Epoch 5716/6000: train_loss=5.9231, val_loss=7.2657, \n",
            "Epoch 5717/6000: train_loss=5.8783, val_loss=7.0411, \n",
            "Epoch 5718/6000: train_loss=5.8983, val_loss=7.6898, \n",
            "Epoch 5719/6000: train_loss=5.8769, val_loss=7.0165, \n",
            "Epoch 5720/6000: train_loss=5.8231, val_loss=7.2083, \n",
            "Epoch 5721/6000: train_loss=5.8562, val_loss=7.4120, \n",
            "Epoch 5722/6000: train_loss=5.8359, val_loss=7.1635, \n",
            "Epoch 5723/6000: train_loss=6.0507, val_loss=7.5010, \n",
            "Epoch 5724/6000: train_loss=7.0930, val_loss=7.5932, \n",
            "Epoch 5725/6000: train_loss=7.3084, val_loss=9.9207, \n",
            "Epoch 5726/6000: train_loss=7.4084, val_loss=7.9684, \n",
            "Epoch 5727/6000: train_loss=7.0878, val_loss=8.7991, \n",
            "Epoch 5728/6000: train_loss=6.7181, val_loss=7.3209, \n",
            "Epoch 5729/6000: train_loss=7.1572, val_loss=9.6796, \n",
            "Epoch 5730/6000: train_loss=8.6868, val_loss=8.5355, \n",
            "Epoch 5731/6000: train_loss=7.8447, val_loss=10.1970, \n",
            "Epoch 5732/6000: train_loss=6.2951, val_loss=7.2999, \n",
            "Epoch 5733/6000: train_loss=6.0968, val_loss=7.5550, \n",
            "Epoch 5734/6000: train_loss=5.9131, val_loss=6.8999, \n",
            "Epoch 5735/6000: train_loss=5.8832, val_loss=7.2911, \n",
            "Epoch 5736/6000: train_loss=5.8445, val_loss=7.3777, \n",
            "Epoch 5737/6000: train_loss=6.0069, val_loss=7.0067, \n",
            "Epoch 5738/6000: train_loss=6.4654, val_loss=8.4100, \n",
            "Epoch 5739/6000: train_loss=6.1329, val_loss=7.1108, \n",
            "Epoch 5740/6000: train_loss=6.4760, val_loss=8.4411, \n",
            "Epoch 5741/6000: train_loss=6.3976, val_loss=7.0819, \n",
            "Epoch 5742/6000: train_loss=6.0754, val_loss=7.7676, \n",
            "Epoch 5743/6000: train_loss=5.8497, val_loss=7.1455, \n",
            "Epoch 5744/6000: train_loss=5.8114, val_loss=7.1496, \n",
            "Epoch 5745/6000: train_loss=5.8659, val_loss=6.9668, \n",
            "Epoch 5746/6000: train_loss=5.9893, val_loss=7.7395, \n",
            "Epoch 5747/6000: train_loss=5.8429, val_loss=7.0673, \n",
            "Epoch 5748/6000: train_loss=6.2446, val_loss=7.9330, \n",
            "Epoch 5749/6000: train_loss=5.8450, val_loss=7.0748, \n",
            "Epoch 5750/6000: train_loss=5.8366, val_loss=7.5111, \n",
            "Epoch 5751/6000: train_loss=5.8261, val_loss=7.1268, \n",
            "Epoch 5752/6000: train_loss=5.8063, val_loss=7.0601, \n",
            "Epoch 5753/6000: train_loss=5.8800, val_loss=7.0225, \n",
            "Epoch 5754/6000: train_loss=5.8246, val_loss=7.4306, \n",
            "Epoch 5755/6000: train_loss=6.0511, val_loss=7.0025, \n",
            "Epoch 5756/6000: train_loss=5.9889, val_loss=7.1702, \n",
            "Epoch 5757/6000: train_loss=5.9860, val_loss=7.0247, \n",
            "Epoch 5758/6000: train_loss=5.8673, val_loss=7.5573, \n",
            "Epoch 5759/6000: train_loss=5.8477, val_loss=7.4945, \n",
            "Epoch 5760/6000: train_loss=5.9396, val_loss=6.8631, \n",
            "Epoch 5761/6000: train_loss=5.7928, val_loss=7.2757, \n",
            "Epoch 5762/6000: train_loss=5.9485, val_loss=7.9744, \n",
            "Epoch 5763/6000: train_loss=5.7934, val_loss=7.2518, \n",
            "Epoch 5764/6000: train_loss=5.9009, val_loss=6.9005, \n",
            "Epoch 5765/6000: train_loss=5.8651, val_loss=6.9670, \n",
            "Epoch 5766/6000: train_loss=5.9325, val_loss=7.8774, \n",
            "Epoch 5767/6000: train_loss=6.2727, val_loss=7.3615, \n",
            "Epoch 5768/6000: train_loss=6.2276, val_loss=7.7701, \n",
            "Epoch 5769/6000: train_loss=6.1434, val_loss=6.7769, \n",
            "Epoch 5770/6000: train_loss=6.2397, val_loss=8.0991, \n",
            "Epoch 5771/6000: train_loss=6.6309, val_loss=7.7679, \n",
            "Epoch 5772/6000: train_loss=5.9305, val_loss=7.5983, \n",
            "Epoch 5773/6000: train_loss=5.8839, val_loss=6.7879, \n",
            "Epoch 5774/6000: train_loss=5.8110, val_loss=6.8973, \n",
            "Epoch 5775/6000: train_loss=5.7874, val_loss=7.3042, \n",
            "Epoch 5776/6000: train_loss=5.8041, val_loss=7.4527, \n",
            "Epoch 5777/6000: train_loss=5.8031, val_loss=7.2410, \n",
            "Epoch 5778/6000: train_loss=5.8091, val_loss=6.9618, \n",
            "Epoch 5779/6000: train_loss=5.8375, val_loss=7.2296, \n",
            "Epoch 5780/6000: train_loss=5.8935, val_loss=7.5910, \n",
            "Epoch 5781/6000: train_loss=5.8695, val_loss=6.9073, \n",
            "Epoch 5782/6000: train_loss=6.1087, val_loss=7.7618, \n",
            "Epoch 5783/6000: train_loss=5.8410, val_loss=7.0906, \n",
            "Epoch 5784/6000: train_loss=5.8530, val_loss=7.6134, \n",
            "Epoch 5785/6000: train_loss=5.8056, val_loss=7.2500, \n",
            "Epoch 5786/6000: train_loss=5.9311, val_loss=6.9133, \n",
            "Epoch 5787/6000: train_loss=5.8565, val_loss=7.2146, \n",
            "Epoch 5788/6000: train_loss=5.8141, val_loss=7.3343, \n",
            "Epoch 5789/6000: train_loss=5.7905, val_loss=7.4151, \n",
            "Epoch 5790/6000: train_loss=5.8286, val_loss=6.8151, \n",
            "Epoch 5791/6000: train_loss=5.8216, val_loss=6.8818, \n",
            "Epoch 5792/6000: train_loss=5.8953, val_loss=7.5277, \n",
            "Epoch 5793/6000: train_loss=5.8493, val_loss=7.5316, \n",
            "Epoch 5794/6000: train_loss=6.3813, val_loss=6.7958, \n",
            "Epoch 5795/6000: train_loss=6.8021, val_loss=8.6349, \n",
            "Epoch 5796/6000: train_loss=6.3571, val_loss=7.5644, \n",
            "Epoch 5797/6000: train_loss=6.0241, val_loss=8.0681, \n",
            "Epoch 5798/6000: train_loss=6.2484, val_loss=7.0203, \n",
            "Epoch 5799/6000: train_loss=6.5653, val_loss=8.3590, \n",
            "Epoch 5800/6000: train_loss=6.2520, val_loss=7.2145, \n",
            "Epoch 5801/6000: train_loss=6.2676, val_loss=8.1427, \n",
            "Epoch 5802/6000: train_loss=6.1183, val_loss=7.0356, \n",
            "Epoch 5803/6000: train_loss=6.9724, val_loss=9.1856, \n",
            "Epoch 5804/6000: train_loss=6.4201, val_loss=7.2806, \n",
            "Epoch 5805/6000: train_loss=6.7066, val_loss=8.4214, \n",
            "Epoch 5806/6000: train_loss=6.1845, val_loss=7.1718, \n",
            "Epoch 5807/6000: train_loss=6.9196, val_loss=9.3901, \n",
            "Epoch 5808/6000: train_loss=6.9409, val_loss=7.3402, \n",
            "Epoch 5809/6000: train_loss=6.9724, val_loss=8.8373, \n",
            "Epoch 5810/6000: train_loss=6.9833, val_loss=7.6266, \n",
            "Epoch 5811/6000: train_loss=5.9903, val_loss=7.7267, \n",
            "Epoch 5812/6000: train_loss=5.8115, val_loss=7.0051, \n",
            "Epoch 5813/6000: train_loss=5.8641, val_loss=7.2091, \n",
            "Epoch 5814/6000: train_loss=5.7841, val_loss=7.3150, \n",
            "Epoch 5815/6000: train_loss=5.8054, val_loss=7.5506, \n",
            "Epoch 5816/6000: train_loss=6.0139, val_loss=6.8802, \n",
            "Epoch 5817/6000: train_loss=6.1860, val_loss=7.3453, \n",
            "Epoch 5818/6000: train_loss=6.2534, val_loss=7.1541, \n",
            "Epoch 5819/6000: train_loss=6.5393, val_loss=9.3502, \n",
            "Epoch 5820/6000: train_loss=5.9495, val_loss=7.0716, \n",
            "Epoch 5821/6000: train_loss=6.1091, val_loss=7.2280, \n",
            "Epoch 5822/6000: train_loss=5.7808, val_loss=7.2786, \n",
            "Epoch 5823/6000: train_loss=5.9150, val_loss=7.8984, \n",
            "Epoch 5824/6000: train_loss=5.8065, val_loss=7.0466, \n",
            "Epoch 5825/6000: train_loss=5.9022, val_loss=6.7328, \n",
            "Epoch 5826/6000: train_loss=5.9017, val_loss=7.3152, \n",
            "Epoch 5827/6000: train_loss=5.9358, val_loss=8.1442, \n",
            "Epoch 5828/6000: train_loss=6.0253, val_loss=6.8982, \n",
            "Epoch 5829/6000: train_loss=6.0329, val_loss=7.3053, \n",
            "Epoch 5830/6000: train_loss=6.4550, val_loss=7.1584, \n",
            "Epoch 5831/6000: train_loss=5.9860, val_loss=7.9364, \n",
            "Epoch 5832/6000: train_loss=5.7671, val_loss=7.0693, \n",
            "Epoch 5833/6000: train_loss=5.8435, val_loss=6.8557, \n",
            "Epoch 5834/6000: train_loss=5.8662, val_loss=7.7444, \n",
            "Epoch 5835/6000: train_loss=5.7914, val_loss=7.4015, \n",
            "Epoch 5836/6000: train_loss=5.8037, val_loss=6.9220, \n",
            "Epoch 5837/6000: train_loss=5.8456, val_loss=6.8035, \n",
            "Epoch 5838/6000: train_loss=6.1769, val_loss=8.3599, \n",
            "Epoch 5839/6000: train_loss=6.2773, val_loss=7.2466, \n",
            "Epoch 5840/6000: train_loss=6.3409, val_loss=7.8134, \n",
            "Epoch 5841/6000: train_loss=6.3318, val_loss=7.0039, \n",
            "Epoch 5842/6000: train_loss=6.4161, val_loss=8.6329, \n",
            "Epoch 5843/6000: train_loss=5.8744, val_loss=7.0682, \n",
            "Epoch 5844/6000: train_loss=6.0499, val_loss=7.5127, \n",
            "Epoch 5845/6000: train_loss=6.3061, val_loss=7.1669, \n",
            "Epoch 5846/6000: train_loss=6.0408, val_loss=8.2482, \n",
            "Epoch 5847/6000: train_loss=6.2209, val_loss=7.2456, \n",
            "Epoch 5848/6000: train_loss=5.8236, val_loss=7.1852, \n",
            "Epoch 5849/6000: train_loss=5.7668, val_loss=7.0558, \n",
            "Epoch 5850/6000: train_loss=5.7649, val_loss=7.2928, \n",
            "Epoch 5851/6000: train_loss=5.7719, val_loss=7.3352, \n",
            "Epoch 5852/6000: train_loss=5.8390, val_loss=6.9011, \n",
            "Epoch 5853/6000: train_loss=6.0452, val_loss=7.9297, \n",
            "Epoch 5854/6000: train_loss=6.5861, val_loss=7.4404, \n",
            "Epoch 5855/6000: train_loss=6.4118, val_loss=8.4199, \n",
            "Epoch 5856/6000: train_loss=5.9519, val_loss=6.9449, \n",
            "Epoch 5857/6000: train_loss=6.0689, val_loss=7.7100, \n",
            "Epoch 5858/6000: train_loss=6.5196, val_loss=7.3432, \n",
            "Epoch 5859/6000: train_loss=6.1866, val_loss=8.2284, \n",
            "Epoch 5860/6000: train_loss=6.0432, val_loss=7.0555, \n",
            "Epoch 5861/6000: train_loss=6.0541, val_loss=7.7471, \n",
            "Epoch 5862/6000: train_loss=5.7676, val_loss=7.0328, \n",
            "Epoch 5863/6000: train_loss=5.7499, val_loss=7.1497, \n",
            "Epoch 5864/6000: train_loss=5.7923, val_loss=7.1293, \n",
            "Epoch 5865/6000: train_loss=5.7254, val_loss=7.0531, \n",
            "Epoch 5866/6000: train_loss=5.7487, val_loss=6.9938, \n",
            "Epoch 5867/6000: train_loss=5.8412, val_loss=7.0470, \n",
            "Epoch 5868/6000: train_loss=5.7342, val_loss=7.2111, \n",
            "Epoch 5869/6000: train_loss=5.7563, val_loss=7.0053, \n",
            "Epoch 5870/6000: train_loss=5.7296, val_loss=7.3257, \n",
            "Epoch 5871/6000: train_loss=6.0577, val_loss=7.9644, \n",
            "Epoch 5872/6000: train_loss=5.8015, val_loss=6.9360, \n",
            "Epoch 5873/6000: train_loss=5.7745, val_loss=7.2332, \n",
            "Epoch 5874/6000: train_loss=5.7752, val_loss=7.2022, \n",
            "Epoch 5875/6000: train_loss=5.7973, val_loss=7.1905, \n",
            "Epoch 5876/6000: train_loss=5.7872, val_loss=6.7995, \n",
            "Epoch 5877/6000: train_loss=5.8027, val_loss=7.1466, \n",
            "Epoch 5878/6000: train_loss=5.8502, val_loss=7.0436, \n",
            "Epoch 5879/6000: train_loss=5.7558, val_loss=7.1913, \n",
            "Epoch 5880/6000: train_loss=5.7678, val_loss=7.0084, \n",
            "Epoch 5881/6000: train_loss=5.7323, val_loss=7.3680, \n",
            "Epoch 5882/6000: train_loss=5.7776, val_loss=7.6036, \n",
            "Epoch 5883/6000: train_loss=5.7823, val_loss=7.1790, \n",
            "Epoch 5884/6000: train_loss=5.9394, val_loss=6.9114, \n",
            "Epoch 5885/6000: train_loss=6.2799, val_loss=8.5093, \n",
            "Epoch 5886/6000: train_loss=6.3342, val_loss=7.4045, \n",
            "Epoch 5887/6000: train_loss=6.8833, val_loss=8.6106, \n",
            "Epoch 5888/6000: train_loss=7.3934, val_loss=7.4922, \n",
            "Epoch 5889/6000: train_loss=7.9655, val_loss=10.4812, \n",
            "Epoch 5890/6000: train_loss=8.7528, val_loss=9.0283, \n",
            "Epoch 5891/6000: train_loss=6.7959, val_loss=8.9508, \n",
            "Epoch 5892/6000: train_loss=6.0863, val_loss=6.8549, \n",
            "Epoch 5893/6000: train_loss=5.8633, val_loss=7.1890, \n",
            "Epoch 5894/6000: train_loss=6.0464, val_loss=8.0392, \n",
            "Epoch 5895/6000: train_loss=5.8392, val_loss=7.3075, \n",
            "Epoch 5896/6000: train_loss=6.0443, val_loss=7.2118, \n",
            "Epoch 5897/6000: train_loss=6.5607, val_loss=7.0243, \n",
            "Epoch 5898/6000: train_loss=7.8347, val_loss=10.5364, \n",
            "Epoch 5899/6000: train_loss=7.8794, val_loss=8.6482, \n",
            "Epoch 5900/6000: train_loss=7.5789, val_loss=9.6439, \n",
            "Epoch 5901/6000: train_loss=6.5479, val_loss=6.9648, \n",
            "Epoch 5902/6000: train_loss=6.6555, val_loss=8.9364, \n",
            "Epoch 5903/6000: train_loss=6.1791, val_loss=7.3271, \n",
            "Epoch 5904/6000: train_loss=6.5989, val_loss=8.2960, \n",
            "Epoch 5905/6000: train_loss=6.5696, val_loss=7.0743, \n",
            "Epoch 5906/6000: train_loss=6.5270, val_loss=8.6568, \n",
            "Epoch 5907/6000: train_loss=6.3190, val_loss=7.5925, \n",
            "Epoch 5908/6000: train_loss=5.8321, val_loss=7.3395, \n",
            "Epoch 5909/6000: train_loss=5.7973, val_loss=6.7459, \n",
            "Epoch 5910/6000: train_loss=5.8750, val_loss=6.9449, \n",
            "Epoch 5911/6000: train_loss=6.5103, val_loss=8.8659, \n",
            "Epoch 5912/6000: train_loss=6.0442, val_loss=7.1841, \n",
            "Epoch 5913/6000: train_loss=6.3146, val_loss=7.9998, \n",
            "Epoch 5914/6000: train_loss=6.1224, val_loss=6.9989, \n",
            "Epoch 5915/6000: train_loss=6.2079, val_loss=8.2571, \n",
            "Epoch 5916/6000: train_loss=5.7675, val_loss=7.0822, \n",
            "Epoch 5917/6000: train_loss=5.8701, val_loss=7.2736, \n",
            "Epoch 5918/6000: train_loss=5.7912, val_loss=6.9628, \n",
            "Epoch 5919/6000: train_loss=5.7186, val_loss=7.4522, \n",
            "Epoch 5920/6000: train_loss=5.7001, val_loss=7.0876, \n",
            "Epoch 5921/6000: train_loss=5.7618, val_loss=7.1200, \n",
            "Epoch 5922/6000: train_loss=5.7024, val_loss=7.0696, \n",
            "Epoch 5923/6000: train_loss=5.6962, val_loss=7.0886, \n",
            "Epoch 5924/6000: train_loss=5.7437, val_loss=6.9032, \n",
            "Epoch 5925/6000: train_loss=5.7088, val_loss=7.1809, \n",
            "Epoch 5926/6000: train_loss=5.7373, val_loss=7.3787, \n",
            "Epoch 5927/6000: train_loss=5.7451, val_loss=6.9218, \n",
            "Epoch 5928/6000: train_loss=5.7066, val_loss=7.0570, \n",
            "Epoch 5929/6000: train_loss=5.7063, val_loss=7.0327, \n",
            "Epoch 5930/6000: train_loss=5.6931, val_loss=7.2576, \n",
            "Epoch 5931/6000: train_loss=5.7223, val_loss=7.2355, \n",
            "Epoch 5932/6000: train_loss=6.0329, val_loss=7.7564, \n",
            "Epoch 5933/6000: train_loss=5.8592, val_loss=6.8291, \n",
            "Epoch 5934/6000: train_loss=5.8778, val_loss=7.5920, \n",
            "Epoch 5935/6000: train_loss=5.7124, val_loss=7.2191, \n",
            "Epoch 5936/6000: train_loss=5.6879, val_loss=7.1142, \n",
            "Epoch 5937/6000: train_loss=5.7104, val_loss=7.1090, \n",
            "Epoch 5938/6000: train_loss=5.8150, val_loss=7.1168, \n",
            "Epoch 5939/6000: train_loss=5.7146, val_loss=7.2948, \n",
            "Epoch 5940/6000: train_loss=5.6774, val_loss=7.0709, \n",
            "Epoch 5941/6000: train_loss=5.7419, val_loss=7.1178, \n",
            "Epoch 5942/6000: train_loss=5.8996, val_loss=7.1144, \n",
            "Epoch 5943/6000: train_loss=5.7115, val_loss=7.3873, \n",
            "Epoch 5944/6000: train_loss=5.6849, val_loss=7.0325, \n",
            "Epoch 5945/6000: train_loss=5.6937, val_loss=6.8905, \n",
            "Epoch 5946/6000: train_loss=5.6960, val_loss=7.1132, \n",
            "Epoch 5947/6000: train_loss=5.6993, val_loss=7.4042, \n",
            "Epoch 5948/6000: train_loss=5.6760, val_loss=7.1676, \n",
            "Epoch 5949/6000: train_loss=5.9100, val_loss=6.9106, \n",
            "Epoch 5950/6000: train_loss=6.0913, val_loss=7.9614, \n",
            "Epoch 5951/6000: train_loss=5.6794, val_loss=7.2391, \n",
            "Epoch 5952/6000: train_loss=5.7965, val_loss=7.0860, \n",
            "Epoch 5953/6000: train_loss=5.7297, val_loss=7.1225, \n",
            "Epoch 5954/6000: train_loss=5.6805, val_loss=6.9710, \n",
            "Epoch 5955/6000: train_loss=5.6857, val_loss=6.9214, \n",
            "Epoch 5956/6000: train_loss=5.6917, val_loss=7.4122, \n",
            "Epoch 5957/6000: train_loss=5.7306, val_loss=7.5735, \n",
            "Epoch 5958/6000: train_loss=5.6919, val_loss=7.0062, \n",
            "Epoch 5959/6000: train_loss=5.7229, val_loss=6.7778, \n",
            "Epoch 5960/6000: train_loss=5.8157, val_loss=7.3869, \n",
            "Epoch 5961/6000: train_loss=5.6861, val_loss=7.2457, \n",
            "Epoch 5962/6000: train_loss=5.7477, val_loss=7.1946, \n",
            "Epoch 5963/6000: train_loss=5.7257, val_loss=6.8195, \n",
            "Epoch 5964/6000: train_loss=5.6746, val_loss=7.3456, \n",
            "Epoch 5965/6000: train_loss=5.6888, val_loss=7.3296, \n",
            "Epoch 5966/6000: train_loss=5.7703, val_loss=6.7570, \n",
            "Epoch 5967/6000: train_loss=5.6947, val_loss=6.9841, \n",
            "Epoch 5968/6000: train_loss=5.6955, val_loss=7.2094, \n",
            "Epoch 5969/6000: train_loss=5.6741, val_loss=7.2090, \n",
            "Epoch 5970/6000: train_loss=5.7106, val_loss=6.8063, \n",
            "Epoch 5971/6000: train_loss=5.7446, val_loss=7.3625, \n",
            "Epoch 5972/6000: train_loss=5.7278, val_loss=7.1656, \n",
            "Epoch 5973/6000: train_loss=5.9072, val_loss=7.9124, \n",
            "Epoch 5974/6000: train_loss=5.7043, val_loss=7.0101, \n",
            "Epoch 5975/6000: train_loss=5.8060, val_loss=7.1009, \n",
            "Epoch 5976/6000: train_loss=5.6753, val_loss=7.1692, \n",
            "Epoch 5977/6000: train_loss=5.7153, val_loss=7.4758, \n",
            "Epoch 5978/6000: train_loss=5.6692, val_loss=7.3044, \n",
            "Epoch 5979/6000: train_loss=5.9697, val_loss=6.9610, \n",
            "Epoch 5980/6000: train_loss=5.8694, val_loss=7.6854, \n",
            "Epoch 5981/6000: train_loss=5.6865, val_loss=7.2004, \n",
            "Epoch 5982/6000: train_loss=5.6730, val_loss=6.8347, \n",
            "Epoch 5983/6000: train_loss=5.7369, val_loss=6.8193, \n",
            "Epoch 5984/6000: train_loss=5.6788, val_loss=7.4313, \n",
            "Epoch 5985/6000: train_loss=5.7858, val_loss=7.4778, \n",
            "Epoch 5986/6000: train_loss=5.7335, val_loss=6.8181, \n",
            "Epoch 5987/6000: train_loss=5.7547, val_loss=7.4471, \n",
            "Epoch 5988/6000: train_loss=5.7665, val_loss=7.1546, \n",
            "Epoch 5989/6000: train_loss=5.9529, val_loss=7.5651, \n",
            "Epoch 5990/6000: train_loss=5.9826, val_loss=6.7677, \n",
            "Epoch 5991/6000: train_loss=5.6981, val_loss=7.3568, \n",
            "Epoch 5992/6000: train_loss=5.6548, val_loss=7.3426, \n",
            "Epoch 5993/6000: train_loss=5.6803, val_loss=6.8875, \n",
            "Epoch 5994/6000: train_loss=5.8269, val_loss=7.4729, \n",
            "Epoch 5995/6000: train_loss=5.9582, val_loss=7.2907, \n",
            "Epoch 5996/6000: train_loss=6.0551, val_loss=8.0134, \n",
            "Epoch 5997/6000: train_loss=6.1272, val_loss=6.6758, \n",
            "Epoch 5998/6000: train_loss=5.7465, val_loss=7.3595, \n",
            "Epoch 5999/6000: train_loss=5.7655, val_loss=7.2373, \n",
            "Epoch 6000/6000: train_loss=5.7141, val_loss=7.5132, \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "history = {'train_losses': [], 'val_losses': [], 'best_model': None, 'best_epoch': 0}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    first_batch = True  # reset each epoch\n",
        "\n",
        "    # --- Train in mini-batches ---\n",
        "    for X_batch, y_batch in get_batches(X_train, y_train, batch_size):\n",
        "        y_batch = np.asarray(y_batch)  # convert Series  NumPy array\n",
        "\n",
        "        if first_batch:\n",
        "            model.partial_fit(X_batch, y_batch)\n",
        "            first_batch = False\n",
        "        else:\n",
        "            model.partial_fit(X_batch, y_batch)\n",
        "\n",
        "    # --- Training loss ---\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    train_loss = mean_squared_error(y_train, y_train_pred)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "    # --- Validation loss ---\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    val_loss = mean_squared_error(y_val, y_val_pred)\n",
        "    val_r2 = r2_score(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \")\n",
        "\n",
        "    # Save best model (deepcopy to freeze weights)\n",
        "    if (history['best_model'] is None) or (val_loss < min(history['val_losses'], default=float(\"inf\"))):\n",
        "        history['best_model'] = copy.deepcopy(model)\n",
        "        history['best_epoch'] = epoch\n",
        "\n",
        "    history['train_losses'].append(train_loss)\n",
        "    history['val_losses'].append(val_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTYfTPd-z3iO"
      },
      "source": [
        "Observe the trend of the training and validation losses. Going down together is better!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ltDzeyrSz9Ny"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(epochs), history['train_losses'], label='train_loss')\n",
        "plt.plot(range(epochs), history['val_losses'], label='val_loss')\n",
        "plt.plot(history['best_epoch'], history['val_losses'][history['best_epoch']], marker='*')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-ju5N5F0xJQ"
      },
      "source": [
        "**Warning**: The common mistake with programmers is that they forgot to save the model at the best validation loss (minimum val_loss). The `history` variable tracks the best model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEsownTXhKSV"
      },
      "source": [
        "Next step is you validate your model using the validation set through `X_val` and `y_val`. Go to [3.4.4 Regression Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) and select the metrics that best describe your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DZTrlYC2hYNf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    MSE:      7.5132\n",
            "    RMSE:     2.7410\n",
            "    MAE:      2.1225\n",
            "    R Score: 0.8917\n",
            "    \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simple regression report function\n",
        "def regression_report(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    report = f\"\"\"\n",
        "    MSE:      {mse:.4f}\n",
        "    RMSE:     {rmse:.4f}\n",
        "    MAE:      {mae:.4f}\n",
        "    R Score: {r2:.4f}\n",
        "    \"\"\"\n",
        "    return report\n",
        "\n",
        "# Simple scatter plot function  \n",
        "def regression_display(y_true, y_pred):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_true, y_pred, alpha=0.6)\n",
        "    min_val = min(y_true.min(), y_pred.min())\n",
        "    max_val = max(y_true.max(), y_pred.max())\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title('Actual vs Predicted')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Your code:\n",
        "y_val_pred = model.predict(X_val)\n",
        "print(regression_report(y_val, y_val_pred))\n",
        "regression_display(y_val, y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA4WkHwj2Dpp"
      },
      "source": [
        "## 3. Testing\n",
        "\n",
        "Apply the same evaluation metrics to testing set (`X_test` and `y_test`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tncWds8d2DHJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    MSE:      14.2053\n",
            "    RMSE:     3.7690\n",
            "    MAE:      2.6358\n",
            "    R Score: 0.8213\n",
            "    \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simple regression report function\n",
        "def regression_report(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    report = f\"\"\"\n",
        "    MSE:      {mse:.4f}\n",
        "    RMSE:     {rmse:.4f}\n",
        "    MAE:      {mae:.4f}\n",
        "    R Score: {r2:.4f}\n",
        "    \"\"\"\n",
        "    return report\n",
        "\n",
        "# Simple scatter plot function  \n",
        "def regression_display(y_true, y_pred):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_true, y_pred, alpha=0.6)\n",
        "    min_val = min(y_true.min(), y_pred.min())\n",
        "    max_val = max(y_true.max(), y_pred.max())\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title('Actual vs Predicted')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "    \n",
        "y_test_pred = model.predict(X_test)\n",
        "print(regression_report(y_test, y_test_pred))\n",
        "regression_display(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1OnMcpAiDC-"
      },
      "source": [
        "Note: Do not forget to save your model offline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Mu5BIQic0oTl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mlp_regressor.pkl']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "model_name = \"mlp_regressor.pkl\"\n",
        "joblib.dump(model, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oW544W0Vvcw5"
      },
      "outputs": [],
      "source": [
        "# End of laboratory notebook. Nothing follows ..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Fvgy1kqc1k2S",
        "bBP7qoqubmNa"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
